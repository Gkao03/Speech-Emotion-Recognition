{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25508,"status":"ok","timestamp":1638389255760,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"HJkp8FiNBW2D","outputId":"c7bfe6c6-7ea1-4054-c9a5-54b63a31b069"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4781,"status":"ok","timestamp":1638389260537,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"x5pGdNEtDO1j","outputId":"ab8022c1-d587-45d7-9ee9-cc20b91ea0a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting allosaurus\n","  Downloading allosaurus-1.0.2-py3-none-any.whl (52 kB)\n","\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 834 kB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.10.0+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.4.1)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.5.3)\n","Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.2.2)\n","Collecting panphon\n","  Downloading panphon-0.19-py2.py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 615 kB/s \n","\u001b[?25hCollecting unicodecsv\n","  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (2019.12.20)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (57.4.0)\n","Collecting munkres\n","  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (3.13)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (1.15.0)\n","Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (0.51.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy->allosaurus) (0.34.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->allosaurus) (3.10.0.2)\n","Building wheels for collected packages: unicodecsv\n","  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10765 sha256=9baff5f7ad61f7cb9df62e572405ddcf1e1c75f32f9a9bc058f6f99559afab41\n","  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n","Successfully built unicodecsv\n","Installing collected packages: unicodecsv, munkres, panphon, allosaurus\n","Successfully installed allosaurus-1.0.2 munkres-1.1.4 panphon-0.19 unicodecsv-0.14.1\n"]}],"source":["!pip install allosaurus"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6625,"status":"ok","timestamp":1638389267158,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"-k-7oiYQ4Ivx"},"outputs":[],"source":["#These libraries help to interact with the operating system and the runtime environment respectively\n","import os\n","import sys\n","import pickle\n","\n","#Model/Training related libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","\n","#Dataloader libraries\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Transforms and datasets\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dset\n","\n","import time\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pandas as pd\n","from tqdm import tqdm\n","import random\n","\n","# Allosaurus\n","from allosaurus.audio import read_audio\n","from allosaurus.app import read_recognizer\n","from allosaurus.am.utils import *"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8592,"status":"ok","timestamp":1638389277164,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"scRMPhAs_9ig","outputId":"0bf1945c-8667-4293-fcf4-5f3f78d1a923"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading model  latest\n","from:  https://github.com/xinjli/allosaurus/releases/download/v1.0/latest.tar.gz\n","to:    /usr/local/lib/python3.7/dist-packages/allosaurus/pretrained\n","please wait...\n"]}],"source":["recognizer = read_recognizer()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2087,"status":"ok","timestamp":1638389279243,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"p7__m5ma3Qzf","outputId":"68e9c08c-eac1-4b29-9027-f65325a9e0ee"},"outputs":[{"data":{"text/plain":["(10039, 7)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# df = pd.read_csv(\"/content/gdrive/MyDrive/iemocap_full_dataset.csv\")\n","df = pd.read_csv(\"/content/gdrive/MyDrive/18786 IDL/IDL Project/iemocap_full_dataset.csv\")\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df[df.emotion != 'xxx']  # only keep data that has emotion label\n","# only keep 'neu', 'hap', 'sad', 'ang' labels\n","df = df.drop(df[~ ((df.emotion == 'neu') | (df.emotion == 'hap') | (df.emotion == 'sad') | (df.emotion == 'ang'))].index)\n","\n","df_unedit = df.copy()\n","df_unedit[\"path\"] = df_unedit[\"path\"].apply(lambda x : x.split('/')[-1])\n","all_files = list(df_unedit.path)\n","file_to_emotion = dict(zip(df_unedit.path, df_unedit.emotion))\n","\n","all_full_files = list(df.path)\n","print(df)\n","print(df_unedit)\n","print(len(file_to_emotion))\n","print(file_to_emotion)\n","print(all_full_files)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1638389283393,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"BAPXqH0zAKHk","outputId":"35365cbf-85b1-4c14-98ce-bf585d4e272e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","{0: 'neu', 1: 'hap', 2: 'sad', 3: 'ang'}\n","Counter({'neu': 1708, 'ang': 1103, 'sad': 1084, 'hap': 595})\n"]}],"source":["from collections import Counter\n","\n","# get unique emotions\n","# emotion_to_label = {'neu': 0, 'fru': 1, 'sad': 2, 'sur': 3, 'ang': 4, 'hap': 5, 'exc': 6, 'fea': 7, 'dis': 8, 'oth': 9}\n","emotion_to_label = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","label_to_emotion = {v: k for k, v in emotion_to_label.items()}\n","print(emotion_to_label)\n","print(label_to_emotion)\n","\n","# counter number of class instances\n","emotion_instances_list = [v for v in file_to_emotion.values()]\n","counter = Counter(emotion_instances_list)\n","print(counter)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_to_label = {k: emotion_to_label[v] for k, v in file_to_emotion.items()}\n","print(file_to_label)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1638389284135,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"c3di3Mr5rRG4"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, file_list, target_list):\n","        \n","        self.file_list = file_list\n","        self.target_list = target_list\n","        self.num_classes = len(list(set(target_list)))\n","\n","        self.x = file_list\n","        self.y = target_list\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        filepath = self.file_list[index]\n","        x = torch.tensor(recognizer.pm.compute(read_audio(filepath)))\n","        x = x.detach()\n","        x_len = torch.tensor(np.array([x.shape[0]], dtype=np.int32))\n","        x_len = x_len.detach()\n","        y = torch.Tensor([self.target_list[index]])\n","        return x, x_len, y"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1638389285788,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"-4ffBDD2AJyL","outputId":"981e8363-331b-46b5-a30b-89969a7e1699"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","gdrive\tsample_data\n"]}],"source":["%cd /content\n","!ls"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1638389286864,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"AK8jRp6isDN2"},"outputs":[],"source":["# collate function\n","def pad_collate(batch):\n","    # print(\"inside collate\")\n","    # batch looks like [(x0, xlen0, y0), (x4, xlen4, y4), (x2, xlen2, y2)... ]\n","    feats = [sample[0] for sample in batch]\n","    feat_lens = [sample[1] for sample in batch]\n","    target_list = torch.Tensor([sample[2] for sample in batch])\n","\n","    feats = pad_sequence(feats, batch_first=True, padding_value=0) # batch, features, len\n","    feat_lens = pad_sequence(feat_lens, batch_first=True, padding_value=0).squeeze()\n","    idx = torch.argsort(feat_lens, descending=True) # sorting the input in descending order as required by the lstms in AM.\n","\n","    # reorder\n","    # tensor_batch_feat = feats[idx]\n","    # tensor_batch_feat_len = feat_lens[idx]\n","    targets = target_list[idx]\n","    tensor_batch_feat, tensor_batch_feat_len = move_to_tensor([feats[idx], feat_lens[idx]], device_id=-1) # converting to the required tensors\n","\n","    # Features\n","    output_tensor, input_lengths = recognizer.am(tensor_batch_feat, tensor_batch_feat_len, return_lstm=True) # output_shape: [len,batch,features]\n","    output_tensor = output_tensor.detach()\n","    input_lengths = input_lengths.detach()\n","    \n","    return output_tensor, input_lengths, targets"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1638389287695,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"jwpZTdgHsBjN"},"outputs":[],"source":["# all_file_paths = [os.path.join(\"gdrive\", \"MyDrive\", \"data\", \"IEMOCAP_full_release\", file_path) for file_path in all_full_files]\n","all_file_paths = [os.path.join(\"gdrive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"data\", \"IEMOCAP_full_release\", file_path) for file_path in all_full_files]\n","total_instances = len(all_file_paths)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1638389287992,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"abbkoaDuscWe","outputId":"e11bd779-ad60-4eb3-a742-9c4fabfc391d"},"outputs":[{"name":"stdout","output_type":"stream","text":["number training instances: 3592\n","number validation instances: 449\n","number test instances: 449\n"]}],"source":["num_train = round(0.8 * total_instances)\n","num_test_all = total_instances - num_train\n","num_val = round(0.5 * num_test_all)\n","num_test = num_test_all - num_val\n","\n","print(\"number training instances:\", str(num_train))\n","print(\"number validation instances:\", str(num_val))\n","print(\"number test instances:\", str(num_test))\n","assert(num_train + num_val + num_test == total_instances)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1638389289660,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"Xw3Mh8bpsYc9"},"outputs":[],"source":["# shuffle data\n","import random\n","random.seed(2021)\n","\n","shuffled_data_paths = random.sample(all_file_paths, k=total_instances)\n","# train_list_paths = shuffled_data_paths[:num_train]\n","# testall_list_paths = shuffled_data_paths[num_train:]\n","# val_list_paths = testall_list_paths[:num_val]\n","# test_list_paths = testall_list_paths[num_test:]\n","\n","# assert(len(train_list_paths) + len(val_list_paths) + len(test_list_paths) == total_instances)\n","\n","# train, val, test variables:\n","# train_list_paths\n","# val_list_paths\n","# test_list_paths"]},{"cell_type":"markdown","metadata":{"id":"6TfpVcv48QJQ"},"source":["##Model"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1638389290777,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"h8ZIiO_l6-i4"},"outputs":[],"source":["class ICASSP3CNN(nn.Module):\n","    def __init__(self, embed_size=640, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n","        super().__init__()\n","        self.n_layers = num_lstm_layers \n","        self.hidden = hidden_size\n","        self.bidirectional = bidirectional\n","        \n","        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n","        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n","        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n","\n","        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n","\n","        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n","                            hidden_size = hidden_size, \n","                            num_layers = num_lstm_layers, \n","                            bidirectional = bidirectional)\n","\n","        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n","                                out_features = label_size)\n","\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        padded_x: (B,T) padded LongTensor\n","        \"\"\"\n","        \n","        batch_size = x.shape[0]\n","        \n","        x = x.permute(1, 2, 0)    # (seq_len, batch_size, input_size) -> (batch_size, input_size, seq_len)\n","      \n","        cnn_output = torch.cat([self.cnn(x), self.cnn2(x), self.cnn3(x)], dim=1)\n","\n","        input = F.relu(self.batchnorm(cnn_output))\n","\n","        input = input.transpose(1,2)\n","\n","        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits\n","        \n","        \n","class ICASSP2CNN(nn.Module):\n","    def __init__(self, embed_size=640, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n","        super().__init__()\n","        self.n_layers = num_lstm_layers \n","        self.hidden = hidden_size\n","        self.bidirectional = bidirectional\n","\n","        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n","        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n","\n","        self.batchnorm = nn.BatchNorm1d(2 * embed_size)\n","\n","        self.lstm = nn.LSTM(input_size = 2 * embed_size, \n","                            hidden_size = hidden_size, \n","                            num_layers = num_lstm_layers, \n","                            bidirectional = bidirectional)\n","\n","        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n","                                out_features = label_size)\n","\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        padded_x: (B,T) padded LongTensor\n","        \"\"\"\n","        \n","        batch_size = x.shape[0]\n","        # torch.Size([468, 64, 640])\n","        x = x.permute(1, 2, 0)    # (seq_len, batch_size, input_size) -> (batch_size, input_size, seq_len)\n","\n","        cnn_output = torch.cat([self.cnn(x), self.cnn2(x)], dim=1)\n","\n","        input = F.relu(self.batchnorm(cnn_output))\n","\n","        input = input.transpose(1,2)\n","\n","        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits\n","    \n","\n","class ICASSP1CNN(nn.Module):\n","    def __init__(self, embed_size=640, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n","        super().__init__()\n","        self.n_layers = num_lstm_layers \n","        self.hidden = hidden_size\n","        self.bidirectional = bidirectional\n","\n","        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n","\n","        self.batchnorm = nn.BatchNorm1d(embed_size)\n","\n","        self.lstm = nn.LSTM(input_size = embed_size, \n","                            hidden_size = hidden_size, \n","                            num_layers = num_lstm_layers, \n","                            bidirectional = bidirectional)\n","\n","        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n","                                out_features = label_size)\n","\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        padded_x: (B,T) padded LongTensor\n","        \"\"\"\n","        batch_size = x.shape[0]\n","     \n","        x = x.permute(1, 2, 0)    # (seq_len, batch_size, input_size) -> (batch_size, input_size, seq_len)\n","\n","        cnn_output = self.cnn(x)\n","\n","        input = F.relu(self.batchnorm(cnn_output))\n","\n","        input = input.transpose(1,2)\n","\n","        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits\n","        "]},{"cell_type":"markdown","metadata":{"id":"KZAxmuMs8jAa"},"source":["## Training"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":568,"status":"ok","timestamp":1638389293917,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"eMCs_r1t8g5O"},"outputs":[],"source":["def train_language_model(train_loader_LM, model, opt, criterion, device):\n","\n","    loss_accum = 0.0\n","    batch_cnt = 0\n","\n","    model.train()\n","    start_time = time.time()\n","    for batch, (x, lengths, y) in enumerate(train_loader_LM):\n","\n","        x = x.to(device)\n","        #lengths = lengths.to(device)\n","        y = y.long().to(device)\n","        opt.zero_grad()\n","\n","        logits = model(x, lengths)\n","        \n","        loss = criterion(logits.permute(0,2,1), y)\n","        loss_score = loss.cpu().item()\n","\n","        loss_accum += loss_score\n","        batch_cnt += 1\n","        loss.backward()\n","        opt.step()      \n","\n","    NLL = loss_accum / batch_cnt\n","        \n","    return model, NLL\n","\n","\n","def train_model(train_loader, model, opt, criterion, device):\n","\n","    loss_accum = 0.0\n","    batch_cnt = 0\n","\n","    acc_cnt = 0     #count correct predictions\n","    err_cnt = 0     #count incorrect predictions\n","\n","    model.train()\n","    start_time = time.time()\n","    for batch, (x, lengths, y) in enumerate(train_loader):\n","        x = x.to(device)\n","        #lengths = lengths.to(device)\n","        y = y.long().to(device)\n","        opt.zero_grad()\n","\n","        logits = model(x, lengths)\n","\n","        loss = criterion(logits, y)\n","        loss_score = loss.cpu().item()\n","\n","        loss_accum += loss_score\n","        batch_cnt += 1\n","        loss.backward()\n","        opt.step()\n","\n","        #model outputs\n","        out_val, out_indices = torch.max(logits, dim=1)\n","        tar_indices = y\n","\n","        for i in range(len(out_indices)):\n","            if out_indices[i] == tar_indices[i]:\n","                acc_cnt += 1\n","            else:\n","                err_cnt += 1\n","                     \n","    training_accuracy =  acc_cnt/(err_cnt+acc_cnt) \n","    training_loss = loss_accum / batch_cnt\n","        \n","    return model, training_accuracy, training_loss\n","\n","\n","def test_model(loader, model, opt, criterion, device):\n","    model.eval()\n","    acc_cnt = 0\n","    err_cnt = 0\n","\n","    for x, lengths, y in loader:\n","        \n","        x = x.to(device)\n","        y = y.long().to(device)\n","        \n","        logits = model(x, lengths)\n","\n","        out_val, out_indices = torch.max(logits, dim=1)\n","        tar_indices = y\n","\n","        for i in range(len(out_indices)):\n","            if out_indices[i] == tar_indices[i]:\n","                acc_cnt += 1\n","            else:\n","                err_cnt += 1\n","\n","    current_acc = acc_cnt/(err_cnt+acc_cnt)\n","    \n","    return current_acc"]},{"cell_type":"markdown","metadata":{"id":"aAOlPe9g80N_"},"source":["## Main runner"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8019,"status":"ok","timestamp":1638389303787,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"oXwYXAdJ2DLN"},"outputs":[],"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","model = ICASSP1CNN()\n","# checkpoint = torch.load(\"/content/gdrive/MyDrive/model/model.pt\")\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","# opt.load_state_dict(checkpoint['optimizer_state_dict'])\n","# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","criterion = nn.CrossEntropyLoss()\n","model.to(device)\n","# opt = optim.Adam(model.parameters(), lr = 0.001)\n","# criterion = nn.CrossEntropyLoss()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","# valid_acc = test_model(val_loader, model, opt, criterion, device)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1638389303788,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"FxQKSePGstCE"},"outputs":[],"source":["def get_k_folder(k, i):\n","  n = num_train+num_val\n","  train_val_list_paths = shuffled_data_paths[:n]\n","  fold_size = (n + k-1) // k\n","\n","  train_list_paths = train_val_list_paths[:i*fold_size] + train_val_list_paths[i*fold_size+fold_size:n]\n","  val_list_paths = train_val_list_paths[i*fold_size:min(i*fold_size+fold_size, n)]\n","\n","  return train_list_paths, val_list_paths"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1638389303788,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"SkU-j5F9ssjF"},"outputs":[],"source":["def get_loaders(k, i):\n","  train_list_paths, val_list_paths = get_k_folder(k, i)\n","  # get corresponding labels for data\n","  train_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in train_list_paths]\n","  val_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in val_list_paths]\n","\n","  assert(len(train_list_labels) == len(train_list_paths))\n","  assert(len(val_list_labels) == len(val_list_paths))\n","\n","  # train dataloader\n","  train_dset = MyDataset(train_list_paths, train_list_labels)\n","  train_args = dict(shuffle=True, batch_size=128, num_workers=2, collate_fn=pad_collate, drop_last=True)  # change to num_workers=4 on diff platform\n","  train_loader = DataLoader(train_dset, **train_args)\n","\n","  # val dataloader\n","  val_dset = MyDataset(val_list_paths, val_list_labels)\n","  val_args = dict(shuffle=False, batch_size=128, num_workers=2, collate_fn=pad_collate, drop_last=True)\n","  val_loader = DataLoader(val_dset, **val_args)\n","\n","  return train_loader, val_loader"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1638389305190,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"8ebmLV8Xmgu5"},"outputs":[],"source":["def reset_weights(m):\n","    '''\n","        Try resetting model weights to avoid\n","        weight leakage.\n","    '''\n","    for layer in m.children():\n","        if hasattr(layer, 'reset_parameters'):\n","            print(f'Reset trainable parameters of layer = {layer}')\n","            layer.reset_parameters()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56435916,"status":"ok","timestamp":1638445742552,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"FyMP1HFp8y6C","outputId":"1aa65a35-9e09-4e5a-ef35-aa1c48491c58"},"outputs":[{"name":"stdout","output_type":"stream","text":["3CNN,False,640,2,128\n","ICASSP3CNN(\n","  (cnn): Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","  (cnn2): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","  (cnn3): Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","  (batchnorm): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lstm): LSTM(1920, 128, num_layers=2)\n","  (linear): Linear(in_features=128, out_features=31, bias=True)\n",")\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 0th cross validation.......\n","Fold: 0, Epoch: 0, Training Accuracy: 0.3719429347826087, Training loss:1.9202533338380896, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 1, Training Accuracy: 0.38654891304347827, Training loss:1.3105963572211887, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 2, Training Accuracy: 0.405570652173913, Training loss:1.2633265878843225, Validation accuracy:0.40401785714285715\n","Fold: 0, Epoch: 3, Training Accuracy: 0.43172554347826086, Training loss:1.2234253935191943, Validation accuracy:0.38058035714285715\n","Fold: 0, Epoch: 4, Training Accuracy: 0.460258152173913, Training loss:1.178560355435247, Validation accuracy:0.45870535714285715\n","Fold: 0, Epoch: 5, Training Accuracy: 0.48947010869565216, Training loss:1.1541974544525146, Validation accuracy:0.44419642857142855\n","Fold: 0, Epoch: 6, Training Accuracy: 0.47927989130434784, Training loss:1.1766973215600718, Validation accuracy:0.42410714285714285\n","Fold: 0, Epoch: 7, Training Accuracy: 0.5067934782608695, Training loss:1.1374052141023718, Validation accuracy:0.49441964285714285\n","Fold: 0, Epoch: 8, Training Accuracy: 0.5159646739130435, Training loss:1.1052878628606382, Validation accuracy:0.49888392857142855\n","Fold: 0, Epoch: 9, Training Accuracy: 0.5543478260869565, Training loss:1.0825836477072344, Validation accuracy:0.5256696428571429\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 1th cross validation.......\n","Fold: 1, Epoch: 0, Training Accuracy: 0.36277173913043476, Training loss:1.9216440501420393, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 1, Training Accuracy: 0.37907608695652173, Training loss:1.3395806706469993, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 2, Training Accuracy: 0.38077445652173914, Training loss:1.3141478144604226, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 3, Training Accuracy: 0.3923233695652174, Training loss:1.2902966737747192, Validation accuracy:0.40066964285714285\n","Fold: 1, Epoch: 4, Training Accuracy: 0.4001358695652174, Training loss:1.2598310708999634, Validation accuracy:0.44419642857142855\n","Fold: 1, Epoch: 5, Training Accuracy: 0.41813858695652173, Training loss:1.24671324957972, Validation accuracy:0.4765625\n","Fold: 1, Epoch: 6, Training Accuracy: 0.4429347826086957, Training loss:1.2168779632319575, Validation accuracy:0.4720982142857143\n","Fold: 1, Epoch: 7, Training Accuracy: 0.4310461956521739, Training loss:1.2297345814497576, Validation accuracy:0.41629464285714285\n","Fold: 1, Epoch: 8, Training Accuracy: 0.44870923913043476, Training loss:1.1918305469595867, Validation accuracy:0.49107142857142855\n","Fold: 1, Epoch: 9, Training Accuracy: 0.4874320652173913, Training loss:1.1517224881959998, Validation accuracy:0.49330357142857145\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 2th cross validation.......\n","Fold: 2, Epoch: 0, Training Accuracy: 0.3617527173913043, Training loss:1.9378403269726296, Validation accuracy:0.3939732142857143\n","Fold: 2, Epoch: 1, Training Accuracy: 0.39470108695652173, Training loss:1.2781619144522625, Validation accuracy:0.4017857142857143\n","Fold: 2, Epoch: 2, Training Accuracy: 0.429008152173913, Training loss:1.2500338813532954, Validation accuracy:0.4375\n","Fold: 2, Epoch: 3, Training Accuracy: 0.46501358695652173, Training loss:1.18482534263445, Validation accuracy:0.46986607142857145\n","Fold: 2, Epoch: 4, Training Accuracy: 0.46365489130434784, Training loss:1.1936876773834229, Validation accuracy:0.4609375\n","Fold: 2, Epoch: 5, Training Accuracy: 0.4578804347826087, Training loss:1.1903298730435579, Validation accuracy:0.42299107142857145\n","Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 2, Epoch: 6, Training Accuracy: 0.46297554347826086, Training loss:1.1751229970351509, Validation accuracy:0.43973214285714285\n","Fold: 2, Epoch: 7, Training Accuracy: 0.49014945652173914, Training loss:1.1424853438916414, Validation accuracy:0.46986607142857145\n","Fold: 2, Epoch: 8, Training Accuracy: 0.48879076086956524, Training loss:1.1399805338486382, Validation accuracy:0.46763392857142855\n","Fold: 2, Epoch: 9, Training Accuracy: 0.5183423913043478, Training loss:1.1174134275187617, Validation accuracy:0.46316964285714285\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 3th cross validation.......\n","Fold: 3, Epoch: 0, Training Accuracy: 0.37601902173913043, Training loss:1.8332826624745908, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 1, Training Accuracy: 0.38077445652173914, Training loss:1.3322859017745308, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 2, Training Accuracy: 0.3797554347826087, Training loss:1.3203858551771745, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 3, Training Accuracy: 0.3923233695652174, Training loss:1.3043311730675076, Validation accuracy:0.4095982142857143\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 3, Epoch: 4, Training Accuracy: 0.40251358695652173, Training loss:1.2624329069386357, Validation accuracy:0.42075892857142855\n","Fold: 3, Epoch: 5, Training Accuracy: 0.45346467391304346, Training loss:1.2137424272039663, Validation accuracy:0.45870535714285715\n","Fold: 3, Epoch: 6, Training Accuracy: 0.47860054347826086, Training loss:1.1716524725374968, Validation accuracy:0.48660714285714285\n","Fold: 3, Epoch: 7, Training Accuracy: 0.5074728260869565, Training loss:1.1418212444885918, Validation accuracy:0.4799107142857143\n","Fold: 3, Epoch: 8, Training Accuracy: 0.5309103260869565, Training loss:1.103584605714549, Validation accuracy:0.49441964285714285\n","Fold: 3, Epoch: 9, Training Accuracy: 0.5580842391304348, Training loss:1.0779372997905896, Validation accuracy:0.53125\n","The avg acc is: 0.5033482142857143\n","3CNN,False,640,2,256\n","ICASSP3CNN(\n","  (cnn): Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","  (cnn2): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","  (cnn3): Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","  (batchnorm): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lstm): LSTM(1920, 256, num_layers=2)\n","  (linear): Linear(in_features=256, out_features=31, bias=True)\n",")\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 0th cross validation.......\n","Fold: 0, Epoch: 0, Training Accuracy: 0.35597826086956524, Training loss:1.6227630117665166, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 1, Training Accuracy: 0.397758152173913, Training loss:1.2903058788050776, Validation accuracy:0.37611607142857145\n","Fold: 0, Epoch: 2, Training Accuracy: 0.41032608695652173, Training loss:1.2393260313116985, Validation accuracy:0.39285714285714285\n","Fold: 0, Epoch: 3, Training Accuracy: 0.43070652173913043, Training loss:1.2314080621885217, Validation accuracy:0.4341517857142857\n","Fold: 0, Epoch: 4, Training Accuracy: 0.4517663043478261, Training loss:1.20219712153725, Validation accuracy:0.45424107142857145\n","Fold: 0, Epoch: 5, Training Accuracy: 0.47316576086956524, Training loss:1.169151202492092, Validation accuracy:0.46316964285714285\n","Fold: 0, Epoch: 6, Training Accuracy: 0.49592391304347827, Training loss:1.1453666324200837, Validation accuracy:0.515625\n","Fold: 0, Epoch: 7, Training Accuracy: 0.49626358695652173, Training loss:1.1442829059517903, Validation accuracy:0.484375\n","Fold: 0, Epoch: 8, Training Accuracy: 0.5448369565217391, Training loss:1.0751531020454739, Validation accuracy:0.5145089285714286\n","Fold: 0, Epoch: 9, Training Accuracy: 0.5380434782608695, Training loss:1.0719753322394, Validation accuracy:0.5122767857142857\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 1th cross validation.......\n","Fold: 1, Epoch: 0, Training Accuracy: 0.36209239130434784, Training loss:1.6334205606709356, Validation accuracy:0.30245535714285715\n","Fold: 1, Epoch: 1, Training Accuracy: 0.38960597826086957, Training loss:1.2958055423653645, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 2, Training Accuracy: 0.4076086956521739, Training loss:1.2437503856161367, Validation accuracy:0.44642857142857145\n","Fold: 1, Epoch: 3, Training Accuracy: 0.4235733695652174, Training loss:1.2183034212692925, Validation accuracy:0.4486607142857143\n","Fold: 1, Epoch: 4, Training Accuracy: 0.45822010869565216, Training loss:1.1753017695053765, Validation accuracy:0.47433035714285715\n","Fold: 1, Epoch: 5, Training Accuracy: 0.46433423913043476, Training loss:1.1670613651690276, Validation accuracy:0.5245535714285714\n","Fold: 1, Epoch: 6, Training Accuracy: 0.4952445652173913, Training loss:1.1414360533589902, Validation accuracy:0.5167410714285714\n","Fold: 1, Epoch: 7, Training Accuracy: 0.5197010869565217, Training loss:1.1060279918753582, Validation accuracy:0.5502232142857143\n","Fold: 1, Epoch: 8, Training Accuracy: 0.5237771739130435, Training loss:1.1031762750252434, Validation accuracy:0.546875\n","Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 1, Epoch: 9, Training Accuracy: 0.5295516304347826, Training loss:1.09150012679722, Validation accuracy:0.5424107142857143\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 2th cross validation.......\n","Fold: 2, Epoch: 0, Training Accuracy: 0.3624320652173913, Training loss:1.6424187473628833, Validation accuracy:0.3950892857142857\n","Fold: 2, Epoch: 1, Training Accuracy: 0.3811141304347826, Training loss:1.3051430660745371, Validation accuracy:0.42410714285714285\n","Fold: 2, Epoch: 2, Training Accuracy: 0.41202445652173914, Training loss:1.2490319894707722, Validation accuracy:0.40401785714285715\n","Fold: 2, Epoch: 3, Training Accuracy: 0.429008152173913, Training loss:1.2197851823723835, Validation accuracy:0.44642857142857145\n","Fold: 2, Epoch: 4, Training Accuracy: 0.45991847826086957, Training loss:1.188275492709616, Validation accuracy:0.47098214285714285\n","Fold: 2, Epoch: 5, Training Accuracy: 0.4898097826086957, Training loss:1.1533431644025056, Validation accuracy:0.46875\n","Fold: 2, Epoch: 6, Training Accuracy: 0.5084918478260869, Training loss:1.1227313072785088, Validation accuracy:0.5044642857142857\n","Fold: 2, Epoch: 7, Training Accuracy: 0.5390625, Training loss:1.0897518240887185, Validation accuracy:0.5133928571428571\n","Fold: 2, Epoch: 8, Training Accuracy: 0.563858695652174, Training loss:1.0510716852934465, Validation accuracy:0.5200892857142857\n","Fold: 2, Epoch: 9, Training Accuracy: 0.5631793478260869, Training loss:1.043493996495786, Validation accuracy:0.5625\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=2)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 3th cross validation.......\n","Fold: 3, Epoch: 0, Training Accuracy: 0.36379076086956524, Training loss:1.6173096532407014, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 1, Training Accuracy: 0.39266304347826086, Training loss:1.283214983732804, Validation accuracy:0.4029017857142857\n","Fold: 3, Epoch: 2, Training Accuracy: 0.40115489130434784, Training loss:1.2715234238168467, Validation accuracy:0.42745535714285715\n","Fold: 3, Epoch: 3, Training Accuracy: 0.45108695652173914, Training loss:1.2067243638245955, Validation accuracy:0.43973214285714285\n","Fold: 3, Epoch: 4, Training Accuracy: 0.4718070652173913, Training loss:1.1669863047807112, Validation accuracy:0.4642857142857143\n","Fold: 3, Epoch: 5, Training Accuracy: 0.4986413043478261, Training loss:1.1373155583506045, Validation accuracy:0.4720982142857143\n","Fold: 3, Epoch: 6, Training Accuracy: 0.492866847826087, Training loss:1.134892743566762, Validation accuracy:0.4799107142857143\n","Fold: 3, Epoch: 7, Training Accuracy: 0.47316576086956524, Training loss:1.1620310389477273, Validation accuracy:0.53125\n","Fold: 3, Epoch: 8, Training Accuracy: 0.5641983695652174, Training loss:1.0646433000979216, Validation accuracy:0.5513392857142857\n","Fold: 3, Epoch: 9, Training Accuracy: 0.5713315217391305, Training loss:1.0279568666997163, Validation accuracy:0.5279017857142857\n","The avg acc is: 0.5362723214285714\n","3CNN,False,640,3,256\n","ICASSP3CNN(\n","  (cnn): Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","  (cnn2): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","  (cnn3): Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","  (batchnorm): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lstm): LSTM(1920, 256, num_layers=3)\n","  (linear): Linear(in_features=256, out_features=31, bias=True)\n",")\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 0th cross validation.......\n","Fold: 0, Epoch: 0, Training Accuracy: 0.34748641304347827, Training loss:1.7260816356410151, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 1, Training Accuracy: 0.366508152173913, Training loss:1.3293341398239136, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 2, Training Accuracy: 0.3875679347826087, Training loss:1.325362433557925, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 3, Training Accuracy: 0.38790760869565216, Training loss:1.3227364291315493, Validation accuracy:0.35267857142857145\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 0, Epoch: 4, Training Accuracy: 0.3858695652173913, Training loss:1.3274581069531648, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 5, Training Accuracy: 0.38960597826086957, Training loss:1.3219592363938042, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 6, Training Accuracy: 0.38688858695652173, Training loss:1.3247753848200259, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 7, Training Accuracy: 0.38620923913043476, Training loss:1.3231669249741926, Validation accuracy:0.35267857142857145\n","Epoch     9: reducing learning rate of group 0 to 2.5000e-04.\n","Fold: 0, Epoch: 8, Training Accuracy: 0.38688858695652173, Training loss:1.3229773303736811, Validation accuracy:0.35267857142857145\n","Fold: 0, Epoch: 9, Training Accuracy: 0.3841711956521739, Training loss:1.3238475374553516, Validation accuracy:0.35267857142857145\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 1th cross validation.......\n","Fold: 1, Epoch: 0, Training Accuracy: 0.3532608695652174, Training loss:1.7140617888906728, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 1, Training Accuracy: 0.3804347826086957, Training loss:1.3330605755681577, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 2, Training Accuracy: 0.3797554347826087, Training loss:1.3283648853716643, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 3, Training Accuracy: 0.37771739130434784, Training loss:1.3281274411989294, Validation accuracy:0.3861607142857143\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 1, Epoch: 4, Training Accuracy: 0.38009510869565216, Training loss:1.3228414991627568, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 5, Training Accuracy: 0.37839673913043476, Training loss:1.29704777572466, Validation accuracy:0.3861607142857143\n","Fold: 1, Epoch: 6, Training Accuracy: 0.39266304347826086, Training loss:1.2553224667258884, Validation accuracy:0.3314732142857143\n","Fold: 1, Epoch: 7, Training Accuracy: 0.4038722826086957, Training loss:1.225307392037433, Validation accuracy:0.42075892857142855\n","Fold: 1, Epoch: 8, Training Accuracy: 0.45278532608695654, Training loss:1.1678932490556135, Validation accuracy:0.45200892857142855\n","Fold: 1, Epoch: 9, Training Accuracy: 0.47316576086956524, Training loss:1.1541618419730144, Validation accuracy:0.4955357142857143\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 2th cross validation.......\n","Fold: 2, Epoch: 0, Training Accuracy: 0.36209239130434784, Training loss:1.70714793516242, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 1, Training Accuracy: 0.36684782608695654, Training loss:1.3381566327551138, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 2, Training Accuracy: 0.38485054347826086, Training loss:1.330356908881146, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 3, Training Accuracy: 0.382133152173913, Training loss:1.3291665056477422, Validation accuracy:0.38392857142857145\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 2, Epoch: 4, Training Accuracy: 0.38315217391304346, Training loss:1.3249766256498254, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 5, Training Accuracy: 0.3845108695652174, Training loss:1.3222531546717105, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 6, Training Accuracy: 0.382133152173913, Training loss:1.3250988825507786, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 7, Training Accuracy: 0.38179347826086957, Training loss:1.3251586064048435, Validation accuracy:0.38392857142857145\n","Epoch     9: reducing learning rate of group 0 to 2.5000e-04.\n","Fold: 2, Epoch: 8, Training Accuracy: 0.3828125, Training loss:1.3244279882182246, Validation accuracy:0.38392857142857145\n","Fold: 2, Epoch: 9, Training Accuracy: 0.3828125, Training loss:1.3250734339589658, Validation accuracy:0.38392857142857145\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 256, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=256, out_features=31, bias=True)\n","Running 3th cross validation.......\n","Fold: 3, Epoch: 0, Training Accuracy: 0.34714673913043476, Training loss:1.7132499891778696, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 1, Training Accuracy: 0.3797554347826087, Training loss:1.329915368038675, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 2, Training Accuracy: 0.38179347826086957, Training loss:1.3319704066152158, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 3, Training Accuracy: 0.38247282608695654, Training loss:1.326889815537826, Validation accuracy:0.38504464285714285\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n","Fold: 3, Epoch: 4, Training Accuracy: 0.3797554347826087, Training loss:1.3307741413945737, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 5, Training Accuracy: 0.3797554347826087, Training loss:1.3258747588033262, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 6, Training Accuracy: 0.3804347826086957, Training loss:1.3243890275125918, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 7, Training Accuracy: 0.38247282608695654, Training loss:1.3199774182361106, Validation accuracy:0.38504464285714285\n","Epoch     9: reducing learning rate of group 0 to 2.5000e-04.\n","Fold: 3, Epoch: 8, Training Accuracy: 0.3797554347826087, Training loss:1.3154490201369575, Validation accuracy:0.38504464285714285\n","Fold: 3, Epoch: 9, Training Accuracy: 0.3804347826086957, Training loss:1.2900960445404053, Validation accuracy:0.38504464285714285\n","The avg acc is: 0.404296875\n"]}],"source":["os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","run_num = 1\n","n_epochs = 10\n","cuda = torch.cuda.is_available()\n","\n","#Define Training Grid Search\n","# model_list = ['1CNN', '2CNN', '3CNN']\n","# emb_size_list = [640, 640, 640]\n","# hidden_size_list = [128, 256, 384, 512]\n","# num_lstm_layers_list = [1, 2, 3]\n","# bidirectional_list = [False, True]\n","\n","# model_list = ['1CNN', '2CNN', '3CNN']\n","# emb_size_list = [640]\n","# hidden_size_list = [128, 256]\n","# num_lstm_layers_list = [1, 2, 3]\n","# bidirectional_list = [False]\n","models = [\"3CNN 640 128 2 False\", \"3CNN 640 256 2 False\", \"3CNN 640 256 3 False\"]\n","\n","\n","model_id = 0\n","best_avg_acc = 0\n","\n","for model in models:\n","    model_id += 1\n","    start_time = time.time()\n","\n","    split_string = model.split(' ')\n","\n","    model_name = split_string[0]\n","    emb_size = int(split_string[1])\n","    hidden_size = int(split_string[2])\n","    num_lstm = int(split_string[3])\n","    bidirectionality = True if split_string[4] == \"True\" else False\n","    \n","    #Log Metadata\n","    metadata = model_name + ',' + str(bidirectionality) + ',' + str(emb_size) + ',' + str(num_lstm) + ',' + str(hidden_size)\n","    print(metadata)\n","\n","    #initialize model\n","    if model_name == '1CNN':\n","        model = ICASSP1CNN(emb_size, hidden_size, num_lstm, bidirectionality)\n","    elif model_name == '2CNN':\n","        model = ICASSP2CNN(emb_size, hidden_size, num_lstm, bidirectionality)\n","    elif model_name == '3CNN':\n","        model = ICASSP3CNN(emb_size, hidden_size, num_lstm, bidirectionality)        \n","\n","    device = torch.device(\"cuda\" if cuda else \"cpu\")\n","    model.to(device)\n","    \n","    print(model)\n","    \n","    max_valid_acc = 0\n","    max_test_acc = 0\n","    k = 4\n","\n","    avg_val_acc = 0\n","    for i in range(k):\n","        # start with new opt, criterion and scheduler for each fold\n","        opt = optim.Adam(model.parameters(), lr = 0.001)\n","        criterion = nn.CrossEntropyLoss()\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=3, threshold=0.04, threshold_mode='abs', verbose=True)\n","\n","        # reset weight\n","        model.apply(reset_weights) \n","\n","\n","        print(f'Running {i}th cross validation.......')\n","        train_loader, val_loader = get_loaders(k, i)\n","        for n in range(n_epochs):\n","            model, train_acc, train_loss = train_model(train_loader, model, opt, criterion, device)\n","            valid_acc = test_model(val_loader, model, opt, criterion, device)\n","            # test_acc = test_model(test_loader, model, opt, criterion, device)\n","\n","            if valid_acc > max_valid_acc:\n","                max_valid_acc = valid_acc\n","                # max_test_acc = test_acc\n","            \n","            scheduler.step(valid_acc)\n","            if n == n_epochs-1:\n","                avg_val_acc += valid_acc\n","\n","            # Print log of accuracy and loss\n","            print(\"Fold: \"+str(i) + \", Epoch: \"+str(n)+\", Training Accuracy: \"+str(train_acc)+\", Training loss:\"+str(train_loss)+ \", Validation accuracy:\"+str(valid_acc))\n","\n","    avg_val_acc /= k\n","    print(\"The avg acc is: \" + str(avg_val_acc))\n","    # if avg_val_acc >= best_avg_acc:\n","    save_path = os.path.join(\"gdrive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"saved_models\", \"AESDD\", \"yifan\", f\"run{run_num}\", f\"fold{i}_model{model_name}_embed{emb_size}_hsize{hidden_size}_numlstm{num_lstm}.pth\")\n","    torch.save({'model_id': id,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': opt.state_dict(),\n","                'scheduler_state_dict' : scheduler.state_dict(),\n","                'avg_val_acc': avg_val_acc,\n","                }, save_path)\n","    \n","    total_time = (time.time() - start_time)/60\n","\n","# for model_name in model_list:\n","#     for bidirectionality in bidirectional_list:\n","#         for emb_size in emb_size_list:\n","#             for num_lstm in num_lstm_layers_list:\n","#                 for hidden_size in hidden_size_list:\n","#                         model_id += 1\n","#                         start_time = time.time()\n","                        \n","#                         #Log Metadata\n","#                         metadata = model_name + ',' + str(bidirectionality) + ',' + str(emb_size) + ',' + str(num_lstm) + ',' + str(hidden_size)\n","#                         print(metadata)\n","\n","#                         #initialize model\n","#                         if model_name == '1CNN':\n","#                             model = ICASSP1CNN(emb_size, hidden_size, num_lstm, bidirectionality)\n","#                         elif model_name == '2CNN':\n","#                             model = ICASSP2CNN(emb_size, hidden_size, num_lstm, bidirectionality)\n","#                         elif model_name == '3CNN':\n","#                             model = ICASSP3CNN(emb_size, hidden_size, num_lstm, bidirectionality)        \n"," \n","#                         device = torch.device(\"cuda\" if cuda else \"cpu\")\n","#                         model.to(device)\n","                        \n","#                         print(model)\n","                        \n","#                         max_valid_acc = 0\n","#                         max_test_acc = 0\n","#                         k = 4\n","\n","#                         avg_val_acc = 0\n","#                         for i in range(k):\n","#                           # start with new opt, criterion and scheduler for each fold\n","#                           opt = optim.Adam(model.parameters(), lr = 0.001)\n","#                           criterion = nn.CrossEntropyLoss()\n","#                           scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=3, threshold=0.04, threshold_mode='abs', verbose=True)\n","\n","#                           # reset weight\n","#                           model.apply(reset_weights) \n","\n","\n","#                           print(f'Running {i}th cross validation.......')\n","#                           train_loader, val_loader = get_loaders(k, i)\n","#                           for n in range(n_epochs):\n","#                               model, train_acc, train_loss = train_model(train_loader, model, opt, criterion, device)\n","#                               valid_acc = test_model(val_loader, model, opt, criterion, device)\n","#                               # test_acc = test_model(test_loader, model, opt, criterion, device)\n","\n","#                               if valid_acc > max_valid_acc:\n","#                                   max_valid_acc = valid_acc\n","#                                   # max_test_acc = test_acc\n","                              \n","#                               scheduler.step(valid_acc)\n","#                               if n == n_epochs-1:\n","#                                 avg_val_acc += valid_acc\n","\n","#                               # Print log of accuracy and loss\n","#                               print(\"Fold: \"+str(i) + \", Epoch: \"+str(n)+\", Training Accuracy: \"+str(train_acc)+\", Training loss:\"+str(train_loss)+ \", Validation accuracy:\"+str(valid_acc))\n","\n","#                         avg_val_acc /= k\n","#                         print(\"The avg acc is: \" + str(avg_val_acc))\n","#                         if avg_val_acc >= best_avg_acc:\n","#                           save_path = os.path.join(\"gdrive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"saved_models\", \"AESDD\", \"yifan\", f\"run{run_num}\", f\"fold{i}_model{model_name}_embed{emb_size}_hsize{hidden_size}_numlstm{num_lstm}.pth\")\n","#                           torch.save({\n","#                                       'model_id': id,\n","#                                       'model_state_dict': model.state_dict(),\n","#                                       'optimizer_state_dict': opt.state_dict(),\n","#                                       'scheduler_state_dict' : scheduler.state_dict(),\n","#                                       }, save_path)\n","                        \n","#                         total_time = (time.time() - start_time)/60\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CU9w5QE1CipB"},"outputs":[],"source":["def get_test_acc(model, test_loader):\n","    # checkpoint = torch.load(model_pth)\n","    # model.load_state_dict(checkpoint[\"model_state_dict\"])\n","\n","    model.eval()\n","    test_num_correct = 0\n","    total = 0\n","    for batch_num, (x, lengths, y) in enumerate(test_loader):\n","        x = x.to(device)\n","        y = y.long().to(device)\n","\n","        logits = model(x, lengths)\n","        test_num_correct += (torch.argmax(logits, axis=1) == y).sum().item()\n","        total += len(y)\n","\n","    test_acc = test_num_correct / total\n","    return test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dt4N_ml4CjP8","outputId":"c5e00f91-f968-4694-f597-6504317a9ec7"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5625\n"]}],"source":["# test dataloader\n","test_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in test_list_paths]\n","test_dset = MyDataset(test_list_paths, test_list_labels)\n","test_args = dict(shuffle=False, batch_size=32, num_workers=2, collate_fn=pad_collate, drop_last=True)\n","test_loader = DataLoader(test_dset, **test_args)\n","\n","test_acc = get_test_acc(model, test_loader)\n","print(test_acc)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"embeddings_+_CNN_+_LSTM_K_Fold.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
