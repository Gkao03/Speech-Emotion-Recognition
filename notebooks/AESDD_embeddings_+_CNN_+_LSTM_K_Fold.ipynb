{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15780,"status":"ok","timestamp":1638350966166,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"HJkp8FiNBW2D","outputId":"bdc18a74-9056-462b-855d-401253efa9b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5469,"status":"ok","timestamp":1638350971631,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"x5pGdNEtDO1j","outputId":"7d84399a-0334-4f56-b985-cb64a571783a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting allosaurus\n","  Downloading allosaurus-1.0.2-py3-none-any.whl (52 kB)\n","\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 40 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 162 kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.4.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.10.0+cu111)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.5.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.19.5)\n","Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.2.2)\n","Collecting panphon\n","  Downloading panphon-0.19-py2.py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 544 kB/s \n","\u001b[?25hCollecting unicodecsv\n","  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (2019.12.20)\n","Collecting munkres\n","  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (57.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (3.13)\n","Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (0.51.2)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (1.15.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy->allosaurus) (0.34.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->allosaurus) (3.10.0.2)\n","Building wheels for collected packages: unicodecsv\n","  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10765 sha256=2b5e47e6d62c5e79fade7973f8f901aaeeacddf2b093c5c8df6ae741279ace3b\n","  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n","Successfully built unicodecsv\n","Installing collected packages: unicodecsv, munkres, panphon, allosaurus\n","Successfully installed allosaurus-1.0.2 munkres-1.1.4 panphon-0.19 unicodecsv-0.14.1\n"]}],"source":["!pip install allosaurus"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7389,"status":"ok","timestamp":1638350979016,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"-k-7oiYQ4Ivx"},"outputs":[],"source":["#These libraries help to interact with the operating system and the runtime environment respectively\n","import os\n","import sys\n","import pickle\n","\n","#Model/Training related libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","\n","#Dataloader libraries\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Transforms and datasets\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dset\n","\n","import time\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pandas as pd\n","from tqdm import tqdm\n","import random\n","from sklearn.model_selection import KFold\n","import wave\n","import librosa\n","\n","# Allosaurus\n","from allosaurus.audio import read_audio\n","from allosaurus.app import read_recognizer\n","from allosaurus.am.utils import *"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1671,"status":"ok","timestamp":1638249132576,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"QLLLGJLoMQR9"},"outputs":[],"source":["# pth = '/content/gdrive/MyDrive/18786 IDL/IDL Project/data/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_impro01/Ses01F_impro01_F000.wav'\n","pth = 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/fear/f02 (1).wav'\n","wf = wave.open(pth)  # will throw error for AESDD files\n","# audio, sr = librosa.load(pth, sr=None)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4870,"status":"ok","timestamp":1638350983880,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"scRMPhAs_9ig","outputId":"cea8970a-b6d7-4612-d5a9-21a83a7b8576"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading model  latest\n","from:  https://github.com/xinjli/allosaurus/releases/download/v1.0/latest.tar.gz\n","to:    /usr/local/lib/python3.7/dist-packages/allosaurus/pretrained\n","please wait...\n"]}],"source":["recognizer = read_recognizer()"]},{"cell_type":"markdown","metadata":{"id":"WhMGUryguaql"},"source":["# IEMOCAP"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7__m5ma3Qzf","outputId":"8311d0c3-d43c-4b6f-b178-6a71f5638f07"},"outputs":[{"data":{"text/plain":["(10039, 7)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"/content/gdrive/MyDrive/iemocap_full_dataset.csv\")\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df[df.emotion != 'xxx']  # only keep data that has emotion label\n","# only keep 'neu', 'hap', 'sad', 'ang' labels\n","df = df.drop(df[~ ((df.emotion == 'neu') | (df.emotion == 'hap') | (df.emotion == 'sad') | (df.emotion == 'ang'))].index)\n","\n","df_unedit = df.copy()\n","df_unedit[\"path\"] = df_unedit[\"path\"].apply(lambda x : x.split('/')[-1])\n","all_files = list(df_unedit.path)\n","file_to_emotion = dict(zip(df_unedit.path, df_unedit.emotion))\n","\n","all_full_files = list(df.path)\n","print(df)\n","print(df_unedit)\n","print(len(file_to_emotion))\n","print(file_to_emotion)\n","print(all_full_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAPXqH0zAKHk","outputId":"fd48d623-c995-41fc-9850-feaf6797363c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","{0: 'neu', 1: 'hap', 2: 'sad', 3: 'ang'}\n","Counter({'neu': 1708, 'ang': 1103, 'sad': 1084, 'hap': 595})\n"]}],"source":["from collections import Counter\n","\n","# get unique emotions\n","# emotion_to_label = {'neu': 0, 'fru': 1, 'sad': 2, 'sur': 3, 'ang': 4, 'hap': 5, 'exc': 6, 'fea': 7, 'dis': 8, 'oth': 9}\n","emotion_to_label = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","label_to_emotion = {v: k for k, v in emotion_to_label.items()}\n","print(emotion_to_label)\n","print(label_to_emotion)\n","\n","# counter number of class instances\n","emotion_instances_list = [v for v in file_to_emotion.values()]\n","counter = Counter(emotion_instances_list)\n","print(counter)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_to_label = {k: emotion_to_label[v] for k, v in file_to_emotion.items()}\n","print(file_to_label)"]},{"cell_type":"markdown","metadata":{"id":"kdpxTu1sEqoz"},"source":["# AESDD PreProcessing"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1638350983880,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"mZwVTTTzFAxt"},"outputs":[],"source":["data_dir = os.path.join(\"gdrive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"data\", \"AESDD\", \"AESDD_mod\")\n","mapping = {'happiness': 0, 'sadness': 1, 'anger': 2, 'disgust': 3, 'fear': 4}\n","mapping2 = {'h': 0, 's': 1, 'a': 2, 'd': 3, 'f': 4}"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1638350983881,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"qc5TzYvMEySe"},"outputs":[],"source":["def parse_data(data_dir):\n","    file_paths = []  # full file paths from drive to wav file\n","    labels = []  # corresponding labels\n","\n","    for root, directories, filenames in os.walk(data_dir):\n","            for filename in filenames:\n","                if filename.endswith('.wav') and filename[0] != '.':\n","                    abbrev = filename[0]\n","                    label = mapping2[abbrev]\n","                    path = os.path.join(root, filename)\n","\n","                    file_paths.append(path)\n","                    labels.append(label)\n","\n","    return file_paths, labels"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5823,"status":"ok","timestamp":1638350989696,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"LR1SKS20I3-n"},"outputs":[],"source":["file_paths, labels = parse_data(data_dir)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1638350989697,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"wIpa4y-IvqXm","outputId":"bf40043f-0727-4fb4-a731-8f8a42b67476"},"outputs":[{"name":"stdout","output_type":"stream","text":["['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d07 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d17 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d03 (5)b.wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d11 (6).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d06 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d20 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d05 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d04 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d13 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d16 (2).wav']\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"]}],"source":["print(file_paths[:10])\n","print(labels[:10])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1638350989697,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"fxcat-1_vvB_"},"outputs":[],"source":["combined = list(zip(file_paths, labels))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1638350989697,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"QdiUKI6Tv-K5"},"outputs":[],"source":["random.shuffle(combined)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1638350989698,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"aUqygPe9wA04"},"outputs":[],"source":["file_paths = [pair[0] for pair in combined]\n","labels = [pair[1] for pair in combined] "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1638350989698,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"cWMSm1zdwN6h","outputId":"f249a996-b248-4cf2-eebe-b62b0c08136f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/anger/a17 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/happiness/h20 (6).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d07 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/happiness/h12 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d15 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/happiness/h13 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/happiness/h16 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/disgust/d10 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/happiness/h19 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD_mod/fear/f15 (6).wav']\n","[2, 0, 3, 0, 3, 0, 0, 3, 0, 4]\n"]}],"source":["print(file_paths[:10])\n","print(labels[:10])"]},{"cell_type":"markdown","metadata":{"id":"PHI8A3dbNyGp"},"source":["# K fold (testing)"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1638208335172,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"sDB-n1tjNxx9"},"outputs":[],"source":["kf = KFold(n_splits=5, shuffle=False)  # already shuffled above"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1638208339236,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"-kUgdw-A0MXW"},"outputs":[],"source":["test_data = []  # reserved for test data splits"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1638210283783,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"Ay7JgsciN_WK","outputId":"039132bb-836e-4a38-a234-48eb2d785e61"},"outputs":[{"name":"stdout","output_type":"stream","text":["['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h09 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f07 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h12 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d12 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s11 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d03 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s03 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s02 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h14 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h14 (4).wav']\n","[0, 4, 0, 3, 1, 3, 1, 1, 0, 0]\n","['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f15 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f05 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a07 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a20 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f11 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d07 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a01 (6).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a02 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h05 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s11 (4).wav']\n","[4, 4, 2, 2, 4, 3, 2, 2, 0, 1]\n","['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f12 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h01 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h17 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d13 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f19 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s02 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d13 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d14 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d07 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s13 (2).wav']\n","[4, 0, 0, 3, 4, 1, 3, 3, 3, 1]\n","['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a09 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f06 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d03 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s14 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s13 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/sadness/s18 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a02 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f09 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f08 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f12 (01).wav']\n","[2, 4, 3, 1, 1, 1, 2, 4, 4, 4]\n","['gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f04 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d04 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f03 (2).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f15 (1).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h04 (4).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/fear/f12 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a02 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/happiness/h02 (3).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a11 (5).wav', 'gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/anger/a14 (5).wav']\n","[4, 3, 4, 4, 0, 4, 2, 0, 2, 2]\n"]}],"source":["for i, (train_index, test_index) in enumerate(kf.split(file_paths)):\n","    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","    train_index = list(train_index)\n","    test_index = list(test_index)\n","    xtrain, ytrain = [], []\n","    xtest_all, ytest_all = [], []\n","\n","    for idx in train_index:\n","        xtrain.append(file_paths[idx])\n","        ytrain.append(labels[idx])\n","\n","    for idx in test_index:\n","        xtest_all.append(file_paths[idx])\n","        ytest_all.append(labels[idx])\n","\n","    mid = len(xtest_all) // 2\n","    xval = xtest_all[:mid]\n","    yval = ytest_all[:mid]\n","\n","    xtest = xtest_all[mid:]\n","    ytest = ytest_all[mid:]\n","\n","    test_data.append((xtest, ytest))\n","    \n","    print(xval[-10:])\n","    print(yval[-10:])\n","    \n","    assert(len(xtrain) + len(xval) + len(xtest) == len(file_paths))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385,"status":"ok","timestamp":1638206699538,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"aVfYDUh5RM10","outputId":"ef3281e2-3712-481d-b74b-f8a132cde8de"},"outputs":[{"name":"stdout","output_type":"stream","text":["gdrive/MyDrive/18786 IDL/IDL Project/data/AESDD/AESDD/disgust/d19 (3).wav\n","3\n"]}],"source":["print(xtrain[400])\n","print(ytrain[400])"]},{"cell_type":"markdown","metadata":{"id":"SYKc39naSj6D"},"source":["# weight reset"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1638350989699,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"MsVO53NBSjbV"},"outputs":[],"source":["def reset_weights(m):\n","    '''\n","        Try resetting model weights to avoid\n","        weight leakage.\n","    '''\n","    for layer in m.children():\n","        if hasattr(layer, 'reset_parameters'):\n","            print(f'Reset trainable parameters of layer = {layer}')\n","            layer.reset_parameters()"]},{"cell_type":"markdown","metadata":{"id":"GYhrBINEEwv2"},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1638350989699,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"c3di3Mr5rRG4"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, file_list, target_list):\n","        \n","        self.file_list = file_list\n","        self.target_list = target_list\n","        self.num_classes = len(list(set(target_list)))\n","\n","        self.x = file_list\n","        self.y = target_list\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        filepath = self.file_list[index]\n","        x = torch.tensor(recognizer.pm.compute(read_audio(filepath)))\n","        x = x.detach()\n","        x_len = torch.tensor(np.array([x.shape[0]], dtype=np.int32))\n","        x_len = x_len.detach()\n","        y = torch.Tensor([self.target_list[index]])\n","        abbrev = filepath.split('/')[-1][0]\n","        assert(mapping2[abbrev] == self.target_list[index])\n","        return x, x_len, y"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1638350989699,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"AK8jRp6isDN2"},"outputs":[],"source":["# collate function\n","def pad_collate(batch):\n","    # print(\"inside collate\")\n","    # batch looks like [(x0, xlen0, y0), (x4, xlen4, y4), (x2, xlen2, y2)... ]\n","    feats = [sample[0] for sample in batch]\n","    feat_lens = [sample[1] for sample in batch]\n","    target_list = torch.Tensor([sample[2] for sample in batch])\n","\n","    feats = pad_sequence(feats, batch_first=True, padding_value=0) # batch, features, len\n","    feat_lens = pad_sequence(feat_lens, batch_first=True, padding_value=0).squeeze()\n","    idx = torch.argsort(feat_lens, descending=True) # sorting the input in descending order as required by the lstms in AM.\n","\n","    # reorder\n","    # tensor_batch_feat = feats[idx]\n","    # tensor_batch_feat_len = feat_lens[idx]\n","    targets = target_list[idx]\n","    tensor_batch_feat, tensor_batch_feat_len = move_to_tensor([feats[idx], feat_lens[idx]], device_id=-1) # converting to the required tensors\n","\n","    # Features\n","    output_tensor, input_lengths = recognizer.am(tensor_batch_feat, tensor_batch_feat_len, return_lstm=True) # output_shape: [len,batch,features]\n","    output_tensor = output_tensor.detach()\n","    input_lengths = input_lengths.detach()\n","    \n","    return output_tensor, input_lengths, targets"]},{"cell_type":"markdown","metadata":{"id":"UbOBzciy8s4I"},"source":["# IEMOCAP data preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwpZTdgHsBjN"},"outputs":[],"source":["all_file_paths = [os.path.join(\"gdrive\", \"MyDrive\", \"data\", \"IEMOCAP_full_release\", file_path) for file_path in all_full_files]\n","total_instances = len(all_file_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KudBSi9kjz-R"},"outputs":[],"source":["!tar -xf archive.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abbkoaDuscWe","outputId":"419b43cf-5d00-4b60-fe07-319878b7f367"},"outputs":[{"name":"stdout","output_type":"stream","text":["number training instances: 3592\n","number validation instances: 449\n","number test instances: 449\n"]}],"source":["num_train = round(0.8 * total_instances)\n","num_test_all = total_instances - num_train\n","num_val = round(0.5 * num_test_all)\n","num_test = num_test_all - num_val\n","\n","print(\"number training instances:\", str(num_train))\n","print(\"number validation instances:\", str(num_val))\n","print(\"number test instances:\", str(num_test))\n","assert(num_train + num_val + num_test == total_instances)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw3Mh8bpsYc9"},"outputs":[],"source":["# shuffle data\n","import random\n","random.seed(2021)\n","\n","shuffled_data_paths = random.sample(all_file_paths, k=total_instances)\n","# train_list_paths = shuffled_data_paths[:num_train]\n","# testall_list_paths = shuffled_data_paths[num_train:]\n","# val_list_paths = testall_list_paths[:num_val]\n","# test_list_paths = testall_list_paths[num_test:]\n","\n","# assert(len(train_list_paths) + len(val_list_paths) + len(test_list_paths) == total_instances)\n","\n","# train, val, test variables:\n","# train_list_paths\n","# val_list_paths\n","# test_list_paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6L5WOufrx7i"},"outputs":[],"source":["# get corresponding labels for data\n","train_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in train_list_paths]\n","val_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in val_list_paths]\n","test_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in test_list_paths]\n","\n","assert(len(train_list_labels) == len(train_list_paths))\n","assert(len(val_list_labels) == len(val_list_paths))\n","assert(len(test_list_labels) == len(test_list_paths))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_V9_bpjrxg8"},"outputs":[],"source":["# train dataloader\n","train_dset = MyDataset(train_list_paths, train_list_labels)\n","train_args = dict(shuffle=True, batch_size=64, num_workers=2, collate_fn=pad_collate, drop_last=True)  # change to num_workers=4 on diff platform\n","train_loader = DataLoader(train_dset, **train_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ktxCl_ZftaMl"},"outputs":[],"source":["# val dataloader\n","val_dset = MyDataset(val_list_paths, val_list_labels)\n","val_args = dict(shuffle=False, batch_size=64, num_workers=2, collate_fn=pad_collate, drop_last=True)\n","val_loader = DataLoader(val_dset, **val_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"B9kBfewtsiFR","outputId":"e911a139-4c87-4d65-cb90-6e5570ade4aa"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-812a6f8b4fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"]}],"source":["test_batch = next(iter(train_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7zOqRNnsiSY","outputId":"0c325018-7216-4c7a-f53c-d968a0e00be0"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([473, 64, 640])\n","tensor([473, 350, 316, 307, 305, 300, 265, 263, 240, 240, 235, 233, 224, 209,\n","        203, 191, 189, 184, 181, 178, 166, 165, 161, 159, 156, 149, 145, 143,\n","        142, 140, 129, 128, 125, 125, 122, 121, 117, 109, 108, 108, 106, 105,\n","        105, 101, 100,  99,  95,  93,  91,  86,  85,  77,  70,  70,  66,  61,\n","         56,  56,  55,  55,  46,  46,  44,  44], dtype=torch.int32)\n","tensor([3., 0., 2., 0., 3., 1., 2., 2., 0., 1., 0., 3., 3., 2., 0., 0., 0., 0.,\n","        2., 3., 2., 1., 0., 3., 2., 2., 1., 0., 1., 2., 3., 3., 1., 0., 2., 0.,\n","        3., 2., 2., 0., 3., 3., 0., 3., 2., 3., 0., 1., 3., 3., 0., 1., 2., 0.,\n","        0., 0., 0., 0., 0., 2., 0., 0., 3., 0.])\n"]}],"source":["x, x_len, y = test_batch\n","print(x.shape)  # seq_len, batch_size, input_size\n","print(x_len)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"6TfpVcv48QJQ"},"source":["##Model"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":174,"status":"ok","timestamp":1638350990048,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"h8ZIiO_l6-i4"},"outputs":[],"source":["class ICASSP3CNN(nn.Module):\n","    def __init__(self, embed_size=640, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n","        super().__init__()\n","        self.n_layers = num_lstm_layers \n","        self.hidden = hidden_size\n","        self.bidirectional = bidirectional\n","        \n","        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n","        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n","        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n","\n","        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n","\n","        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n","                            hidden_size = hidden_size, \n","                            num_layers = num_lstm_layers, \n","                            bidirectional = bidirectional)\n","\n","        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n","                                out_features = label_size)\n","\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        padded_x: (B,T) padded LongTensor\n","        \"\"\"\n","        \n","        batch_size = x.shape[0]\n","        \n","        x = x.permute(1, 2, 0)    # (seq_len, batch_size, input_size) -> (batch_size, input_size, seq_len)\n","      \n","        cnn_output = torch.cat([self.cnn(x), self.cnn2(x), self.cnn3(x)], dim=1)\n","\n","        input = F.relu(self.batchnorm(cnn_output))\n","\n","        input = input.transpose(1,2)\n","\n","        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits\n","        \n","        \n","class ICASSP2CNN(nn.Module):\n","    def __init__(self, embed_size=640, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n","        super().__init__()\n","        self.n_layers = num_lstm_layers \n","        self.hidden = hidden_size\n","        self.bidirectional = bidirectional\n","\n","        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n","        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n","\n","        self.batchnorm = nn.BatchNorm1d(2 * embed_size)\n","\n","        self.lstm = nn.LSTM(input_size = 2 * embed_size, \n","                            hidden_size = hidden_size, \n","                            num_layers = num_lstm_layers, \n","                            bidirectional = bidirectional)\n","\n","        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n","                                out_features = label_size)\n","\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        padded_x: (B,T) padded LongTensor\n","        \"\"\"\n","        \n","        batch_size = x.shape[0]\n","        # torch.Size([468, 64, 640])\n","        x = x.permute(1, 2, 0)    # (seq_len, batch_size, input_size) -> (batch_size, input_size, seq_len)\n","\n","        cnn_output = torch.cat([self.cnn(x), self.cnn2(x)], dim=1)\n","\n","        input = F.relu(self.batchnorm(cnn_output))\n","\n","        input = input.transpose(1,2)\n","\n","        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits\n","    \n","\n","class ICASSP1CNN(nn.Module):\n","    def __init__(self, embed_size=640, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n","        super().__init__()\n","        self.n_layers = num_lstm_layers \n","        self.hidden = hidden_size\n","        self.bidirectional = bidirectional\n","\n","        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n","\n","        self.batchnorm = nn.BatchNorm1d(embed_size)\n","\n","        self.lstm = nn.LSTM(input_size = embed_size, \n","                            hidden_size = hidden_size, \n","                            num_layers = num_lstm_layers, \n","                            bidirectional = bidirectional)\n","\n","        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n","                                out_features = label_size)\n","\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        padded_x: (B,T) padded LongTensor\n","        \"\"\"\n","        batch_size = x.shape[0]\n","     \n","        x = x.permute(1, 2, 0)    # (seq_len, batch_size, input_size) -> (batch_size, input_size, seq_len)\n","\n","        cnn_output = self.cnn(x)\n","\n","        input = F.relu(self.batchnorm(cnn_output))\n","\n","        input = input.transpose(1,2)\n","\n","        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits\n","        "]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1638251504265,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"kOU_aZsew3ZI","outputId":"3c17be38-7670-4170-b306-54a35f41422c"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([468, 64, 640])\n","torch.Size([640, 468, 64])\n"]}],"source":["x = torch.zeros([468, 64, 640])\n","print(x.shape)\n","x = x.permute(2, 0, 1) \n","print(x.shape)"]},{"cell_type":"markdown","metadata":{"id":"KZAxmuMs8jAa"},"source":["## Training"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1638350991767,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"eMCs_r1t8g5O"},"outputs":[],"source":["def train_language_model(train_loader_LM, model, opt, criterion, device):\n","\n","    loss_accum = 0.0\n","    batch_cnt = 0\n","\n","    model.train()\n","    start_time = time.time()\n","    for batch, (x, lengths, y) in enumerate(train_loader_LM):\n","\n","        x = x.to(device)\n","        #lengths = lengths.to(device)\n","        y = y.long().to(device)\n","        opt.zero_grad()\n","\n","        logits = model(x, lengths)\n","        \n","        loss = criterion(logits.permute(0,2,1), y)\n","        loss_score = loss.cpu().item()\n","\n","        loss_accum += loss_score\n","        batch_cnt += 1\n","        loss.backward()\n","        opt.step()      \n","\n","    NLL = loss_accum / batch_cnt\n","        \n","    return model, NLL\n","\n","\n","def train_model(train_loader, model, opt, criterion, device):\n","\n","    loss_accum = 0.0\n","    batch_cnt = 0\n","\n","    acc_cnt = 0     #count correct predictions\n","    err_cnt = 0     #count incorrect predictions\n","\n","    model.train()\n","    start_time = time.time()\n","    for batch, (x, lengths, y) in enumerate(train_loader):\n","        x = x.to(device)\n","        #lengths = lengths.to(device)\n","        y = y.long().to(device)\n","        opt.zero_grad()\n","\n","        logits = model(x, lengths)\n","\n","        loss = criterion(logits, y)\n","        loss_score = loss.cpu().item()\n","\n","        loss_accum += loss_score\n","        batch_cnt += 1\n","        loss.backward()\n","        opt.step()\n","\n","        #model outputs\n","        out_val, out_indices = torch.max(logits, dim=1)\n","        tar_indices = y\n","\n","        for i in range(len(out_indices)):\n","            if out_indices[i] == tar_indices[i]:\n","                acc_cnt += 1\n","            else:\n","                err_cnt += 1\n","                     \n","    training_accuracy =  acc_cnt/(err_cnt+acc_cnt) \n","    training_loss = loss_accum / batch_cnt\n","        \n","    return model, training_accuracy, training_loss\n","\n","\n","def test_model(loader, model, opt, criterion, device):\n","    model.eval()\n","    acc_cnt = 0\n","    err_cnt = 0\n","\n","    for x, lengths, y in loader:\n","        \n","        x = x.to(device)\n","        y = y.long().to(device)\n","        \n","        logits = model(x, lengths)\n","\n","        out_val, out_indices = torch.max(logits, dim=1)\n","        tar_indices = y\n","\n","        for i in range(len(out_indices)):\n","            if out_indices[i] == tar_indices[i]:\n","                acc_cnt += 1\n","            else:\n","                err_cnt += 1\n","\n","    current_acc = acc_cnt/(err_cnt+acc_cnt)\n","    \n","    return current_acc"]},{"cell_type":"markdown","metadata":{"id":"aAOlPe9g80N_"},"source":["## Main runner"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":129,"status":"ok","timestamp":1638350994419,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"oXwYXAdJ2DLN"},"outputs":[],"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","# model = ICASSP1CNN()\n","# checkpoint = torch.load(\"/content/gdrive/MyDrive/model/model.pt\")\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","# opt.load_state_dict(checkpoint['optimizer_state_dict'])\n","# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","# criterion = nn.CrossEntropyLoss()\n","# model.to(device)\n","# opt = optim.Adam(model.parameters(), lr = 0.001)\n","# criterion = nn.CrossEntropyLoss()\n","# device = torch.device(\"cuda\" if cuda else \"cpu\")\n","# valid_acc = test_model(val_loader, model, opt, criterion, device)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1638350997784,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"xTesBSsb4jGu"},"outputs":[],"source":["batch_size = 8\n","lr = 0.001\n","weight_decay = 5e-5"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":145,"status":"ok","timestamp":1638350999079,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"uyqFd1hbFcQm"},"outputs":[],"source":["kf = KFold(n_splits=5, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxQKSePGstCE"},"outputs":[],"source":["def get_k_folder(k, i):  # deprecated in AESDD\n","  n = num_train+num_val\n","  train_val_list_paths = shuffled_data_paths[:n]\n","  fold_size = (n + k-1) // k\n","\n","  train_list_paths = train_val_list_paths[:i*fold_size] + train_val_list_paths[i*fold_size+fold_size:n]\n","  val_list_paths = train_val_list_paths[i*fold_size:min(i*fold_size+fold_size, n)]\n","\n","  return train_list_paths, val_list_paths"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1638351001121,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"SkU-j5F9ssjF"},"outputs":[],"source":["def get_loaders(xtrain, ytrain, xval, yval):\n","  # train dataloader\n","  train_dset = MyDataset(xtrain, ytrain)\n","  train_args = dict(shuffle=True, batch_size=batch_size, num_workers=1, collate_fn=pad_collate, drop_last=True)  # change to num_workers=4 on diff platform\n","  train_loader = DataLoader(train_dset, **train_args)\n","\n","  # val dataloader\n","  val_dset = MyDataset(xval, yval)\n","  val_args = dict(shuffle=False, batch_size=batch_size, num_workers=1, collate_fn=pad_collate, drop_last=True)\n","  val_loader = DataLoader(val_dset, **val_args)\n","\n","  return train_loader, val_loader"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17731270,"status":"ok","timestamp":1638368736370,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"FyMP1HFp8y6C","outputId":"e5617bb2-a905-493b-d07e-1c93e433a9bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["3CNN,False,640,3,128\n","ICASSP3CNN(\n","  (cnn): Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","  (cnn2): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","  (cnn3): Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","  (batchnorm): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lstm): LSTM(1920, 128, num_layers=3)\n","  (linear): Linear(in_features=128, out_features=31, bias=True)\n",")\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 1th cross validation.......\n","SAVING CHECKPOINT\n","Epoch: 0, Training Accuracy: 0.175, Training loss:1.9142715017000833, Validation accuracy:0.16071428571428573\n","SAVING CHECKPOINT\n","Epoch: 1, Training Accuracy: 0.17916666666666667, Training loss:1.644492256641388, Validation accuracy:0.21428571428571427\n","Epoch: 2, Training Accuracy: 0.21041666666666667, Training loss:1.6277809182802836, Validation accuracy:0.17857142857142858\n","Epoch     4: reducing learning rate of group 0 to 5.0000e-04.\n","Epoch: 3, Training Accuracy: 0.21041666666666667, Training loss:1.6276097516218822, Validation accuracy:0.17857142857142858\n","SAVING CHECKPOINT\n","Epoch: 4, Training Accuracy: 0.2375, Training loss:1.6072467883427939, Validation accuracy:0.26785714285714285\n","SAVING CHECKPOINT\n","Epoch: 5, Training Accuracy: 0.24791666666666667, Training loss:1.5850296398003896, Validation accuracy:0.26785714285714285\n","Epoch     7: reducing learning rate of group 0 to 2.5000e-04.\n","Epoch: 6, Training Accuracy: 0.30625, Training loss:1.5488272448380789, Validation accuracy:0.19642857142857142\n","Epoch: 7, Training Accuracy: 0.30625, Training loss:1.4881567319234212, Validation accuracy:0.23214285714285715\n","Epoch     9: reducing learning rate of group 0 to 1.2500e-04.\n","Epoch: 8, Training Accuracy: 0.2875, Training loss:1.4973966697851817, Validation accuracy:0.17857142857142858\n","SAVING CHECKPOINT\n","Epoch: 9, Training Accuracy: 0.3375, Training loss:1.4480445663134256, Validation accuracy:0.3392857142857143\n","SAVING CHECKPOINT\n","Epoch: 10, Training Accuracy: 0.3645833333333333, Training loss:1.4084954778353374, Validation accuracy:0.3392857142857143\n","Epoch    12: reducing learning rate of group 0 to 6.2500e-05.\n","Epoch: 11, Training Accuracy: 0.37083333333333335, Training loss:1.3949973652760188, Validation accuracy:0.32142857142857145\n","SAVING CHECKPOINT\n","Epoch: 12, Training Accuracy: 0.38958333333333334, Training loss:1.3699739495913188, Validation accuracy:0.3392857142857143\n","Epoch    14: reducing learning rate of group 0 to 3.1250e-05.\n","Epoch: 13, Training Accuracy: 0.39791666666666664, Training loss:1.3628759940465291, Validation accuracy:0.32142857142857145\n","Epoch: 14, Training Accuracy: 0.4, Training loss:1.350691670179367, Validation accuracy:0.30357142857142855\n","Epoch    16: reducing learning rate of group 0 to 1.5625e-05.\n","Epoch: 15, Training Accuracy: 0.3854166666666667, Training loss:1.3395370145638783, Validation accuracy:0.32142857142857145\n","Epoch: 16, Training Accuracy: 0.3958333333333333, Training loss:1.3278667837381364, Validation accuracy:0.32142857142857145\n","Epoch    18: reducing learning rate of group 0 to 7.8125e-06.\n","Epoch: 17, Training Accuracy: 0.40208333333333335, Training loss:1.3303319354852041, Validation accuracy:0.26785714285714285\n","Epoch: 18, Training Accuracy: 0.4125, Training loss:1.3178384353717167, Validation accuracy:0.32142857142857145\n","Epoch    20: reducing learning rate of group 0 to 3.9063e-06.\n","Epoch: 19, Training Accuracy: 0.4166666666666667, Training loss:1.310187784830729, Validation accuracy:0.32142857142857145\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 2th cross validation.......\n","SAVING CHECKPOINT\n","Epoch: 0, Training Accuracy: 0.19791666666666666, Training loss:1.9442226866881052, Validation accuracy:0.16071428571428573\n","SAVING CHECKPOINT\n","Epoch: 1, Training Accuracy: 0.20416666666666666, Training loss:1.6471807380517325, Validation accuracy:0.17857142857142858\n","SAVING CHECKPOINT\n","Epoch     3: reducing learning rate of group 0 to 5.0000e-04.\n","Epoch: 2, Training Accuracy: 0.15833333333333333, Training loss:1.6387372155984243, Validation accuracy:0.17857142857142858\n","Epoch: 3, Training Accuracy: 0.21666666666666667, Training loss:1.617848159869512, Validation accuracy:0.14285714285714285\n","SAVING CHECKPOINT\n","Epoch     5: reducing learning rate of group 0 to 2.5000e-04.\n","Epoch: 4, Training Accuracy: 0.21875, Training loss:1.6214551309744516, Validation accuracy:0.17857142857142858\n","SAVING CHECKPOINT\n","Epoch: 5, Training Accuracy: 0.22708333333333333, Training loss:1.6185257275899252, Validation accuracy:0.19642857142857142\n","Epoch     7: reducing learning rate of group 0 to 1.2500e-04.\n","Epoch: 6, Training Accuracy: 0.2125, Training loss:1.6100785215695699, Validation accuracy:0.17857142857142858\n","SAVING CHECKPOINT\n","Epoch: 7, Training Accuracy: 0.25625, Training loss:1.5960429807504017, Validation accuracy:0.19642857142857142\n","Epoch     9: reducing learning rate of group 0 to 6.2500e-05.\n","Epoch: 8, Training Accuracy: 0.31875, Training loss:1.559848024447759, Validation accuracy:0.16071428571428573\n","Epoch: 9, Training Accuracy: 0.31875, Training loss:1.524365484714508, Validation accuracy:0.17857142857142858\n","Epoch    11: reducing learning rate of group 0 to 3.1250e-05.\n","Epoch: 10, Training Accuracy: 0.325, Training loss:1.4920163214206696, Validation accuracy:0.14285714285714285\n","Epoch: 11, Training Accuracy: 0.33125, Training loss:1.4623830676078797, Validation accuracy:0.17857142857142858\n","Epoch    13: reducing learning rate of group 0 to 1.5625e-05.\n","Epoch: 12, Training Accuracy: 0.3375, Training loss:1.4310137430826824, Validation accuracy:0.17857142857142858\n","Epoch: 13, Training Accuracy: 0.375, Training loss:1.392864582935969, Validation accuracy:0.14285714285714285\n","Epoch    15: reducing learning rate of group 0 to 7.8125e-06.\n","Epoch: 14, Training Accuracy: 0.41458333333333336, Training loss:1.3674987773100535, Validation accuracy:0.14285714285714285\n","Epoch: 15, Training Accuracy: 0.4125, Training loss:1.349493106206258, Validation accuracy:0.14285714285714285\n","Epoch    17: reducing learning rate of group 0 to 3.9063e-06.\n","Epoch: 16, Training Accuracy: 0.4125, Training loss:1.3438327968120576, Validation accuracy:0.125\n","Epoch: 17, Training Accuracy: 0.4041666666666667, Training loss:1.338148033618927, Validation accuracy:0.125\n","Epoch    19: reducing learning rate of group 0 to 1.9531e-06.\n","Epoch: 18, Training Accuracy: 0.4166666666666667, Training loss:1.3237971107165019, Validation accuracy:0.14285714285714285\n","Epoch: 19, Training Accuracy: 0.43333333333333335, Training loss:1.3246688067913055, Validation accuracy:0.14285714285714285\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 3th cross validation.......\n","SAVING CHECKPOINT\n","Epoch: 0, Training Accuracy: 0.20416666666666666, Training loss:1.9021822849909464, Validation accuracy:0.25\n","SAVING CHECKPOINT\n","Epoch: 1, Training Accuracy: 0.18541666666666667, Training loss:1.6435766339302063, Validation accuracy:0.25\n","Epoch     3: reducing learning rate of group 0 to 5.0000e-04.\n","Epoch: 2, Training Accuracy: 0.21458333333333332, Training loss:1.6324887812137603, Validation accuracy:0.21428571428571427\n","Epoch: 3, Training Accuracy: 0.19583333333333333, Training loss:1.6367771168549856, Validation accuracy:0.14285714285714285\n","Epoch     5: reducing learning rate of group 0 to 2.5000e-04.\n","Epoch: 4, Training Accuracy: 0.18958333333333333, Training loss:1.6251563131809235, Validation accuracy:0.21428571428571427\n","Epoch: 5, Training Accuracy: 0.18333333333333332, Training loss:1.6159129599730173, Validation accuracy:0.14285714285714285\n","Epoch     7: reducing learning rate of group 0 to 1.2500e-04.\n","Epoch: 6, Training Accuracy: 0.20208333333333334, Training loss:1.6169432659943899, Validation accuracy:0.21428571428571427\n","Epoch: 7, Training Accuracy: 0.20833333333333334, Training loss:1.6125000754992167, Validation accuracy:0.14285714285714285\n","Epoch     9: reducing learning rate of group 0 to 6.2500e-05.\n","Epoch: 8, Training Accuracy: 0.19166666666666668, Training loss:1.6110496819019318, Validation accuracy:0.16071428571428573\n","Epoch: 9, Training Accuracy: 0.21458333333333332, Training loss:1.6063802103201548, Validation accuracy:0.14285714285714285\n","Epoch    11: reducing learning rate of group 0 to 3.1250e-05.\n","Epoch: 10, Training Accuracy: 0.2125, Training loss:1.602497637271881, Validation accuracy:0.14285714285714285\n","SAVING CHECKPOINT\n","Epoch: 11, Training Accuracy: 0.28541666666666665, Training loss:1.5965556760629018, Validation accuracy:0.3392857142857143\n","Epoch: 12, Training Accuracy: 0.24791666666666667, Training loss:1.5844148874282837, Validation accuracy:0.32142857142857145\n","SAVING CHECKPOINT\n","Epoch    14: reducing learning rate of group 0 to 1.5625e-05.\n","Epoch: 13, Training Accuracy: 0.30416666666666664, Training loss:1.5577074587345123, Validation accuracy:0.3392857142857143\n","SAVING CHECKPOINT\n","Epoch: 14, Training Accuracy: 0.3458333333333333, Training loss:1.5311843613783518, Validation accuracy:0.375\n","Epoch    16: reducing learning rate of group 0 to 7.8125e-06.\n","Epoch: 15, Training Accuracy: 0.33958333333333335, Training loss:1.5150379339853923, Validation accuracy:0.32142857142857145\n","Epoch: 16, Training Accuracy: 0.3645833333333333, Training loss:1.487116418282191, Validation accuracy:0.3392857142857143\n","Epoch    18: reducing learning rate of group 0 to 3.9063e-06.\n","Epoch: 17, Training Accuracy: 0.3645833333333333, Training loss:1.4770249704519907, Validation accuracy:0.32142857142857145\n","Epoch: 18, Training Accuracy: 0.3645833333333333, Training loss:1.4619991421699523, Validation accuracy:0.3392857142857143\n","Epoch    20: reducing learning rate of group 0 to 1.9531e-06.\n","Epoch: 19, Training Accuracy: 0.37916666666666665, Training loss:1.4519344051678975, Validation accuracy:0.3392857142857143\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 4th cross validation.......\n","SAVING CHECKPOINT\n","Epoch: 0, Training Accuracy: 0.20625, Training loss:1.9218717753887176, Validation accuracy:0.19642857142857142\n","Epoch: 1, Training Accuracy: 0.17708333333333334, Training loss:1.6467851479848226, Validation accuracy:0.14285714285714285\n","SAVING CHECKPOINT\n","Epoch: 2, Training Accuracy: 0.20833333333333334, Training loss:1.6367156783739725, Validation accuracy:0.2857142857142857\n","Epoch: 3, Training Accuracy: 0.20416666666666666, Training loss:1.637838496764501, Validation accuracy:0.14285714285714285\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n","Epoch: 4, Training Accuracy: 0.2125, Training loss:1.6382571578025817, Validation accuracy:0.14285714285714285\n","Epoch: 5, Training Accuracy: 0.21458333333333332, Training loss:1.6260203917821248, Validation accuracy:0.14285714285714285\n","Epoch     7: reducing learning rate of group 0 to 2.5000e-04.\n","Epoch: 6, Training Accuracy: 0.225, Training loss:1.6168590406576793, Validation accuracy:0.23214285714285715\n","SAVING CHECKPOINT\n","Epoch: 7, Training Accuracy: 0.22916666666666666, Training loss:1.6055987735589345, Validation accuracy:0.30357142857142855\n","Epoch     9: reducing learning rate of group 0 to 1.2500e-04.\n","Epoch: 8, Training Accuracy: 0.2791666666666667, Training loss:1.5783069372177123, Validation accuracy:0.10714285714285714\n","Epoch: 9, Training Accuracy: 0.28541666666666665, Training loss:1.5335307856400808, Validation accuracy:0.2857142857142857\n","Epoch    11: reducing learning rate of group 0 to 6.2500e-05.\n","Epoch: 10, Training Accuracy: 0.33125, Training loss:1.5017693201700846, Validation accuracy:0.21428571428571427\n","Epoch: 11, Training Accuracy: 0.3375, Training loss:1.4659783403078714, Validation accuracy:0.26785714285714285\n","SAVING CHECKPOINT\n","Epoch    13: reducing learning rate of group 0 to 3.1250e-05.\n","Epoch: 12, Training Accuracy: 0.35208333333333336, Training loss:1.4306403160095216, Validation accuracy:0.30357142857142855\n","Epoch: 13, Training Accuracy: 0.4083333333333333, Training loss:1.3852887531121572, Validation accuracy:0.2857142857142857\n","SAVING CHECKPOINT\n","Epoch    15: reducing learning rate of group 0 to 1.5625e-05.\n","Epoch: 14, Training Accuracy: 0.39166666666666666, Training loss:1.3622828443845114, Validation accuracy:0.30357142857142855\n","Epoch: 15, Training Accuracy: 0.4270833333333333, Training loss:1.3447042713562647, Validation accuracy:0.2857142857142857\n","Epoch    17: reducing learning rate of group 0 to 7.8125e-06.\n","Epoch: 16, Training Accuracy: 0.42916666666666664, Training loss:1.3395043551921844, Validation accuracy:0.25\n","Epoch: 17, Training Accuracy: 0.45, Training loss:1.3205895443757376, Validation accuracy:0.26785714285714285\n","Epoch    19: reducing learning rate of group 0 to 3.9063e-06.\n","Epoch: 18, Training Accuracy: 0.44166666666666665, Training loss:1.315215320388476, Validation accuracy:0.26785714285714285\n","Epoch: 19, Training Accuracy: 0.4625, Training loss:1.3086808264255523, Validation accuracy:0.2857142857142857\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(2,))\n","Reset trainable parameters of layer = Conv1d(640, 640, kernel_size=(7,), stride=(1,), padding=(3,))\n","Reset trainable parameters of layer = BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","Reset trainable parameters of layer = LSTM(1920, 128, num_layers=3)\n","Reset trainable parameters of layer = Linear(in_features=128, out_features=31, bias=True)\n","Running 5th cross validation.......\n","SAVING CHECKPOINT\n","Epoch: 0, Training Accuracy: 0.18958333333333333, Training loss:1.9096819718678792, Validation accuracy:0.21428571428571427\n","Epoch: 1, Training Accuracy: 0.18333333333333332, Training loss:1.6392115871111552, Validation accuracy:0.14285714285714285\n","SAVING CHECKPOINT\n","Epoch     3: reducing learning rate of group 0 to 5.0000e-04.\n","Epoch: 2, Training Accuracy: 0.17291666666666666, Training loss:1.6380051930745443, Validation accuracy:0.21428571428571427\n","SAVING CHECKPOINT\n","Epoch: 3, Training Accuracy: 0.18958333333333333, Training loss:1.6253481070200602, Validation accuracy:0.23214285714285715\n","Epoch     5: reducing learning rate of group 0 to 2.5000e-04.\n","Epoch: 4, Training Accuracy: 0.19166666666666668, Training loss:1.6207043925921123, Validation accuracy:0.14285714285714285\n","Epoch: 5, Training Accuracy: 0.19583333333333333, Training loss:1.6150264819463094, Validation accuracy:0.14285714285714285\n","Epoch     7: reducing learning rate of group 0 to 1.2500e-04.\n","Epoch: 6, Training Accuracy: 0.21875, Training loss:1.6058717370033264, Validation accuracy:0.21428571428571427\n","SAVING CHECKPOINT\n","Epoch: 7, Training Accuracy: 0.29791666666666666, Training loss:1.5862704912821453, Validation accuracy:0.23214285714285715\n","Epoch     9: reducing learning rate of group 0 to 6.2500e-05.\n","Epoch: 8, Training Accuracy: 0.3333333333333333, Training loss:1.5451009253660837, Validation accuracy:0.21428571428571427\n","SAVING CHECKPOINT\n","Epoch: 9, Training Accuracy: 0.3416666666666667, Training loss:1.4911937097708383, Validation accuracy:0.23214285714285715\n","SAVING CHECKPOINT\n","Epoch    11: reducing learning rate of group 0 to 3.1250e-05.\n","Epoch: 10, Training Accuracy: 0.36666666666666664, Training loss:1.445289812485377, Validation accuracy:0.25\n","SAVING CHECKPOINT\n","Epoch: 11, Training Accuracy: 0.37083333333333335, Training loss:1.4112167179584503, Validation accuracy:0.2857142857142857\n","Epoch: 12, Training Accuracy: 0.37916666666666665, Training loss:1.3743538439273835, Validation accuracy:0.23214285714285715\n","Epoch    14: reducing learning rate of group 0 to 1.5625e-05.\n","Epoch: 13, Training Accuracy: 0.4395833333333333, Training loss:1.3475292861461639, Validation accuracy:0.26785714285714285\n","Epoch: 14, Training Accuracy: 0.43125, Training loss:1.3306883156299592, Validation accuracy:0.26785714285714285\n","SAVING CHECKPOINT\n","Epoch    16: reducing learning rate of group 0 to 7.8125e-06.\n","Epoch: 15, Training Accuracy: 0.45, Training loss:1.3114401360352834, Validation accuracy:0.30357142857142855\n","Epoch: 16, Training Accuracy: 0.44166666666666665, Training loss:1.3014925360679626, Validation accuracy:0.2857142857142857\n","Epoch    18: reducing learning rate of group 0 to 3.9063e-06.\n","Epoch: 17, Training Accuracy: 0.46041666666666664, Training loss:1.2931125164031982, Validation accuracy:0.25\n","SAVING CHECKPOINT\n","Epoch: 18, Training Accuracy: 0.45416666666666666, Training loss:1.2896678507328034, Validation accuracy:0.32142857142857145\n","SAVING CHECKPOINT\n","Epoch    20: reducing learning rate of group 0 to 1.9531e-06.\n","Epoch: 19, Training Accuracy: 0.4583333333333333, Training loss:1.2877700249354045, Validation accuracy:0.32142857142857145\n"]}],"source":["# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","run_num = 2\n","n_epochs = 20\n","cuda = torch.cuda.is_available()\n","\n","#Define Training Grid Search\n","# model_list = ['1CNN', '2CNN', '3CNN']\n","# emb_size_list = [640, 640, 640, 640]\n","# hidden_size_list = [128, 256, 384, 512]\n","# num_lstm_layers_list = [1, 2, 3]\n","# bidirectional_list = [False, True]\n","\n","model_list = ['3CNN']\n","emb_size_list = [640]\n","hidden_size_list = [128]\n","num_lstm_layers_list = [3]\n","bidirectional_list = [False]\n","\n","\n","for model_name in model_list:\n","    for bidirectionality in bidirectional_list:\n","        for emb_size in emb_size_list:\n","            for num_lstm in num_lstm_layers_list:\n","                for hidden_size in hidden_size_list:\n","                    \n","                        start_time = time.time()\n","                        \n","                        #Log Metadata\n","                        metadata = model_name + ',' + str(bidirectionality) + ',' + str(emb_size) + ',' + str(num_lstm) + ',' + str(hidden_size)\n","                        print(metadata)\n","\n","                        #initialize model\n","                        if model_name == '1CNN':\n","                            model = ICASSP1CNN(emb_size, hidden_size, num_lstm, bidirectionality)\n","                        elif model_name == '2CNN':\n","                            model = ICASSP2CNN(emb_size, hidden_size, num_lstm, bidirectionality)\n","                        elif model_name == '3CNN':\n","                            model = ICASSP3CNN(emb_size, hidden_size, num_lstm, bidirectionality)        \n","                          \n","                        # opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","                        # criterion = nn.CrossEntropyLoss()\n","                        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=2, threshold=0.04, threshold_mode='abs', verbose=True)\n"," \n","                        device = torch.device(\"cuda\" if cuda else \"cpu\")\n","                        model.to(device)\n","                        \n","                        print(model)\n","                        \n","                        test_data = []\n","\n","                        for i, (train_index, test_index) in enumerate(kf.split(file_paths)):\n","                            max_valid_acc = 0\n","                            max_test_acc = 0\n","                            model.apply(reset_weights)  # reset weights on each fold\n","                            opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","                            criterion = nn.CrossEntropyLoss()\n","                            scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=1, threshold=0.04, threshold_mode='abs', verbose=True)\n","\n","                            print(f'Running {i + 1}th cross validation.......')\n","                            # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","                            train_index = list(train_index)\n","                            test_index = list(test_index)\n","                            xtrain, ytrain = [], []\n","                            xtest_all, ytest_all = [], []\n","\n","                            for idx in train_index:\n","                                xtrain.append(file_paths[idx])\n","                                ytrain.append(labels[idx])\n","\n","                            for idx in test_index:\n","                                xtest_all.append(file_paths[idx])\n","                                ytest_all.append(labels[idx])\n","\n","                            mid = len(xtest_all) // 2\n","                            xval = xtest_all[:mid]\n","                            yval = ytest_all[:mid]\n","\n","                            xtest = xtest_all[mid:]\n","                            ytest = ytest_all[mid:]\n","\n","                            test_data.append((xtest, ytest))\n","\n","                            assert(len(xtrain) + len(xval) + len(xtest) == len(file_paths))\n","                            \n","                            train_loader, val_loader = get_loaders(xtrain, ytrain, xval, yval)\n","\n","                            for epoch in range(n_epochs):\n","                                model, train_acc, train_loss = train_model(train_loader, model, opt, criterion, device)\n","                                valid_acc = test_model(val_loader, model, opt, criterion, device)\n","                                # test_acc = test_model(test_loader, model, opt, criterion, device)\n","\n","                                if valid_acc >= max_valid_acc:\n","                                    print(\"SAVING CHECKPOINT\")\n","                                    max_valid_acc = valid_acc\n","                                    # max_test_acc = test_acc\n","                                    save_path = os.path.join(\"gdrive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"saved_models\", \"AESDD\", f\"run{run_num}\", f\"epoch{epoch}_fold{i+1}_model{model_name}_batchsize{batch_size}_lr{lr}_embed{emb_size}_hsize{hidden_size}_numlstm{num_lstm}.pth\")\n","\n","                                    torch.save({\n","                                        'model_state_dict': model.state_dict(),\n","                                        'optimizer_state_dict': opt.state_dict(),\n","                                        'scheduler_state_dict' : scheduler.state_dict(),\n","                                        'train_acc': train_acc,\n","                                        'val_acc': valid_acc,\n","                                        }, save_path)\n","\n","                                \n","                                scheduler.step(valid_acc)\n","\n","\n","                                # Print log of accuracy and loss\n","                                print(\"Epoch: \"+ str(epoch) +\", Training Accuracy: \"+str(train_acc)+\", Training loss:\"+str(train_loss)+ \", Validation accuracy:\"+str(valid_acc))\n","                        \n","\n","                        total_time = (time.time() - start_time) / 60\n","            "]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1638368737948,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"CU9w5QE1CipB"},"outputs":[],"source":["def get_test_acc(model, test_loader):\n","    # checkpoint = torch.load(model_pth)\n","    # model.load_state_dict(checkpoint[\"model_state_dict\"])\n","\n","    model.eval()\n","    test_num_correct = 0\n","    total = 0\n","    for batch_num, (x, lengths, y) in enumerate(test_loader):\n","        x = x.to(device)\n","        y = y.long().to(device)\n","\n","        logits = model(x, lengths)\n","        test_num_correct += (torch.argmax(logits, axis=1) == y).sum().item()\n","        total += len(y)\n","\n","    test_acc = test_num_correct / total\n","    return test_acc"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20805,"status":"ok","timestamp":1638368758752,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":300},"id":"dt4N_ml4CjP8","outputId":"25b4848c-8601-4e8a-ed24-050227bf7b91"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.42857142857142855\n"]}],"source":["# test dataloader\n","test_dset = MyDataset(xtest, ytest)\n","test_args = dict(shuffle=False, batch_size=batch_size, num_workers=1, collate_fn=pad_collate, drop_last=True)\n","test_loader = DataLoader(test_dset, **test_args)\n","\n","test_acc = get_test_acc(model, test_loader)\n","print(test_acc)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"AESDD_embeddings_+_CNN_+_LSTM_K_Fold.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
