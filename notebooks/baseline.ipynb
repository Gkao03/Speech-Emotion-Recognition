{"cells":[{"cell_type":"markdown","metadata":{"id":"3N8Inmytpear"},"source":["# Installs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4132,"status":"ok","timestamp":1635554669467,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"AXUoxGkrp4uj","outputId":"c5e9b973-c72c-4d81-b0af-584e01006b37"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"]}],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3962,"status":"ok","timestamp":1636065423198,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"XIMBeItvqS-k","outputId":"13c1ac08-4861-4410-9fe7-5365481260e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n","Collecting torchaudio\n","  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 59.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 49.8 MB/s \n","\u001b[?25hInstalling collected packages: torchaudio\n","Successfully installed torchaudio-0.9.0\n"]}],"source":["!pip install torch torchvision torchaudio"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3822,"status":"ok","timestamp":1636065427018,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"EFillham-O1K","outputId":"93907fda-3ccd-4294-a379-bf5e8461b1b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting allosaurus\n","  Downloading allosaurus-1.0.2-py3-none-any.whl (52 kB)\n","\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 709 kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.4.1)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.5.3)\n","Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.19.5)\n","Collecting panphon\n","  Downloading panphon-0.19-py2.py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 471 kB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.9.0+cu111)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (3.13)\n","Collecting munkres\n","  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (2019.12.20)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (57.4.0)\n","Collecting unicodecsv\n","  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (1.15.0)\n","Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (0.51.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy->allosaurus) (0.34.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->allosaurus) (3.7.4.3)\n","Building wheels for collected packages: unicodecsv\n","  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10765 sha256=ed73a58b14eba40829e8f6e8d05894409981b7b7eda0f79bfe10911f8dfba459\n","  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n","Successfully built unicodecsv\n","Installing collected packages: unicodecsv, munkres, panphon, allosaurus\n","Successfully installed allosaurus-1.0.2 munkres-1.1.4 panphon-0.19 unicodecsv-0.14.1\n"]}],"source":["!pip install allosaurus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3144,"status":"ok","timestamp":1635648834321,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"7kzE9hbDC0hK","outputId":"b25cb19b-d81d-4b04-e5ab-a3f13e13b64c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1635562711137,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"bcOgzMr59RUE","outputId":"933a1a04-da42-4226-fd4c-713010fe9d08"},"outputs":[{"name":"stdout","output_type":"stream","text":[".   .config  iemocap_full_dataset.csv  Ses01F_script02_1_F000.wav\n","..  drive    sample_data\n"]}],"source":["!ls -a"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15234,"status":"ok","timestamp":1636065442251,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"jtZM0NIU5ZYg","outputId":"76d0c616-e666-4743-942d-7c7446a68d8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"_7aZ6m_fBP7D"},"source":["# Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":14441,"status":"ok","timestamp":1636065458950,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"aSVUkSiTA9iu"},"outputs":[],"source":["#These libraries help to interact with the operating system and the runtime environment respectively\n","import os\n","import sys\n","\n","#Model/Training related libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","\n","#Dataloader libraries\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Transforms and datasets\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dset\n","\n","import time\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Allosaurus\n","from allosaurus.audio import read_audio\n","from allosaurus.app import read_recognizer\n","from allosaurus.am.utils import *"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1636065472824,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"PnbMwoBoqi0t","outputId":"b8ce7c84-4dcc-463a-df35-f598e904c5c2"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1636065474448,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"wDdfpkyJadhS","outputId":"35c8875f-0f87-4585-8efa-6dbb95e03457"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.current_device()"]},{"cell_type":"markdown","metadata":{"id":"zyD9tTXR9Zqy"},"source":["# Process IEMOCAP dataset csv"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1636065476390,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"t5ooLiTQ9WPG","outputId":"4ff1ce46-ea57-4f25-f110-0c14bd4c9ca1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session</th>\n","      <th>method</th>\n","      <th>gender</th>\n","      <th>emotion</th>\n","      <th>n_annotators</th>\n","      <th>agreement</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>script</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>script</td>\n","      <td>F</td>\n","      <td>fru</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>script</td>\n","      <td>F</td>\n","      <td>xxx</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>script</td>\n","      <td>F</td>\n","      <td>sur</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>script</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session1/sentences/wav/Ses01F_script02_1/Ses01...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10034</th>\n","      <td>5</td>\n","      <td>impro</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session5/sentences/wav/Ses05F_impro06/Ses05F_i...</td>\n","    </tr>\n","    <tr>\n","      <th>10035</th>\n","      <td>5</td>\n","      <td>impro</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session5/sentences/wav/Ses05F_impro06/Ses05F_i...</td>\n","    </tr>\n","    <tr>\n","      <th>10036</th>\n","      <td>5</td>\n","      <td>impro</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session5/sentences/wav/Ses05F_impro06/Ses05F_i...</td>\n","    </tr>\n","    <tr>\n","      <th>10037</th>\n","      <td>5</td>\n","      <td>impro</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>Session5/sentences/wav/Ses05F_impro06/Ses05F_i...</td>\n","    </tr>\n","    <tr>\n","      <th>10038</th>\n","      <td>5</td>\n","      <td>impro</td>\n","      <td>F</td>\n","      <td>neu</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>Session5/sentences/wav/Ses05F_impro06/Ses05F_i...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10039 rows × 7 columns</p>\n","</div>"],"text/plain":["       session  ...                                               path\n","0            1  ...  Session1/sentences/wav/Ses01F_script02_1/Ses01...\n","1            1  ...  Session1/sentences/wav/Ses01F_script02_1/Ses01...\n","2            1  ...  Session1/sentences/wav/Ses01F_script02_1/Ses01...\n","3            1  ...  Session1/sentences/wav/Ses01F_script02_1/Ses01...\n","4            1  ...  Session1/sentences/wav/Ses01F_script02_1/Ses01...\n","...        ...  ...                                                ...\n","10034        5  ...  Session5/sentences/wav/Ses05F_impro06/Ses05F_i...\n","10035        5  ...  Session5/sentences/wav/Ses05F_impro06/Ses05F_i...\n","10036        5  ...  Session5/sentences/wav/Ses05F_impro06/Ses05F_i...\n","10037        5  ...  Session5/sentences/wav/Ses05F_impro06/Ses05F_i...\n","10038        5  ...  Session5/sentences/wav/Ses05F_impro06/Ses05F_i...\n","\n","[10039 rows x 7 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"iemocap_full_dataset.csv\")\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df[df.emotion != 'xxx']  # only keep data that has emotion label\n","# only keep 'neu', 'hap', 'sad', 'ang' labels\n","df = df.drop(df[~ ((df.emotion == 'neu') | (df.emotion == 'hap') | (df.emotion == 'sad') | (df.emotion == 'ang'))].index)\n","\n","df_unedit = df.copy()\n","df_unedit[\"path\"] = df_unedit[\"path\"].apply(lambda x : x.split('/')[-1])\n","all_files = list(df_unedit.path)\n","file_to_emotion = dict(zip(df_unedit.path, df_unedit.emotion))\n","\n","all_full_files = list(df.path)\n","print(df)\n","print(df_unedit)\n","print(len(file_to_emotion))\n","print(file_to_emotion)\n","print(all_full_files)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1636065481190,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"WmcN27BJf0-W","outputId":"01d32664-da00-4f8c-a4b9-1e4ffbfe3e7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","{0: 'neu', 1: 'hap', 2: 'sad', 3: 'ang'}\n","Counter({'neu': 1708, 'ang': 1103, 'sad': 1084, 'hap': 595})\n"]}],"source":["from collections import Counter\n","\n","# get unique emotions\n","# emotion_to_label = {'neu': 0, 'fru': 1, 'sad': 2, 'sur': 3, 'ang': 4, 'hap': 5, 'exc': 6, 'fea': 7, 'dis': 8, 'oth': 9}\n","emotion_to_label = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","label_to_emotion = {v: k for k, v in emotion_to_label.items()}\n","print(emotion_to_label)\n","print(label_to_emotion)\n","\n","# counter number of class instances\n","emotion_instances_list = [v for v in file_to_emotion.values()]\n","counter = Counter(emotion_instances_list)\n","print(counter)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_to_label = {k: emotion_to_label[v] for k, v in file_to_emotion.items()}\n","print(file_to_label)"]},{"cell_type":"markdown","metadata":{"id":"saituhpFsM_L"},"source":["# Data Processing and Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1635645410253,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"Jw0McKvuuGhT","outputId":"c648332f-c5be-40cb-8740-6c8ae9fed2f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive  iemocap_full_dataset.csv  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1636065485289,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"JBWWXrvDv10O","outputId":"a0cbb6bb-2f7e-42cb-bfff-772c3f25fc69"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive/MyDrive/18786 IDL/IDL Project/data/IEMOCAP_full_release\n"]}],"source":["data_dir = os.path.join(\"drive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"data\", \"IEMOCAP_full_release\")\n","# data_dir = os.path.join(\"drive\", \"MyDrive\", \"IDL Project\", \"data\", \"IEMOCAP_full_release\")\n","print(data_dir)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2424,"status":"ok","timestamp":1636065489089,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"MZ1MCeA4VDQx","outputId":"af348ae8-4599-44dd-9b94-67a6c3a78fdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading model  latest\n","from:  https://github.com/xinjli/allosaurus/releases/download/v1.0/latest.tar.gz\n","to:    /usr/local/lib/python3.7/dist-packages/allosaurus/pretrained\n","please wait...\n"]}],"source":["recognizer = read_recognizer()"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1636065489482,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"fORmXOdVl3-X"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, file_list, target_list):\n","        \n","        self.file_list = file_list\n","        self.target_list = target_list\n","        self.num_classes = len(list(set(target_list)))\n","\n","        # self.recognizer = read_recognizer()\n","\n","        # feats, feat_lens = [], []\n","        # for file in tqdm(file_list):\n","            \n","        #     feat = torch.tensor(recognizer.pm.compute(read_audio(file))) # batch, len, features\n","        #     feat_len = torch.tensor(np.array([feat.shape[0]], dtype=np.int32)) # 1D array\n","            \n","        #     feats.append(feat)\n","        #     feat_lens.append(feat_len)\n","            \n","\n","        # feats = pad_sequence(feats,batch_first=True,padding_value=0) # batch,features,len\n","        # feat_lens = pad_sequence(feat_lens,batch_first=True,padding_value=0).squeeze()\n","        # idx = torch.argsort(feat_lens,descending=True) # sorting the input in descending order as required by the lstms in AM.\n","        # self.y = np.array(self.target_list)[idx].tolist()   # reorder\n","        # tensor_batch_feat, tensor_batch_feat_len = move_to_tensor([feats[idx], feat_lens[idx]], device_id=-1) # converting to the required tensors\n","\n","        # # Features\n","        # output_tensor, input_lengths = recognizer.am(tensor_batch_feat, tensor_batch_feat_len, return_lstm=True) # output_shape: [len,batch,features]\n","        # assert(len(file_list) == output_tensor.shape[1])\n","\n","        # self.x = output_tensor\n","        self.x = file_list\n","        self.y = target_list\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        # x = self.x[:, index, :]\n","        # y = self.y[index]\n","        # y = torch.Tensor([y])\n","        # print(\"inside get item\")\n","        filepath = self.file_list[index]\n","        x = torch.tensor(recognizer.pm.compute(read_audio(filepath)))\n","        x = x.detach()\n","        x_len = torch.tensor(np.array([x.shape[0]], dtype=np.int32))\n","        x_len = x_len.detach()\n","        y = torch.Tensor([self.target_list[index]])\n","        return x, x_len, y"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":143,"status":"ok","timestamp":1636065491918,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"j7w12HfMJfFZ"},"outputs":[],"source":["# collate function\n","def pad_collate(batch):\n","    # print(\"inside collate\")\n","    # batch looks like [(x0, xlen0, y0), (x4, xlen4, y4), (x2, xlen2, y2)... ]\n","    feats = [sample[0] for sample in batch]\n","    feat_lens = [sample[1] for sample in batch]\n","    target_list = torch.Tensor([sample[2] for sample in batch])\n","\n","    feats = pad_sequence(feats, batch_first=True, padding_value=0) # batch, features, len\n","    feat_lens = pad_sequence(feat_lens, batch_first=True, padding_value=0).squeeze()\n","    idx = torch.argsort(feat_lens, descending=True) # sorting the input in descending order as required by the lstms in AM.\n","\n","    # reorder\n","    # tensor_batch_feat = feats[idx]\n","    # tensor_batch_feat_len = feat_lens[idx]\n","    targets = target_list[idx]\n","    tensor_batch_feat, tensor_batch_feat_len = move_to_tensor([feats[idx], feat_lens[idx]], device_id=-1) # converting to the required tensors\n","\n","    # Features\n","    output_tensor, input_lengths = recognizer.am(tensor_batch_feat, tensor_batch_feat_len, return_lstm=True) # output_shape: [len,batch,features]\n","    output_tensor = output_tensor.detach()\n","    input_lengths = input_lengths.detach()\n","    \n","    return output_tensor, input_lengths, targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3RE_LACUxb_3"},"outputs":[],"source":["def parse_data(data_dir):\n","    all_file_paths = []  # full file paths from drive to wav file\n","\n","    for root, directories, filenames in os.walk(data_dir):\n","            for filename in filenames:\n","                if filename.endswith('.wav') and filename[0] != '.' and filename in all_files:\n","                    filei = os.path.join(root, filename)\n","                    all_file_paths.append(filei)\n","\n","    return all_file_paths\n","\n","# assert(len(all_file_paths) == len(all_files))"]},{"cell_type":"markdown","metadata":{"id":"bSqGHFcAuCD5"},"source":["## random shuffle data order for train, val, test split"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1636065495483,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"GG5tor0xt__p","outputId":"e7ed8128-ba86-4a34-b2b9-79a1d90455c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["4490\n"]}],"source":["# all_file_paths = parse_data(data_dir)\n","all_file_paths = [os.path.join(\"drive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"data\", \"IEMOCAP_full_release\", file_path) for file_path in all_full_files]\n","# all_file_paths = [os.path.join(\"drive\", \"MyDrive\", \"IDL Project\", \"data\", \"IEMOCAP_full_release\", file_path) for file_path in all_full_files]\n","total_instances = len(all_file_paths)\n","print(total_instances)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1636065501809,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"XItX_F7vwn_P","outputId":"f0248a18-5150-4828-edc0-c55fd59e266a"},"outputs":[{"name":"stdout","output_type":"stream","text":["number training instances: 3143\n","number validation instances: 674\n","number test instances: 673\n"]}],"source":["num_train = round(0.7 * total_instances)\n","num_test_all = total_instances - num_train\n","num_val = round(0.5 * num_test_all)\n","num_test = num_test_all - num_val\n","\n","print(\"number training instances:\", str(num_train))\n","print(\"number validation instances:\", str(num_val))\n","print(\"number test instances:\", str(num_test))\n","assert(num_train + num_val + num_test == total_instances)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1636065504441,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"FWsZkUFMxeEC"},"outputs":[],"source":["# shuffle data\n","import random\n","random.seed(420)\n","\n","shuffled_data_paths = random.sample(all_file_paths, k=total_instances)\n","train_list_paths = shuffled_data_paths[:num_train]\n","testall_list_paths = shuffled_data_paths[num_train:]\n","val_list_paths = testall_list_paths[:num_val]\n","test_list_paths = testall_list_paths[num_val:]\n","\n","assert(len(train_list_paths) + len(val_list_paths) + len(test_list_paths) == total_instances)\n","\n","# train, val, test variables:\n","# train_list_paths\n","# val_list_paths\n","# test_list_paths"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1636065506802,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"oSvmpPUr1gqY"},"outputs":[],"source":["# get corresponding labels for data\n","train_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in train_list_paths]\n","val_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in val_list_paths]\n","test_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in test_list_paths]\n","\n","assert(len(train_list_labels) == len(train_list_paths))\n","assert(len(val_list_labels) == len(val_list_paths))\n","assert(len(test_list_labels) == len(test_list_paths))"]},{"cell_type":"markdown","metadata":{"id":"gXbNMUMu1Dl6"},"source":["## Create datasets and dataloaders"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":143,"status":"ok","timestamp":1636065508690,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"xGVIsdGT4tC8"},"outputs":[],"source":["batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BjQITuxo1G3-"},"outputs":[],"source":["# train dataloader\n","train_dset = MyDataset(train_list_paths, train_list_labels)\n","train_args = dict(shuffle=True, batch_size=batch_size, num_workers=2, collate_fn=pad_collate, drop_last=True)  # change to num_workers=4 on diff platform\n","train_loader = DataLoader(train_dset, **train_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFiuseBjAsSm"},"outputs":[],"source":["# val dataloader\n","val_dset = MyDataset(val_list_paths, val_list_labels)\n","val_args = dict(shuffle=False, batch_size=batch_size, num_workers=2, collate_fn=pad_collate, drop_last=True)\n","val_loader = DataLoader(val_dset, **val_args)"]},{"cell_type":"markdown","metadata":{"id":"NpEvyQOKW0ZG"},"source":["## Check a batch from dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cwhdjf56W4ow"},"outputs":[],"source":["test_batch = next(iter(train_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1635928197240,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"kvp-n3g5XEyx","outputId":"2ba3d9e5-37a3-413d-eab9-9bace1dedb31"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([371, 32, 640])\n","tensor([371, 315, 284, 255, 241, 231, 202, 195, 194, 194, 179, 165, 164, 151,\n","        150, 149, 136, 133, 119, 117, 117, 113,  96,  90,  80,  76,  73,  73,\n","         64,  63,  62,  54], dtype=torch.int32)\n","tensor([0., 2., 3., 0., 2., 0., 0., 0., 1., 2., 2., 1., 0., 3., 0., 3., 0., 2.,\n","        2., 0., 2., 2., 1., 2., 2., 3., 0., 3., 1., 3., 0., 0.])\n"]}],"source":["x, x_len, y = test_batch\n","print(x.shape)  # seq_len, batch_size, input_size\n","print(x_len)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"7coNzITWIEo_"},"source":["# Test Allosaurus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":603,"status":"ok","timestamp":1635568570634,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"fDPpzwsqIKQ-","outputId":"19a947b1-4007-4318-e8b6-26017ecec204"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([69, 120])\n","tensor([69], dtype=torch.int32)\n","torch.Size([50, 120])\n","tensor([50], dtype=torch.int32)\n"]}],"source":["recognizer = read_recognizer()\n","wav_paths = [\"Ses01F_script02_1_F000.wav\", \"Ses01F_script02_1_F001.wav\"]\n","\n","feats, feat_lens = [], []\n","for wav_path in wav_paths:\n","    \n","    feat = torch.tensor(recognizer.pm.compute(read_audio(wav_path))) # batch, len, features\n","    feat_len = torch.tensor(np.array([feat.shape[0]], dtype=np.int32)) # 1D array\n","\n","    print(feat.shape)\n","    print(feat_len)\n","    \n","    feats.append(feat)\n","    feat_lens.append(feat_len)\n","    \n","\n","feats = pad_sequence(feats,batch_first=True,padding_value=0) # batch,features,len\n","feat_lens = pad_sequence(feat_lens,batch_first=True,padding_value=0).squeeze()\n","idx = torch.argsort(feat_lens,descending=True) # sorting the input in descending order as required by the lstms in AM.\n","tensor_batch_feat, tensor_batch_feat_len = move_to_tensor([feats[idx], feat_lens[idx]], recognizer.config.device_id) # converting to the required tensors\n","\n","# Features\n","output_tensor, input_lengths = recognizer.am(tensor_batch_feat, tensor_batch_feat_len, return_lstm=True) # output_shape: [len,batch,features]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1635564760064,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"Gp13ha09I6F0","outputId":"47848ba5-cc49-4134-c6a1-f7d942a5544a"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([69, 2, 640])\n","tensor([69, 50], dtype=torch.int32)\n"]}],"source":["print(output_tensor.shape)\n","print(input_lengths)"]},{"cell_type":"markdown","metadata":{"id":"XKIv8u3C_J2P"},"source":["## see how many test files produce 0 length phonetic transcriptions (don't run again)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4889899,"status":"ok","timestamp":1635633245731,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03949356216555416755"},"user_tz":240},"id":"o49aWcMX_P7B","outputId":"0d980bad-5685-4dc4-ea51-999752bd1969"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 7532/7532 [1:21:29<00:00,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["number of data instances with no phonetic transcription: 53\n","total number of data instances: 7532\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from allosaurus.app import read_recognizer\n","\n","# load your model\n","model = read_recognizer()\n","\n","num_no_transcription = 0\n","\n","# run inference -> æ l u s ɔ ɹ s\n","for file in tqdm(all_file_paths):\n","    output = model.recognize(file)\n","    if len(output) == 0:\n","        num_no_transcription += 1\n","\n","print(f\"number of data instances with no phonetic transcription: {num_no_transcription}\")\n","print(f\"total number of data instances: {len(all_file_paths)}\")"]},{"cell_type":"markdown","metadata":{"id":"LzO39LNCl83v"},"source":["# Models"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":154,"status":"ok","timestamp":1636065672590,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"2z1N6UkgSRSy"},"outputs":[],"source":["class BaseLSTM(nn.Module):\n","    def __init__(self, num_layers, num_classes, input_size, hidden_size, dropout, bidirectional=False):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.bidirectional = bidirectional\n","        \n","        # self.embed = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=bidirectional, batch_first=False)\n","\n","        self.linear = nn.Linear(in_features=2 * hidden_size if bidirectional else hidden_size, \n","                                out_features=num_classes)\n","        \n","    def forward(self, x, lengths=None):\n","        # input = self.embed(x)\n","        \n","        # batch_size = input.size(0)\n","        # input = input.transpose(1,2)    # (B,T,H) -> (B,H,T)\n","\n","        # cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n","\n","        # input = F.relu(self.batchnorm(cnn_output))\n","\n","        # input = input.transpose(1,2)\n","\n","        _, (hn, cn) = self.lstm(x)\n","\n","        # pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n","        # _, (hn, cn) = self.lstm(pack_tensor)\n","\n","        if self.bidirectional:\n","            h_n = hn.view(self.num_layers, 2, batch_size, self.hidden_size)\n","            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n","        else:\n","            h_n = hn[-1]\n","        \n","        logits = self.linear(h_n)\n","\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFnlPBZnmAJB"},"outputs":[],"source":["class BaseLSTM(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n","        super(BaseLSTM, self).__init__()\n","        self.hidden_dim = hidden_dim\n","\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # The LSTM takes word embeddings as inputs, and outputs hidden states\n","        # with dimensionality hidden_dim.\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n","\n","        # The linear layer that maps from hidden state space to tag space\n","        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n","\n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n","        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n","        tag_scores = F.log_softmax(tag_space, dim=1)\n","        return tag_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xip_GsBkpCeP"},"outputs":[],"source":["class BidirectionalLSTM(nn.Module):\n","    def __init__(self, hidden_size, nlayers, out_size=47, embed_size=40):\n","        super(BidirectionalLSTM, self).__init__()\n","        self.nlayers = nlayers\n","        self.hidden_size = hidden_size\n","        self.embed_size = embed_size\n","        self.out_size = out_size\n","        self.cnns = torch.nn.Sequential(\n","            nn.Conv1d(self.embed_size, self.hidden_size, 3, padding=1, bias=False),\n","            nn.BatchNorm1d(self.hidden_size),\n","            nn.ReLU(inplace=True))\n","        self.rnns = nn.LSTM(input_size=self.hidden_size,\n","                            hidden_size=self.hidden_size,\n","                            num_layers=3,\n","                            bias=True,\n","                            batch_first=True,\n","                            dropout=0.2, # regularization\n","                            bidirectional=True)\n","        self.hidden2label = torch.nn.Sequential(\n","            nn.Linear(self.hidden_size*2, self.hidden_size),\n","            nn.Linear(self.hidden_size, self.out_size))\n","    def forward(self, x, xLens): # x dim (B, T_in, C_in=40)\n","        x_cnn_input = x.permute(0, 2, 1) # (B, C_in, T_in)\n","        x_post_cnn = self.cnns(x_cnn_input) # (B, C_out, T_out)\n","        x_rnn_in = x_post_cnn.permute(2, 0, 1) # (T, B, C_out)\n","        x_packed = pack_padded_sequence(x_rnn_in, xLens, enforce_sorted=False)\n","        out_packed, hidden = self.rnns(x_packed)\n","        out, out_lens = pad_packed_sequence(out_packed, batch_first=True) # (B, T, C)\n","        \n","        # Log softmax after output layer is required since nn.CTCLoss expect log prob\n","        out_prob = self.hidden2label(out).log_softmax(2) # (B, T, Classes=47)\n","        \n","        # Permute to fit for input format of CTCLoss\n","        out_prob = out_prob.permute(1, 0, 2) #torch.transpose(out_prob, 0, 1) # (T, B, C)\n","        \n","        # TODO: calculate new xLens\n","        return out_prob, xLens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJiHELAj7mgA"},"outputs":[],"source":["class classifier(nn.Module):\n","    \n","    #define all the layers used in model\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout):\n","        \n","        #Constructor\n","        super().__init__()          \n","        \n","        #embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm layer\n","        self.lstm = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout,\n","                           batch_first=True)\n","        \n","        #dense layer\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        #activation function\n","        self.act = nn.Sigmoid()\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        #text = [batch size,sent_length]\n","        embedded = self.embedding(text)\n","        #embedded = [batch size, sent_len, emb dim]\n","      \n","        #packed sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n","        \n","        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n","        #hidden = [batch size, num layers * num directions,hid dim]\n","        #cell = [batch size, num layers * num directions,hid dim]\n","        \n","        #concat the final forward and backward hidden state\n","        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","        dense_outputs=self.fc(hidden)\n","\n","        #Final activation function\n","        outputs=self.act(dense_outputs)\n","\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"cZadPFt0yS1S"},"source":["# Instantiate Model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAjsQPGOykvq"},"outputs":[],"source":["run_num = 4\n","batch_size = 32\n","# lr = 0.01\n","lr = 0.001\n","weight_decay = 5e-5\n","# weight_decay = 0.0001\n","num_epochs = 40\n","# in_features = 3 # RGB channels\n","# momentum = 0.9\n","\n","num_classes = 4  # 'neu', 'hap', 'sad', 'ang'\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9422,"status":"ok","timestamp":1635928225900,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"AhwEhFb9yld8","outputId":"a455028d-cc72-4419-91ee-4866210a4f69"},"outputs":[{"name":"stdout","output_type":"stream","text":["BaseLSTM(\n","  (lstm): LSTM(640, 256, num_layers=3, dropout=0.1, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=4, bias=True)\n",")\n","Adjusting learning rate of group 0 to 1.0000e-03.\n"]}],"source":["model = BaseLSTM(num_layers=3, num_classes=num_classes, input_size=640, hidden_size=256, dropout=0.1, bidirectional=True)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","criterion = nn.CrossEntropyLoss()\n","model = model.to(device)\n","print(model)\n","\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.SGD(network.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, nesterov=False)\n","# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=2, threshold=0.04, threshold_mode='abs', verbose=True)  # used for up to run 8 (inclusive)\n","# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.2, patience=3, threshold=0.04, threshold_mode='abs', verbose=True)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5, verbose=True)"]},{"cell_type":"markdown","metadata":{"id":"oP9Oiqo_g_6d"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25791203,"status":"ok","timestamp":1635954025354,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"gNGUtB1Vh6UL","outputId":"3ec8d0f1-8fc3-47bb-fbdb-163ed10b0cee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0\tBatch: 10\tAvg-Loss: 1.3536\n","Epoch: 0\tBatch: 20\tAvg-Loss: 1.2892\n","Epoch: 0\tBatch: 30\tAvg-Loss: 1.2581\n","Epoch: 0\tBatch: 40\tAvg-Loss: 1.2758\n","Epoch: 0\tBatch: 50\tAvg-Loss: 1.2511\n","Epoch: 0\tBatch: 60\tAvg-Loss: 1.2654\n","Epoch: 0\tBatch: 70\tAvg-Loss: 1.2016\n","Epoch: 0\tBatch: 80\tAvg-Loss: 1.1765\n","Epoch: 0\tBatch: 90\tAvg-Loss: 1.2031\n","Training Time 843.5502893924713 seconds\n","Training Acc: 0.4209354120267261\n","Epoch: 0, Validation Accuracy: 0.44\n","Validation Time 193.56710290908813 seconds\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","SAVING CHECKPOINT\n","Epoch: 1\tBatch: 10\tAvg-Loss: 1.1872\n","Epoch: 1\tBatch: 20\tAvg-Loss: 1.1651\n","Epoch: 1\tBatch: 30\tAvg-Loss: 1.1624\n","Epoch: 1\tBatch: 40\tAvg-Loss: 1.1815\n","Epoch: 1\tBatch: 50\tAvg-Loss: 1.1696\n","Epoch: 1\tBatch: 60\tAvg-Loss: 1.1581\n","Epoch: 1\tBatch: 70\tAvg-Loss: 1.2127\n","Epoch: 1\tBatch: 80\tAvg-Loss: 1.0790\n","Epoch: 1\tBatch: 90\tAvg-Loss: 1.2226\n","Training Time 512.1933341026306 seconds\n","Training Acc: 0.47120585427935097\n","Epoch: 1, Validation Accuracy: 0.49\n","Validation Time 114.30402398109436 seconds\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","SAVING CHECKPOINT\n","Epoch: 2\tBatch: 10\tAvg-Loss: 1.1584\n","Epoch: 2\tBatch: 20\tAvg-Loss: 1.1146\n","Epoch: 2\tBatch: 30\tAvg-Loss: 1.1307\n","Epoch: 2\tBatch: 40\tAvg-Loss: 1.1480\n","Epoch: 2\tBatch: 50\tAvg-Loss: 1.1070\n","Epoch: 2\tBatch: 60\tAvg-Loss: 1.1364\n","Epoch: 2\tBatch: 70\tAvg-Loss: 1.1295\n","Epoch: 2\tBatch: 80\tAvg-Loss: 1.1765\n","Epoch: 2\tBatch: 90\tAvg-Loss: 1.1406\n","Training Time 515.3200707435608 seconds\n","Training Acc: 0.49093223035316574\n","Epoch: 2, Validation Accuracy: 0.45\n","Validation Time 113.97767400741577 seconds\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","SAVING CHECKPOINT\n","Epoch: 3\tBatch: 10\tAvg-Loss: 1.1540\n","Epoch: 3\tBatch: 20\tAvg-Loss: 1.1646\n","Epoch: 3\tBatch: 30\tAvg-Loss: 1.0612\n","Epoch: 3\tBatch: 40\tAvg-Loss: 1.0520\n","Epoch: 3\tBatch: 50\tAvg-Loss: 1.0689\n","Epoch: 3\tBatch: 60\tAvg-Loss: 1.1025\n","Epoch: 3\tBatch: 70\tAvg-Loss: 1.0879\n","Epoch: 3\tBatch: 80\tAvg-Loss: 1.0485\n","Epoch: 3\tBatch: 90\tAvg-Loss: 1.0184\n","Training Time 512.4981787204742 seconds\n","Training Acc: 0.5211581291759465\n","Epoch: 3, Validation Accuracy: 0.49\n","Validation Time 114.78686475753784 seconds\n","Adjusting learning rate of group 0 to 5.0000e-04.\n","SAVING CHECKPOINT\n","Epoch: 4\tBatch: 10\tAvg-Loss: 1.1092\n","Epoch: 4\tBatch: 20\tAvg-Loss: 1.0319\n","Epoch: 4\tBatch: 30\tAvg-Loss: 0.9440\n","Epoch: 4\tBatch: 40\tAvg-Loss: 1.0772\n","Epoch: 4\tBatch: 50\tAvg-Loss: 0.9987\n","Epoch: 4\tBatch: 60\tAvg-Loss: 0.9298\n","Epoch: 4\tBatch: 70\tAvg-Loss: 1.0415\n","Epoch: 4\tBatch: 80\tAvg-Loss: 0.9658\n","Epoch: 4\tBatch: 90\tAvg-Loss: 1.0223\n","Training Time 513.4490022659302 seconds\n","Training Acc: 0.5669742284441617\n","Epoch: 4, Validation Accuracy: 0.53\n","Validation Time 114.8066771030426 seconds\n","Adjusting learning rate of group 0 to 5.0000e-04.\n","SAVING CHECKPOINT\n","Epoch: 5\tBatch: 10\tAvg-Loss: 0.8953\n","Epoch: 5\tBatch: 20\tAvg-Loss: 0.9355\n","Epoch: 5\tBatch: 30\tAvg-Loss: 0.9397\n","Epoch: 5\tBatch: 40\tAvg-Loss: 1.0183\n","Epoch: 5\tBatch: 50\tAvg-Loss: 1.0461\n","Epoch: 5\tBatch: 60\tAvg-Loss: 0.9433\n","Epoch: 5\tBatch: 70\tAvg-Loss: 0.9919\n","Epoch: 5\tBatch: 80\tAvg-Loss: 0.9848\n","Epoch: 5\tBatch: 90\tAvg-Loss: 1.0520\n","Training Time 516.5941660404205 seconds\n","Training Acc: 0.5968819599109132\n","Epoch: 5, Validation Accuracy: 0.53\n","Validation Time 114.01835012435913 seconds\n","Adjusting learning rate of group 0 to 5.0000e-04.\n","SAVING CHECKPOINT\n","Epoch: 6\tBatch: 10\tAvg-Loss: 0.8574\n","Epoch: 6\tBatch: 20\tAvg-Loss: 0.9118\n","Epoch: 6\tBatch: 30\tAvg-Loss: 0.9738\n","Epoch: 6\tBatch: 40\tAvg-Loss: 0.9057\n","Epoch: 6\tBatch: 50\tAvg-Loss: 0.8914\n","Epoch: 6\tBatch: 60\tAvg-Loss: 0.8699\n","Epoch: 6\tBatch: 70\tAvg-Loss: 0.9265\n","Epoch: 6\tBatch: 80\tAvg-Loss: 0.8758\n","Epoch: 6\tBatch: 90\tAvg-Loss: 1.0101\n","Training Time 515.568347454071 seconds\n","Training Acc: 0.6286986955138403\n","Epoch: 6, Validation Accuracy: 0.53\n","Validation Time 114.06539034843445 seconds\n","Adjusting learning rate of group 0 to 5.0000e-04.\n","SAVING CHECKPOINT\n","Epoch: 7\tBatch: 10\tAvg-Loss: 0.8706\n","Epoch: 7\tBatch: 20\tAvg-Loss: 0.8761\n","Epoch: 7\tBatch: 30\tAvg-Loss: 0.8175\n","Epoch: 7\tBatch: 40\tAvg-Loss: 0.8778\n","Epoch: 7\tBatch: 50\tAvg-Loss: 0.9281\n","Epoch: 7\tBatch: 60\tAvg-Loss: 0.9450\n","Epoch: 7\tBatch: 70\tAvg-Loss: 0.8887\n","Epoch: 7\tBatch: 80\tAvg-Loss: 0.9102\n","Epoch: 7\tBatch: 90\tAvg-Loss: 0.8130\n","Training Time 516.5077271461487 seconds\n","Training Acc: 0.6446070633153038\n","Epoch: 7, Validation Accuracy: 0.56\n","Validation Time 114.8465428352356 seconds\n","Adjusting learning rate of group 0 to 2.5000e-04.\n","SAVING CHECKPOINT\n","Epoch: 8\tBatch: 10\tAvg-Loss: 0.7482\n","Epoch: 8\tBatch: 20\tAvg-Loss: 0.7623\n","Epoch: 8\tBatch: 30\tAvg-Loss: 0.7767\n","Epoch: 8\tBatch: 40\tAvg-Loss: 0.7326\n","Epoch: 8\tBatch: 50\tAvg-Loss: 0.7974\n","Epoch: 8\tBatch: 60\tAvg-Loss: 0.7217\n","Epoch: 8\tBatch: 70\tAvg-Loss: 0.8050\n","Epoch: 8\tBatch: 80\tAvg-Loss: 0.8115\n","Epoch: 8\tBatch: 90\tAvg-Loss: 0.8813\n","Training Time 518.3989217281342 seconds\n","Training Acc: 0.6891504931594018\n","Epoch: 8, Validation Accuracy: 0.55\n","Validation Time 115.96468687057495 seconds\n","Adjusting learning rate of group 0 to 2.5000e-04.\n","SAVING CHECKPOINT\n","Epoch: 9\tBatch: 10\tAvg-Loss: 0.7355\n","Epoch: 9\tBatch: 20\tAvg-Loss: 0.6987\n","Epoch: 9\tBatch: 30\tAvg-Loss: 0.7032\n","Epoch: 9\tBatch: 40\tAvg-Loss: 0.6790\n","Epoch: 9\tBatch: 50\tAvg-Loss: 0.7371\n","Epoch: 9\tBatch: 60\tAvg-Loss: 0.7387\n","Epoch: 9\tBatch: 70\tAvg-Loss: 0.7124\n","Epoch: 9\tBatch: 80\tAvg-Loss: 0.7458\n","Epoch: 9\tBatch: 90\tAvg-Loss: 0.7100\n","Training Time 525.3847541809082 seconds\n","Training Acc: 0.7231944002545339\n","Epoch: 9, Validation Accuracy: 0.56\n","Validation Time 117.2480263710022 seconds\n","Adjusting learning rate of group 0 to 2.5000e-04.\n","SAVING CHECKPOINT\n","Epoch: 10\tBatch: 10\tAvg-Loss: 0.6169\n","Epoch: 10\tBatch: 20\tAvg-Loss: 0.6812\n","Epoch: 10\tBatch: 30\tAvg-Loss: 0.7059\n","Epoch: 10\tBatch: 40\tAvg-Loss: 0.7249\n","Epoch: 10\tBatch: 50\tAvg-Loss: 0.6051\n","Epoch: 10\tBatch: 60\tAvg-Loss: 0.6485\n","Epoch: 10\tBatch: 70\tAvg-Loss: 0.6678\n","Epoch: 10\tBatch: 80\tAvg-Loss: 0.7033\n","Epoch: 10\tBatch: 90\tAvg-Loss: 0.6697\n","Training Time 522.8156650066376 seconds\n","Training Acc: 0.7438752783964365\n","Epoch: 10, Validation Accuracy: 0.55\n","Validation Time 116.50335097312927 seconds\n","Adjusting learning rate of group 0 to 2.5000e-04.\n","SAVING CHECKPOINT\n","Epoch: 11\tBatch: 10\tAvg-Loss: 0.6403\n","Epoch: 11\tBatch: 20\tAvg-Loss: 0.5857\n","Epoch: 11\tBatch: 30\tAvg-Loss: 0.6672\n","Epoch: 11\tBatch: 40\tAvg-Loss: 0.6354\n","Epoch: 11\tBatch: 50\tAvg-Loss: 0.6173\n","Epoch: 11\tBatch: 60\tAvg-Loss: 0.5609\n","Epoch: 11\tBatch: 70\tAvg-Loss: 0.6190\n","Epoch: 11\tBatch: 80\tAvg-Loss: 0.6681\n","Epoch: 11\tBatch: 90\tAvg-Loss: 0.5906\n","Training Time 520.5602436065674 seconds\n","Training Acc: 0.7706013363028953\n","Epoch: 11, Validation Accuracy: 0.55\n","Validation Time 115.54681205749512 seconds\n","Adjusting learning rate of group 0 to 1.2500e-04.\n","SAVING CHECKPOINT\n","Epoch: 12\tBatch: 10\tAvg-Loss: 0.5403\n","Epoch: 12\tBatch: 20\tAvg-Loss: 0.5608\n","Epoch: 12\tBatch: 30\tAvg-Loss: 0.5261\n","Epoch: 12\tBatch: 40\tAvg-Loss: 0.6287\n","Epoch: 12\tBatch: 50\tAvg-Loss: 0.5316\n","Epoch: 12\tBatch: 60\tAvg-Loss: 0.5254\n","Epoch: 12\tBatch: 70\tAvg-Loss: 0.4725\n","Epoch: 12\tBatch: 80\tAvg-Loss: 0.5311\n","Epoch: 12\tBatch: 90\tAvg-Loss: 0.4230\n","Training Time 524.3323938846588 seconds\n","Training Acc: 0.8167356029271396\n","Epoch: 12, Validation Accuracy: 0.55\n","Validation Time 116.00833797454834 seconds\n","Adjusting learning rate of group 0 to 1.2500e-04.\n","SAVING CHECKPOINT\n","Epoch: 13\tBatch: 10\tAvg-Loss: 0.4895\n","Epoch: 13\tBatch: 20\tAvg-Loss: 0.4591\n","Epoch: 13\tBatch: 30\tAvg-Loss: 0.4925\n","Epoch: 13\tBatch: 40\tAvg-Loss: 0.4635\n","Epoch: 13\tBatch: 50\tAvg-Loss: 0.4958\n","Epoch: 13\tBatch: 60\tAvg-Loss: 0.6110\n","Epoch: 13\tBatch: 70\tAvg-Loss: 0.4286\n","Epoch: 13\tBatch: 80\tAvg-Loss: 0.4383\n","Epoch: 13\tBatch: 90\tAvg-Loss: 0.4187\n","Training Time 524.4340596199036 seconds\n","Training Acc: 0.8291441298122812\n","Epoch: 13, Validation Accuracy: 0.56\n","Validation Time 115.77420616149902 seconds\n","Adjusting learning rate of group 0 to 1.2500e-04.\n","SAVING CHECKPOINT\n","Epoch: 14\tBatch: 10\tAvg-Loss: 0.4144\n","Epoch: 14\tBatch: 20\tAvg-Loss: 0.4291\n","Epoch: 14\tBatch: 30\tAvg-Loss: 0.4118\n","Epoch: 14\tBatch: 40\tAvg-Loss: 0.4519\n","Epoch: 14\tBatch: 50\tAvg-Loss: 0.4331\n","Epoch: 14\tBatch: 60\tAvg-Loss: 0.5093\n","Epoch: 14\tBatch: 70\tAvg-Loss: 0.4782\n","Epoch: 14\tBatch: 80\tAvg-Loss: 0.3842\n","Epoch: 14\tBatch: 90\tAvg-Loss: 0.4695\n","Training Time 525.4246063232422 seconds\n","Training Acc: 0.8396436525612472\n","Epoch: 14, Validation Accuracy: 0.56\n","Validation Time 116.67373752593994 seconds\n","Adjusting learning rate of group 0 to 1.2500e-04.\n","SAVING CHECKPOINT\n","Epoch: 15\tBatch: 10\tAvg-Loss: 0.3628\n","Epoch: 15\tBatch: 20\tAvg-Loss: 0.3825\n","Epoch: 15\tBatch: 30\tAvg-Loss: 0.4651\n","Epoch: 15\tBatch: 40\tAvg-Loss: 0.3292\n","Epoch: 15\tBatch: 50\tAvg-Loss: 0.3830\n","Epoch: 15\tBatch: 60\tAvg-Loss: 0.4380\n","Epoch: 15\tBatch: 70\tAvg-Loss: 0.3571\n","Epoch: 15\tBatch: 80\tAvg-Loss: 0.4577\n","Epoch: 15\tBatch: 90\tAvg-Loss: 0.3589\n","Training Time 521.9426720142365 seconds\n","Training Acc: 0.8622335348393255\n","Epoch: 15, Validation Accuracy: 0.54\n","Validation Time 116.12265467643738 seconds\n","Adjusting learning rate of group 0 to 6.2500e-05.\n","SAVING CHECKPOINT\n","Epoch: 16\tBatch: 10\tAvg-Loss: 0.3794\n","Epoch: 16\tBatch: 20\tAvg-Loss: 0.3400\n","Epoch: 16\tBatch: 30\tAvg-Loss: 0.2923\n","Epoch: 16\tBatch: 40\tAvg-Loss: 0.3277\n","Epoch: 16\tBatch: 50\tAvg-Loss: 0.3246\n","Epoch: 16\tBatch: 60\tAvg-Loss: 0.4196\n","Epoch: 16\tBatch: 70\tAvg-Loss: 0.3257\n","Epoch: 16\tBatch: 80\tAvg-Loss: 0.3218\n","Epoch: 16\tBatch: 90\tAvg-Loss: 0.3671\n","Training Time 519.7160096168518 seconds\n","Training Acc: 0.8832325803372574\n","Epoch: 16, Validation Accuracy: 0.56\n","Validation Time 115.22049236297607 seconds\n","Adjusting learning rate of group 0 to 6.2500e-05.\n","SAVING CHECKPOINT\n","Epoch: 17\tBatch: 10\tAvg-Loss: 0.2409\n","Epoch: 17\tBatch: 20\tAvg-Loss: 0.3384\n","Epoch: 17\tBatch: 30\tAvg-Loss: 0.2929\n","Epoch: 17\tBatch: 40\tAvg-Loss: 0.3666\n","Epoch: 17\tBatch: 50\tAvg-Loss: 0.2553\n","Epoch: 17\tBatch: 60\tAvg-Loss: 0.2763\n","Epoch: 17\tBatch: 70\tAvg-Loss: 0.3312\n","Epoch: 17\tBatch: 80\tAvg-Loss: 0.3478\n","Epoch: 17\tBatch: 90\tAvg-Loss: 0.3375\n","Training Time 518.3825154304504 seconds\n","Training Acc: 0.8969137766465161\n","Epoch: 17, Validation Accuracy: 0.56\n","Validation Time 114.6922812461853 seconds\n","Adjusting learning rate of group 0 to 6.2500e-05.\n","SAVING CHECKPOINT\n","Epoch: 18\tBatch: 10\tAvg-Loss: 0.3586\n","Epoch: 18\tBatch: 20\tAvg-Loss: 0.2603\n","Epoch: 18\tBatch: 30\tAvg-Loss: 0.3151\n","Epoch: 18\tBatch: 40\tAvg-Loss: 0.2418\n","Epoch: 18\tBatch: 50\tAvg-Loss: 0.3183\n","Epoch: 18\tBatch: 60\tAvg-Loss: 0.2667\n","Epoch: 18\tBatch: 70\tAvg-Loss: 0.2356\n","Epoch: 18\tBatch: 80\tAvg-Loss: 0.2983\n","Epoch: 18\tBatch: 90\tAvg-Loss: 0.2946\n","Training Time 516.5071153640747 seconds\n","Training Acc: 0.9061406299713649\n","Epoch: 18, Validation Accuracy: 0.56\n","Validation Time 115.92938327789307 seconds\n","Adjusting learning rate of group 0 to 6.2500e-05.\n","SAVING CHECKPOINT\n","Epoch: 19\tBatch: 10\tAvg-Loss: 0.2669\n","Epoch: 19\tBatch: 20\tAvg-Loss: 0.2469\n","Epoch: 19\tBatch: 30\tAvg-Loss: 0.2080\n","Epoch: 19\tBatch: 40\tAvg-Loss: 0.2467\n","Epoch: 19\tBatch: 50\tAvg-Loss: 0.2718\n","Epoch: 19\tBatch: 60\tAvg-Loss: 0.2829\n","Epoch: 19\tBatch: 70\tAvg-Loss: 0.2783\n","Epoch: 19\tBatch: 80\tAvg-Loss: 0.2749\n","Epoch: 19\tBatch: 90\tAvg-Loss: 0.2869\n","Training Time 519.6641416549683 seconds\n","Training Acc: 0.9137766465160675\n","Epoch: 19, Validation Accuracy: 0.56\n","Validation Time 114.82080435752869 seconds\n","Adjusting learning rate of group 0 to 3.1250e-05.\n","SAVING CHECKPOINT\n","Epoch: 20\tBatch: 10\tAvg-Loss: 0.2885\n","Epoch: 20\tBatch: 20\tAvg-Loss: 0.2039\n","Epoch: 20\tBatch: 30\tAvg-Loss: 0.2401\n","Epoch: 20\tBatch: 40\tAvg-Loss: 0.2468\n","Epoch: 20\tBatch: 50\tAvg-Loss: 0.2436\n","Epoch: 20\tBatch: 60\tAvg-Loss: 0.2045\n","Epoch: 20\tBatch: 70\tAvg-Loss: 0.2383\n","Epoch: 20\tBatch: 80\tAvg-Loss: 0.2205\n","Epoch: 20\tBatch: 90\tAvg-Loss: 0.2084\n","Training Time 516.7864553928375 seconds\n","Training Acc: 0.922685332484887\n","Epoch: 20, Validation Accuracy: 0.55\n","Validation Time 115.76956343650818 seconds\n","Adjusting learning rate of group 0 to 3.1250e-05.\n","SAVING CHECKPOINT\n","Epoch: 21\tBatch: 10\tAvg-Loss: 0.2403\n","Epoch: 21\tBatch: 20\tAvg-Loss: 0.1811\n","Epoch: 21\tBatch: 30\tAvg-Loss: 0.2106\n","Epoch: 21\tBatch: 40\tAvg-Loss: 0.2148\n","Epoch: 21\tBatch: 50\tAvg-Loss: 0.1801\n","Epoch: 21\tBatch: 60\tAvg-Loss: 0.2503\n","Epoch: 21\tBatch: 70\tAvg-Loss: 0.2444\n","Epoch: 21\tBatch: 80\tAvg-Loss: 0.2063\n","Epoch: 21\tBatch: 90\tAvg-Loss: 0.2110\n","Training Time 519.473858833313 seconds\n","Training Acc: 0.9293668469615017\n","Epoch: 21, Validation Accuracy: 0.54\n","Validation Time 115.83538842201233 seconds\n","Adjusting learning rate of group 0 to 3.1250e-05.\n","SAVING CHECKPOINT\n","Epoch: 22\tBatch: 10\tAvg-Loss: 0.2582\n","Epoch: 22\tBatch: 20\tAvg-Loss: 0.1958\n","Epoch: 22\tBatch: 30\tAvg-Loss: 0.2277\n","Epoch: 22\tBatch: 40\tAvg-Loss: 0.1862\n","Epoch: 22\tBatch: 50\tAvg-Loss: 0.2551\n","Epoch: 22\tBatch: 60\tAvg-Loss: 0.1682\n","Epoch: 22\tBatch: 70\tAvg-Loss: 0.1891\n","Epoch: 22\tBatch: 80\tAvg-Loss: 0.1781\n","Epoch: 22\tBatch: 90\tAvg-Loss: 0.1913\n","Training Time 518.3166315555573 seconds\n","Training Acc: 0.9363665287941457\n","Epoch: 22, Validation Accuracy: 0.55\n","Validation Time 115.07118487358093 seconds\n","Adjusting learning rate of group 0 to 3.1250e-05.\n","SAVING CHECKPOINT\n","Epoch: 23\tBatch: 10\tAvg-Loss: 0.1943\n","Epoch: 23\tBatch: 20\tAvg-Loss: 0.1906\n","Epoch: 23\tBatch: 30\tAvg-Loss: 0.2264\n","Epoch: 23\tBatch: 40\tAvg-Loss: 0.1343\n","Epoch: 23\tBatch: 50\tAvg-Loss: 0.1900\n","Epoch: 23\tBatch: 60\tAvg-Loss: 0.1481\n","Epoch: 23\tBatch: 70\tAvg-Loss: 0.2770\n","Epoch: 23\tBatch: 80\tAvg-Loss: 0.2188\n","Epoch: 23\tBatch: 90\tAvg-Loss: 0.1795\n","Training Time 517.2112398147583 seconds\n","Training Acc: 0.936684696150175\n","Epoch: 23, Validation Accuracy: 0.54\n","Validation Time 114.75530672073364 seconds\n","Adjusting learning rate of group 0 to 1.5625e-05.\n","SAVING CHECKPOINT\n","Epoch: 24\tBatch: 10\tAvg-Loss: 0.2336\n","Epoch: 24\tBatch: 20\tAvg-Loss: 0.1628\n","Epoch: 24\tBatch: 30\tAvg-Loss: 0.2113\n","Epoch: 24\tBatch: 40\tAvg-Loss: 0.1727\n","Epoch: 24\tBatch: 50\tAvg-Loss: 0.1516\n","Epoch: 24\tBatch: 60\tAvg-Loss: 0.1887\n","Epoch: 24\tBatch: 70\tAvg-Loss: 0.1918\n","Epoch: 24\tBatch: 80\tAvg-Loss: 0.1629\n","Epoch: 24\tBatch: 90\tAvg-Loss: 0.1760\n","Training Time 518.0780608654022 seconds\n","Training Acc: 0.9433662106267897\n","Epoch: 24, Validation Accuracy: 0.54\n","Validation Time 115.26877927780151 seconds\n","Adjusting learning rate of group 0 to 1.5625e-05.\n","SAVING CHECKPOINT\n","Epoch: 25\tBatch: 10\tAvg-Loss: 0.1568\n","Epoch: 25\tBatch: 20\tAvg-Loss: 0.1765\n","Epoch: 25\tBatch: 30\tAvg-Loss: 0.1629\n","Epoch: 25\tBatch: 40\tAvg-Loss: 0.1823\n","Epoch: 25\tBatch: 50\tAvg-Loss: 0.2275\n","Epoch: 25\tBatch: 60\tAvg-Loss: 0.1531\n","Epoch: 25\tBatch: 70\tAvg-Loss: 0.1709\n","Epoch: 25\tBatch: 80\tAvg-Loss: 0.1503\n","Epoch: 25\tBatch: 90\tAvg-Loss: 0.2204\n","Training Time 520.2078988552094 seconds\n","Training Acc: 0.9440025453388482\n","Epoch: 25, Validation Accuracy: 0.54\n","Validation Time 115.08199548721313 seconds\n","Adjusting learning rate of group 0 to 1.5625e-05.\n","SAVING CHECKPOINT\n","Epoch: 26\tBatch: 10\tAvg-Loss: 0.1432\n","Epoch: 26\tBatch: 20\tAvg-Loss: 0.1514\n","Epoch: 26\tBatch: 30\tAvg-Loss: 0.1484\n","Epoch: 26\tBatch: 40\tAvg-Loss: 0.1171\n","Epoch: 26\tBatch: 50\tAvg-Loss: 0.1765\n","Epoch: 26\tBatch: 60\tAvg-Loss: 0.1388\n","Epoch: 26\tBatch: 70\tAvg-Loss: 0.1547\n","Epoch: 26\tBatch: 80\tAvg-Loss: 0.2443\n","Epoch: 26\tBatch: 90\tAvg-Loss: 0.2176\n","Training Time 517.0812633037567 seconds\n","Training Acc: 0.9455933821189946\n","Epoch: 26, Validation Accuracy: 0.54\n","Validation Time 115.47751355171204 seconds\n","Adjusting learning rate of group 0 to 1.5625e-05.\n","SAVING CHECKPOINT\n","Epoch: 27\tBatch: 10\tAvg-Loss: 0.1741\n","Epoch: 27\tBatch: 20\tAvg-Loss: 0.2014\n","Epoch: 27\tBatch: 30\tAvg-Loss: 0.1521\n","Epoch: 27\tBatch: 40\tAvg-Loss: 0.1047\n","Epoch: 27\tBatch: 50\tAvg-Loss: 0.1612\n","Epoch: 27\tBatch: 60\tAvg-Loss: 0.1847\n","Epoch: 27\tBatch: 70\tAvg-Loss: 0.1713\n","Epoch: 27\tBatch: 80\tAvg-Loss: 0.1149\n","Epoch: 27\tBatch: 90\tAvg-Loss: 0.1641\n","Training Time 521.0941436290741 seconds\n","Training Acc: 0.9475023862551702\n","Epoch: 27, Validation Accuracy: 0.54\n","Validation Time 115.0781991481781 seconds\n","Adjusting learning rate of group 0 to 7.8125e-06.\n","SAVING CHECKPOINT\n","Epoch: 28\tBatch: 10\tAvg-Loss: 0.1909\n","Epoch: 28\tBatch: 20\tAvg-Loss: 0.1569\n","Epoch: 28\tBatch: 30\tAvg-Loss: 0.1288\n","Epoch: 28\tBatch: 40\tAvg-Loss: 0.1233\n","Epoch: 28\tBatch: 50\tAvg-Loss: 0.1318\n","Epoch: 28\tBatch: 60\tAvg-Loss: 0.1362\n","Epoch: 28\tBatch: 70\tAvg-Loss: 0.1649\n","Epoch: 28\tBatch: 80\tAvg-Loss: 0.1889\n","Epoch: 28\tBatch: 90\tAvg-Loss: 0.1576\n","Training Time 519.4659466743469 seconds\n","Training Acc: 0.9494113903913458\n","Epoch: 28, Validation Accuracy: 0.54\n","Validation Time 115.38869619369507 seconds\n","Adjusting learning rate of group 0 to 7.8125e-06.\n","SAVING CHECKPOINT\n","Epoch: 29\tBatch: 10\tAvg-Loss: 0.1163\n","Epoch: 29\tBatch: 20\tAvg-Loss: 0.1652\n","Epoch: 29\tBatch: 30\tAvg-Loss: 0.1465\n","Epoch: 29\tBatch: 40\tAvg-Loss: 0.1503\n","Epoch: 29\tBatch: 50\tAvg-Loss: 0.1352\n","Epoch: 29\tBatch: 60\tAvg-Loss: 0.1679\n","Epoch: 29\tBatch: 70\tAvg-Loss: 0.1892\n","Epoch: 29\tBatch: 80\tAvg-Loss: 0.1629\n","Epoch: 29\tBatch: 90\tAvg-Loss: 0.1601\n","Training Time 521.2878413200378 seconds\n","Training Acc: 0.9500477251034044\n","Epoch: 29, Validation Accuracy: 0.54\n","Validation Time 115.17765188217163 seconds\n","Adjusting learning rate of group 0 to 7.8125e-06.\n","SAVING CHECKPOINT\n","Epoch: 30\tBatch: 10\tAvg-Loss: 0.1395\n","Epoch: 30\tBatch: 20\tAvg-Loss: 0.1472\n","Epoch: 30\tBatch: 30\tAvg-Loss: 0.0989\n","Epoch: 30\tBatch: 40\tAvg-Loss: 0.2050\n","Epoch: 30\tBatch: 50\tAvg-Loss: 0.1886\n","Epoch: 30\tBatch: 60\tAvg-Loss: 0.1599\n","Epoch: 30\tBatch: 70\tAvg-Loss: 0.1392\n","Epoch: 30\tBatch: 80\tAvg-Loss: 0.1669\n","Epoch: 30\tBatch: 90\tAvg-Loss: 0.1262\n","Training Time 519.2405726909637 seconds\n","Training Acc: 0.9525930639516386\n","Epoch: 30, Validation Accuracy: 0.53\n","Validation Time 115.17853140830994 seconds\n","Adjusting learning rate of group 0 to 7.8125e-06.\n","SAVING CHECKPOINT\n","Epoch: 31\tBatch: 10\tAvg-Loss: 0.1536\n","Epoch: 31\tBatch: 20\tAvg-Loss: 0.1723\n","Epoch: 31\tBatch: 30\tAvg-Loss: 0.1446\n","Epoch: 31\tBatch: 40\tAvg-Loss: 0.0999\n","Epoch: 31\tBatch: 50\tAvg-Loss: 0.1499\n","Epoch: 31\tBatch: 60\tAvg-Loss: 0.1794\n","Epoch: 31\tBatch: 70\tAvg-Loss: 0.1437\n","Epoch: 31\tBatch: 80\tAvg-Loss: 0.1063\n","Epoch: 31\tBatch: 90\tAvg-Loss: 0.1533\n","Training Time 519.6272547245026 seconds\n","Training Acc: 0.9522748965956093\n","Epoch: 31, Validation Accuracy: 0.54\n","Validation Time 115.05147337913513 seconds\n","Adjusting learning rate of group 0 to 3.9063e-06.\n","SAVING CHECKPOINT\n","Epoch: 32\tBatch: 10\tAvg-Loss: 0.1362\n","Epoch: 32\tBatch: 20\tAvg-Loss: 0.1461\n","Epoch: 32\tBatch: 30\tAvg-Loss: 0.1335\n","Epoch: 32\tBatch: 40\tAvg-Loss: 0.1645\n","Epoch: 32\tBatch: 50\tAvg-Loss: 0.1366\n","Epoch: 32\tBatch: 60\tAvg-Loss: 0.1612\n","Epoch: 32\tBatch: 70\tAvg-Loss: 0.1608\n","Epoch: 32\tBatch: 80\tAvg-Loss: 0.1204\n","Epoch: 32\tBatch: 90\tAvg-Loss: 0.1163\n","Training Time 517.0553884506226 seconds\n","Training Acc: 0.9535475660197263\n","Epoch: 32, Validation Accuracy: 0.54\n","Validation Time 115.03737902641296 seconds\n","Adjusting learning rate of group 0 to 3.9063e-06.\n","SAVING CHECKPOINT\n","Epoch: 33\tBatch: 10\tAvg-Loss: 0.1533\n","Epoch: 33\tBatch: 20\tAvg-Loss: 0.1627\n","Epoch: 33\tBatch: 30\tAvg-Loss: 0.1125\n","Epoch: 33\tBatch: 40\tAvg-Loss: 0.1525\n","Epoch: 33\tBatch: 50\tAvg-Loss: 0.1567\n","Epoch: 33\tBatch: 60\tAvg-Loss: 0.1524\n","Epoch: 33\tBatch: 70\tAvg-Loss: 0.1478\n","Epoch: 33\tBatch: 80\tAvg-Loss: 0.1477\n","Epoch: 33\tBatch: 90\tAvg-Loss: 0.1287\n","Training Time 517.4448645114899 seconds\n","Training Acc: 0.9545020680878142\n","Epoch: 33, Validation Accuracy: 0.54\n","Validation Time 114.90940737724304 seconds\n","Adjusting learning rate of group 0 to 3.9063e-06.\n","SAVING CHECKPOINT\n","Epoch: 34\tBatch: 10\tAvg-Loss: 0.1187\n","Epoch: 34\tBatch: 20\tAvg-Loss: 0.1377\n","Epoch: 34\tBatch: 30\tAvg-Loss: 0.1345\n","Epoch: 34\tBatch: 40\tAvg-Loss: 0.1254\n","Epoch: 34\tBatch: 50\tAvg-Loss: 0.1181\n","Epoch: 34\tBatch: 60\tAvg-Loss: 0.1357\n","Epoch: 34\tBatch: 70\tAvg-Loss: 0.1878\n","Epoch: 34\tBatch: 80\tAvg-Loss: 0.1539\n","Epoch: 34\tBatch: 90\tAvg-Loss: 0.1568\n","Training Time 519.7973916530609 seconds\n","Training Acc: 0.955456570155902\n","Epoch: 34, Validation Accuracy: 0.53\n","Validation Time 115.7476634979248 seconds\n","Adjusting learning rate of group 0 to 3.9063e-06.\n","SAVING CHECKPOINT\n","Epoch: 35\tBatch: 10\tAvg-Loss: 0.1114\n","Epoch: 35\tBatch: 20\tAvg-Loss: 0.1770\n","Epoch: 35\tBatch: 30\tAvg-Loss: 0.1272\n","Epoch: 35\tBatch: 40\tAvg-Loss: 0.1191\n","Epoch: 35\tBatch: 50\tAvg-Loss: 0.1293\n","Epoch: 35\tBatch: 60\tAvg-Loss: 0.1308\n","Epoch: 35\tBatch: 70\tAvg-Loss: 0.1120\n","Epoch: 35\tBatch: 80\tAvg-Loss: 0.1603\n","Epoch: 35\tBatch: 90\tAvg-Loss: 0.1727\n","Training Time 521.1082634925842 seconds\n","Training Acc: 0.9538657333757556\n","Epoch: 35, Validation Accuracy: 0.53\n","Validation Time 114.96293711662292 seconds\n","Adjusting learning rate of group 0 to 1.9531e-06.\n","SAVING CHECKPOINT\n","Epoch: 36\tBatch: 10\tAvg-Loss: 0.1264\n","Epoch: 36\tBatch: 20\tAvg-Loss: 0.0991\n","Epoch: 36\tBatch: 30\tAvg-Loss: 0.1561\n","Epoch: 36\tBatch: 40\tAvg-Loss: 0.1435\n","Epoch: 36\tBatch: 50\tAvg-Loss: 0.1497\n","Epoch: 36\tBatch: 60\tAvg-Loss: 0.1353\n","Epoch: 36\tBatch: 70\tAvg-Loss: 0.1711\n","Epoch: 36\tBatch: 80\tAvg-Loss: 0.1598\n","Epoch: 36\tBatch: 90\tAvg-Loss: 0.0919\n","Training Time 517.2465333938599 seconds\n","Training Acc: 0.9557747375119313\n","Epoch: 36, Validation Accuracy: 0.53\n","Validation Time 114.45593976974487 seconds\n","Adjusting learning rate of group 0 to 1.9531e-06.\n","SAVING CHECKPOINT\n","Epoch: 37\tBatch: 10\tAvg-Loss: 0.1608\n","Epoch: 37\tBatch: 20\tAvg-Loss: 0.0933\n","Epoch: 37\tBatch: 30\tAvg-Loss: 0.1148\n","Epoch: 37\tBatch: 40\tAvg-Loss: 0.0974\n","Epoch: 37\tBatch: 50\tAvg-Loss: 0.1430\n","Epoch: 37\tBatch: 60\tAvg-Loss: 0.1285\n","Epoch: 37\tBatch: 70\tAvg-Loss: 0.1690\n","Epoch: 37\tBatch: 80\tAvg-Loss: 0.1476\n","Epoch: 37\tBatch: 90\tAvg-Loss: 0.1524\n","Training Time 518.9679243564606 seconds\n","Training Acc: 0.9551384027998727\n","Epoch: 37, Validation Accuracy: 0.53\n","Validation Time 116.36482572555542 seconds\n","Adjusting learning rate of group 0 to 1.9531e-06.\n","SAVING CHECKPOINT\n","Epoch: 38\tBatch: 10\tAvg-Loss: 0.1581\n","Epoch: 38\tBatch: 20\tAvg-Loss: 0.1641\n","Epoch: 38\tBatch: 30\tAvg-Loss: 0.1134\n","Epoch: 38\tBatch: 40\tAvg-Loss: 0.1324\n","Epoch: 38\tBatch: 50\tAvg-Loss: 0.1503\n","Epoch: 38\tBatch: 60\tAvg-Loss: 0.1597\n","Epoch: 38\tBatch: 70\tAvg-Loss: 0.1045\n","Epoch: 38\tBatch: 80\tAvg-Loss: 0.1333\n","Epoch: 38\tBatch: 90\tAvg-Loss: 0.1315\n","Training Time 522.3369598388672 seconds\n","Training Acc: 0.9564110722239898\n","Epoch: 38, Validation Accuracy: 0.53\n","Validation Time 116.87080311775208 seconds\n","Adjusting learning rate of group 0 to 1.9531e-06.\n","SAVING CHECKPOINT\n","Epoch: 39\tBatch: 10\tAvg-Loss: 0.1303\n","Epoch: 39\tBatch: 20\tAvg-Loss: 0.1271\n","Epoch: 39\tBatch: 30\tAvg-Loss: 0.1681\n","Epoch: 39\tBatch: 40\tAvg-Loss: 0.1035\n","Epoch: 39\tBatch: 50\tAvg-Loss: 0.1321\n","Epoch: 39\tBatch: 60\tAvg-Loss: 0.2058\n","Epoch: 39\tBatch: 70\tAvg-Loss: 0.0923\n","Epoch: 39\tBatch: 80\tAvg-Loss: 0.0964\n","Epoch: 39\tBatch: 90\tAvg-Loss: 0.1924\n","Training Time 525.3870849609375 seconds\n","Training Acc: 0.955456570155902\n","Epoch: 39, Validation Accuracy: 0.53\n","Validation Time 115.90748357772827 seconds\n","Adjusting learning rate of group 0 to 9.7656e-07.\n","SAVING CHECKPOINT\n"]}],"source":["# Train!\n","for epoch in range(num_epochs):\n","    \n","    # Train\n","    model.train()\n","    avg_loss = 0.0\n","    \n","    start_time = time.time()\n","    train_num_correct = 0\n","    \n","    for batch_num, (xbatch, xlen, ybatch) in enumerate(train_loader, 0):\n","        assert(xbatch.shape[2] == 640)\n","        optimizer.zero_grad()\n","        \n","        xbatch, ybatch = xbatch.to(device), ybatch.to(device)\n","\n","#         outputs, _ = network(x)  # returns output, embeddings_out\n","        logits = model(xbatch)  # returns output, embeddings_out_norelu, embeddings_out_relu\n","#         print(\"outputs:\", outputs.shape)\n","#         print(\"argmax of output:\", torch.argmax(outputs, axis=1).shape)\n","#         print(\"y long:\", y.long().shape)\n","        train_num_correct += (torch.argmax(logits, axis=1) == ybatch).sum().item()\n","\n","        loss = criterion(logits, ybatch.long())\n","        loss.backward()\n","        optimizer.step()\n","\n","        avg_loss += loss.item()\n","        training_loss = avg_loss\n","\n","        # if batch_num % 5 == 0:\n","        #     print(\"5 batches have passed\")\n","\n","        if batch_num % 10 == 9:\n","            print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch, batch_num + 1, avg_loss / 10))\n","            training_loss = avg_loss / 10\n","            avg_loss = 0.0\n","            \n","    stop_time = time.time()\n","    print(f\"Training Time {stop_time - start_time} seconds\")\n","    \n","    train_acc = train_num_correct / len(train_dset)\n","    print(f\"Training Acc: {train_acc}\")\n","    \n","    # Validate\n","    model.eval()\n","    num_correct = 0\n","    \n","    start_time = time.time()\n","    \n","    # Validation\n","    for batch_num, (x, xlen, y) in enumerate(val_loader, 0):\n","        x, y = x.to(device), y.to(device)\n","#         outputs, _ = network(x)  # returns output, embeddings\n","        logits = model(x)  # returns output, embeddings_out_norelu, embeddings_out_relu\n","        num_correct += (torch.argmax(logits, axis=1) == y).sum().item()\n","    \n","    val_acc = num_correct / len(val_dset)\n","        \n","    print('Epoch: {}, Validation Accuracy: {:.2f}'.format(epoch, val_acc))\n","    \n","    stop_time = time.time()\n","    print(f\"Validation Time {stop_time - start_time} seconds\")\n","    \n","    # scheduler\n","    # scheduler.step(val_acc)  # don't use with StepLR\n","    scheduler.step()\n","    \n","    # save model\n","    print(\"SAVING CHECKPOINT\")\n","    save_path = os.path.join(\"drive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"saved_models\", f\"run{run_num}\", f\"epoch{epoch}_batchsize{batch_size}_lr{lr}.pth\")\n","    # save_path = os.path.join(\"drive\", \"MyDrive\", \"IDL Project\", \"saved_models\", f\"run{run_num}\", f\"epoch{epoch + num_epochs}_batchsize{batch_size}_lr{lr}.pth\")\n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'train_loss': training_loss,\n","            'train_acc': train_acc,\n","            'val_acc': val_acc,\n","            'scheduler_state_dict': scheduler.state_dict()\n","        }, save_path)"]},{"cell_type":"markdown","metadata":{"id":"bVk_l7aQRtnx"},"source":["## Resume Training if needed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AX86jvCURtGL"},"outputs":[],"source":["resume_net_pth = os.path.join(\"drive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"saved_models\", \"run1\", \"epoch2_batchsize64_lr0.001.pth\")\n","# resume_net_pth = os.path.join(\"drive\", \"MyDrive\", \"IDL Project\", \"saved_models\", \"run1\", \"epoch2_batchsize64_lr0.001.pth\")\n","checkpoint = torch.load(resume_net_pth)\n","model = model.to(device)\n","\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n","\n","add_epochs = 40"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpT48aUOR9uC","outputId":"b0d6116f-0a38-41ba-b5b8-13f2a48fc245"},"outputs":[{"name":"stdout","output_type":"stream","text":["5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 10\tAvg-Loss: 1.6448\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 20\tAvg-Loss: 1.6760\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 30\tAvg-Loss: 1.5691\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 40\tAvg-Loss: 1.6351\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 50\tAvg-Loss: 1.7053\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 60\tAvg-Loss: 1.6685\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 70\tAvg-Loss: 1.6528\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 80\tAvg-Loss: 1.7092\n","5 batches have passed\n","5 batches have passed\n","Epoch: 0\tBatch: 90\tAvg-Loss: 1.6550\n","5 batches have passed\n","Training Time 2337.0674788951874 seconds\n","Training Acc: 0.3176236309326253\n","Epoch: 40, Validation Accuracy: 0.33\n","Validation Time 296.99290442466736 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 10\tAvg-Loss: 1.6275\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 20\tAvg-Loss: 1.6492\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 30\tAvg-Loss: 1.5950\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 40\tAvg-Loss: 1.6081\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 50\tAvg-Loss: 1.6147\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 60\tAvg-Loss: 1.7156\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 70\tAvg-Loss: 1.6717\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 80\tAvg-Loss: 1.6067\n","5 batches have passed\n","5 batches have passed\n","Epoch: 1\tBatch: 90\tAvg-Loss: 1.5445\n","5 batches have passed\n","Training Time 1439.0522384643555 seconds\n","Training Acc: 0.34152007965482906\n","Epoch: 41, Validation Accuracy: 0.34\n","Validation Time 171.29526948928833 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 10\tAvg-Loss: 1.5942\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 20\tAvg-Loss: 1.6075\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 30\tAvg-Loss: 1.6913\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 40\tAvg-Loss: 1.6472\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 50\tAvg-Loss: 1.6168\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 60\tAvg-Loss: 1.6327\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 70\tAvg-Loss: 1.5462\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 80\tAvg-Loss: 1.5768\n","5 batches have passed\n","5 batches have passed\n","Epoch: 2\tBatch: 90\tAvg-Loss: 1.5475\n","5 batches have passed\n","Training Time 1439.704231262207 seconds\n","Training Acc: 0.35313640889478926\n","Epoch: 42, Validation Accuracy: 0.35\n","Validation Time 171.96854519844055 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 10\tAvg-Loss: 1.5557\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 20\tAvg-Loss: 1.5446\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 30\tAvg-Loss: 1.5476\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 40\tAvg-Loss: 1.5437\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 50\tAvg-Loss: 1.5454\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 60\tAvg-Loss: 1.6091\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 70\tAvg-Loss: 1.5084\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 80\tAvg-Loss: 1.5697\n","5 batches have passed\n","5 batches have passed\n","Epoch: 3\tBatch: 90\tAvg-Loss: 1.5491\n","5 batches have passed\n","Training Time 1452.2469654083252 seconds\n","Training Acc: 0.37852638566213076\n","Epoch: 43, Validation Accuracy: 0.36\n","Validation Time 174.12588763237 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 10\tAvg-Loss: 1.4830\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 20\tAvg-Loss: 1.5087\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 30\tAvg-Loss: 1.4974\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 40\tAvg-Loss: 1.5002\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 50\tAvg-Loss: 1.4906\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 60\tAvg-Loss: 1.4349\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 70\tAvg-Loss: 1.5289\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 80\tAvg-Loss: 1.4700\n","5 batches have passed\n","5 batches have passed\n","Epoch: 4\tBatch: 90\tAvg-Loss: 1.5998\n","5 batches have passed\n","Training Time 1466.2885828018188 seconds\n","Training Acc: 0.40989047461002326\n","Epoch: 44, Validation Accuracy: 0.37\n","Validation Time 174.82354760169983 seconds\n","Epoch     8: reducing learning rate of group 0 to 2.0000e-04.\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 10\tAvg-Loss: 1.4295\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 20\tAvg-Loss: 1.4447\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 30\tAvg-Loss: 1.3910\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 40\tAvg-Loss: 1.3998\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 50\tAvg-Loss: 1.3610\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 60\tAvg-Loss: 1.3638\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 70\tAvg-Loss: 1.3709\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 80\tAvg-Loss: 1.4702\n","5 batches have passed\n","5 batches have passed\n","Epoch: 5\tBatch: 90\tAvg-Loss: 1.4025\n","5 batches have passed\n","Training Time 1473.0825181007385 seconds\n","Training Acc: 0.4576833720544308\n","Epoch: 45, Validation Accuracy: 0.39\n","Validation Time 174.96196937561035 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 10\tAvg-Loss: 1.3711\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 20\tAvg-Loss: 1.3421\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 30\tAvg-Loss: 1.2817\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 40\tAvg-Loss: 1.3835\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 50\tAvg-Loss: 1.3058\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 60\tAvg-Loss: 1.3437\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 70\tAvg-Loss: 1.3226\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 80\tAvg-Loss: 1.3351\n","5 batches have passed\n","5 batches have passed\n","Epoch: 6\tBatch: 90\tAvg-Loss: 1.3500\n","5 batches have passed\n","Training Time 1472.4576539993286 seconds\n","Training Acc: 0.48788582807832725\n","Epoch: 46, Validation Accuracy: 0.38\n","Validation Time 175.29549837112427 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 10\tAvg-Loss: 1.2976\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 20\tAvg-Loss: 1.2767\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 30\tAvg-Loss: 1.2911\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 40\tAvg-Loss: 1.2695\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 50\tAvg-Loss: 1.2727\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 60\tAvg-Loss: 1.2922\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 70\tAvg-Loss: 1.2685\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 80\tAvg-Loss: 1.2945\n","5 batches have passed\n","5 batches have passed\n","Epoch: 7\tBatch: 90\tAvg-Loss: 1.3069\n","5 batches have passed\n","Training Time 1476.0328013896942 seconds\n","Training Acc: 0.5092930633919681\n","Epoch: 47, Validation Accuracy: 0.37\n","Validation Time 176.2683277130127 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 10\tAvg-Loss: 1.1727\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 20\tAvg-Loss: 1.2898\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 30\tAvg-Loss: 1.2700\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 40\tAvg-Loss: 1.2328\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 50\tAvg-Loss: 1.2582\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 60\tAvg-Loss: 1.1791\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 70\tAvg-Loss: 1.1991\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 80\tAvg-Loss: 1.2473\n","5 batches have passed\n","5 batches have passed\n","Epoch: 8\tBatch: 90\tAvg-Loss: 1.1737\n","5 batches have passed\n","Training Time 1470.7572433948517 seconds\n","Training Acc: 0.5406571523398606\n","Epoch: 48, Validation Accuracy: 0.35\n","Validation Time 175.91502594947815 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 10\tAvg-Loss: 1.1930\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 20\tAvg-Loss: 1.1287\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 30\tAvg-Loss: 1.1742\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 40\tAvg-Loss: 1.1395\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 50\tAvg-Loss: 1.1522\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 60\tAvg-Loss: 1.1428\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 70\tAvg-Loss: 1.2349\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 80\tAvg-Loss: 1.1954\n","5 batches have passed\n","5 batches have passed\n","Epoch: 9\tBatch: 90\tAvg-Loss: 1.1475\n","5 batches have passed\n","Training Time 1443.563535451889 seconds\n","Training Acc: 0.5692001327580485\n","Epoch: 49, Validation Accuracy: 0.37\n","Validation Time 169.90438652038574 seconds\n","Epoch    13: reducing learning rate of group 0 to 4.0000e-05.\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 10\tAvg-Loss: 1.1447\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 20\tAvg-Loss: 1.0770\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 30\tAvg-Loss: 0.9366\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 40\tAvg-Loss: 1.0001\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 50\tAvg-Loss: 1.0326\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 60\tAvg-Loss: 1.0702\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 70\tAvg-Loss: 0.9952\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 80\tAvg-Loss: 1.0343\n","5 batches have passed\n","5 batches have passed\n","Epoch: 10\tBatch: 90\tAvg-Loss: 1.0374\n","5 batches have passed\n","Training Time 1435.5043556690216 seconds\n","Training Acc: 0.6208098240955858\n","Epoch: 50, Validation Accuracy: 0.38\n","Validation Time 169.86569833755493 seconds\n","SAVING CHECKPOINT\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 10\tAvg-Loss: 1.0206\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 20\tAvg-Loss: 0.9941\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 30\tAvg-Loss: 1.0075\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 40\tAvg-Loss: 0.9887\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 50\tAvg-Loss: 1.0013\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 60\tAvg-Loss: 0.9496\n","5 batches have passed\n","5 batches have passed\n","Epoch: 11\tBatch: 70\tAvg-Loss: 1.0243\n","5 batches have passed\n","5 batches have passed\n"]}],"source":["for epoch in range(add_epochs):\n","    \n","    # Train\n","    model.train()\n","    avg_loss = 0.0\n","    \n","    start_time = time.time()\n","    train_num_correct = 0\n","    \n","    for batch_num, (xbatch, xlen, ybatch) in enumerate(train_loader, 0):\n","        assert(xbatch.shape[2] == 640)\n","        optimizer.zero_grad()\n","        \n","        xbatch, ybatch = xbatch.to(device), ybatch.to(device)\n","\n","#         outputs, _ = network(x)  # returns output, embeddings_out\n","        logits = model(xbatch)  # returns output, embeddings_out_norelu, embeddings_out_relu\n","#         print(\"outputs:\", outputs.shape)\n","#         print(\"argmax of output:\", torch.argmax(outputs, axis=1).shape)\n","#         print(\"y long:\", y.long().shape)\n","        train_num_correct += (torch.argmax(logits, axis=1) == ybatch).sum().item()\n","\n","        loss = criterion(logits, ybatch.long())\n","        loss.backward()\n","        optimizer.step()\n","\n","        avg_loss += loss.item()\n","        training_loss = avg_loss\n","\n","        if batch_num % 5 == 0:\n","            print(\"5 batches have passed\")\n","\n","        if batch_num % 10 == 9:\n","            print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch, batch_num + 1, avg_loss / 10))\n","            training_loss = avg_loss / 10\n","            avg_loss = 0.0\n","            \n","    stop_time = time.time()\n","    print(f\"Training Time {stop_time - start_time} seconds\")\n","    \n","    train_acc = train_num_correct / len(train_dset)\n","    print(f\"Training Acc: {train_acc}\")\n","    \n","    # Validate\n","    model.eval()\n","    num_correct = 0\n","    \n","    start_time = time.time()\n","    \n","    # Validation\n","    for batch_num, (x, xlen, y) in enumerate(val_loader, 0):\n","        x, y = x.to(device), y.to(device)\n","#         outputs, _ = network(x)  # returns output, embeddings\n","        logits = model(x)  # returns output, embeddings_out_norelu, embeddings_out_relu\n","        num_correct += (torch.argmax(logits, axis=1) == y).sum().item()\n","    \n","    val_acc = num_correct / len(val_dset)\n","        \n","    print('Epoch: {}, Validation Accuracy: {:.2f}'.format(epoch + num_epochs, val_acc))\n","    \n","    stop_time = time.time()\n","    print(f\"Validation Time {stop_time - start_time} seconds\")\n","    \n","    # scheduler\n","    scheduler.step(val_acc)\n","    \n","    # save model\n","    print(\"SAVING CHECKPOINT\")\n","    save_path = os.path.join(\"drive\", \"MyDrive\", \"18786 IDL\", \"IDL Project\", \"saved_models\", f\"run{run_num}\", f\"epoch{epoch + num_epochs}_batchsize{batch_size}_lr{lr}.pth\")\n","    # save_path = os.path.join(\"drive\", \"MyDrive\", \"IDL Project\", \"saved_models\", f\"run{run_num}\", f\"epoch{epoch + num_epochs}_batchsize{batch_size}_lr{lr}.pth\")\n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'train_loss': training_loss,\n","            'train_acc': train_acc,\n","            'val_acc': val_acc,\n","            'scheduler_state_dict': scheduler.state_dict()\n","        }, save_path)"]},{"cell_type":"markdown","metadata":{"id":"S47ItualGGJA"},"source":["# Inference on Test Set"]},{"cell_type":"markdown","metadata":{"id":"0EnR7MojGIVi"},"source":["## test loader"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":171,"status":"ok","timestamp":1636065522010,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"G-nEsmOkGKuI"},"outputs":[],"source":["# test loader\n","test_dset = MyDataset(test_list_paths, test_list_labels)\n","test_args = dict(shuffle=False, batch_size=32, num_workers=2, collate_fn=pad_collate, drop_last=True)\n","test_loader = DataLoader(test_dset, **test_args)"]},{"cell_type":"markdown","metadata":{"id":"0WpQkEQpGsme"},"source":["## load model for inference"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1636066222126,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"RpQeSNbZGt3K"},"outputs":[],"source":["load_pth = \"/content/drive/MyDrive/18786 IDL/IDL Project/saved_models/run3/epoch10_batchsize32_lr0.001.pth\""]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2503,"status":"ok","timestamp":1636066226323,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"XTuv6XlvG2xO","outputId":"b3f9b3fe-6716-4ff4-81e9-ba8f3c36cfc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.4896142433234421\n"]}],"source":["checkpoint = torch.load(load_pth)\n","print(checkpoint[\"val_acc\"])"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1636066228999,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"GNLwCIo7G4m6","outputId":"15560aae-30df-4737-e04f-02f006b85d4b"},"outputs":[{"data":{"text/plain":["BaseLSTM(\n","  (lstm): LSTM(640, 512, num_layers=3, dropout=0.1, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=4, bias=True)\n",")"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["model = BaseLSTM(num_layers=3, num_classes=4, input_size=640, hidden_size=512, dropout=0.1, bidirectional=True)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"VA2W6RxQHS8G"},"source":["## get test accuracy"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1636066232405,"user":{"displayName":"Gore Kao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18383709196133675783"},"user_tz":240},"id":"M-A7oAvUHUIj"},"outputs":[],"source":["def get_test_acc(model_pth, test_loader):\n","    checkpoint = torch.load(model_pth)\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","\n","    model.eval()\n","    test_num_correct = 0\n","    total = 0\n","    for batch_num, (x, lengths, y) in enumerate(test_loader):\n","        x = x.to(device)\n","        y = y.long().to(device)\n","\n","        logits = model(x, lengths)\n","        test_num_correct += (torch.argmax(logits, axis=1) == y).sum().item()\n","        total += len(y)\n","\n","    test_acc = test_num_correct / total\n","    return test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1ito1DhHWQ7"},"outputs":[],"source":["test_acc = get_test_acc(load_pth, test_loader)\n","print(test_acc)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"baseline.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
