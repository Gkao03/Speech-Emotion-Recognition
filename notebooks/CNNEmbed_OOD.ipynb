{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16279,"status":"ok","timestamp":1638375587798,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"HJkp8FiNBW2D","outputId":"ed465aa9-5d48-4ff0-ed56-913d5d992c06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5390,"status":"ok","timestamp":1638375596581,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"x5pGdNEtDO1j","outputId":"1b8218d9-8ed1-4398-dda0-0af226b00351"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting allosaurus\n","  Downloading allosaurus-1.0.2-py3-none-any.whl (52 kB)\n","\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 40 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 807 kB/s \n","\u001b[?25hRequirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.4.1)\n","Collecting panphon\n","  Downloading panphon-0.19-py2.py3-none-any.whl (72 kB)\n","\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 44.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 30 kB 50.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 40 kB 56.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 51 kB 58.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 61 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 71 kB 62.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 642 kB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.5.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.10.0+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.19.5)\n","Collecting unicodecsv\n","  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n","Collecting munkres\n","  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (57.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (3.13)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (2019.12.20)\n","Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (0.51.2)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (1.15.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy->allosaurus) (0.34.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->allosaurus) (3.10.0.2)\n","Building wheels for collected packages: unicodecsv\n","  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10765 sha256=adcb8b57c99144a5151845e536c0b6a44b5a6155e3d25890b6383186c0d4127c\n","  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n","Successfully built unicodecsv\n","Installing collected packages: unicodecsv, munkres, panphon, allosaurus\n","Successfully installed allosaurus-1.0.2 munkres-1.1.4 panphon-0.19 unicodecsv-0.14.1\n"]}],"source":["!pip install allosaurus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-k-7oiYQ4Ivx"},"outputs":[],"source":["#These libraries help to interact with the operating system and the runtime environment respectively\n","import os\n","import sys\n","import pickle\n","\n","#Model/Training related libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","\n","#Dataloader libraries\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Transforms and datasets\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dset\n","\n","import time\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pandas as pd\n","from tqdm import tqdm\n","import random\n","\n","# Allosaurus\n","from allosaurus.audio import read_audio\n","from allosaurus.app import read_recognizer\n","from allosaurus.am.utils import *\n","\n","\n","# Cross validation\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3438,"status":"ok","timestamp":1638375608424,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"scRMPhAs_9ig","outputId":"33e3c5cf-dd60-4534-d7eb-f0f52165498b"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading model  latest\n","from:  https://github.com/xinjli/allosaurus/releases/download/v1.0/latest.tar.gz\n","to:    /usr/local/lib/python3.7/dist-packages/allosaurus/pretrained\n","please wait...\n"]}],"source":["recognizer = read_recognizer()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip \"/content/gdrive/MyDrive/intro_to_deeplearning/Project/Data/AESDD_mod.zip\" -d \"/content/\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Rough Quick Work\n","\n","\n","# {'happiness': 0, 'sadness': 1, 'anger': 2, 'disgust': 3, 'fear': 4}\n","\n","# mypath=\"/content/AESDD_mod/\"\n","# from os import listdir\n","# from os.path import isfile, join\n","\n","# file_paths=[]\n","# labels=[]\n","# for i in listdir(mypath):\n","#   for j in listdir(mypath+str(i)):\n","\n","#     if (i!=\"Tools and Documentation\"):n\n","\n","#       if(i==\"happiness\"): \n","#         file_paths.append(mypath+str(i)+\"/\" + str(j))\n","#         labels.append(0)\n","#       if(i==\"sadness\"): \n","#         file_paths.append(mypath+str(i)+\"/\" + str(j))\n","#         labels.append(1)\n","#       if(i==\"anger\"): \n","#         file_paths.append(mypath+str(i)+\"/\" + str(j))\n","#         labels.append(2)\n","#       if(i==\"disgust\"): \n","#         file_paths.append(mypath+str(i)+\"/\" + str(j))\n","#         labels.append(3)\n","#       if(i==\"fear\"): \n","#         file_paths.append(mypath+str(i)+\"/\" + str(j))\n","#         labels.append(4)\n","      \n","# print(file_paths[0])\n","\n","# total_instances = len(file_paths)\n","# print(total_instances)\n","\n","# print(file_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McAqWoZr5Rmt"},"outputs":[],"source":["data_dir = \"/content/AESDD_mod\"\n","mapping = {'happiness': 0, 'sadness': 1, 'anger': 2, 'disgust': 3, 'fear': 4}\n","mapping2 = {'h': 0, 's': 1, 'a': 2, 'd': 3, 'f': 4}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmCls_p45Nkx"},"outputs":[],"source":["def parse_data(data_dir):\n","    file_paths = []  # full file paths from drive to wav file\n","    labels = []  # corresponding labels\n","\n","    for root, directories, filenames in os.walk(data_dir):\n","            for filename in filenames:\n","                if filename.endswith('.wav') and filename[0] != '.':\n","                    abbrev = filename[0]\n","                    label = mapping2[abbrev]\n","                    path = os.path.join(root, filename)\n","\n","                    file_paths.append(path)\n","                    labels.append(label)\n","\n","    return file_paths, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142,"status":"ok","timestamp":1638375621533,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"9ObR5Ger5s6p","outputId":"8e93c0f5-32a5-4973-e091-af03bbc02940"},"outputs":[{"name":"stdout","output_type":"stream","text":["['/content/AESDD_mod/fear/f15 (5).wav']\n","[4]\n","604\n","604\n"]}],"source":["file_paths, labels = parse_data(data_dir)\n","print(file_paths[123:124])\n","print(labels[123:124])\n","print(len(file_paths))\n","print(len(labels))\n","total_instances = len(file_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD8BGKJGwhYD"},"outputs":[],"source":["# emotion_to_label = {'happiness': 0, 'sadness': 1, 'anger': 2, 'disgust': 3, 'fear': 4}\n","# label_to_emotion = {v: k for k, v in emotion_to_label.items()}\n","# print(emotion_to_label)\n","# print(label_to_emotion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAPXqH0zAKHk","outputId":"7e8ba1dd-56d5-4354-ca00-01b3991d5906"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","{0: 'neu', 1: 'hap', 2: 'sad', 3: 'ang'}\n","Counter({'neu': 1708, 'ang': 1103, 'sad': 1084, 'hap': 595})\n"]}],"source":["# from collections import Counter\n","\n","# # get unique emotions\n","# # emotion_to_label = {'neu': 0, 'fru': 1, 'sad': 2, 'sur': 3, 'ang': 4, 'hap': 5, 'exc': 6, 'fea': 7, 'dis': 8, 'oth': 9}\n","# emotion_to_label = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n","# label_to_emotion = {v: k for k, v in emotion_to_label.items()}\n","# print(emotion_to_label)\n","# print(label_to_emotion)\n","\n","# # counter number of class instances\n","# emotion_instances_list = [v for v in file_to_emotion.values()]\n","# counter = Counter(emotion_instances_list)\n","# print(counter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3di3Mr5rRG4"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, file_list, target_list):\n","        \n","        self.file_list = file_list\n","        self.target_list = target_list\n","        self.num_classes = len(list(set(target_list)))\n","\n","        self.x = file_list\n","        self.y = target_list\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        filepath = self.file_list[index]\n","        x = torch.tensor(recognizer.pm.compute(read_audio(filepath)))\n","        x = x.detach()\n","        x_len = torch.tensor(np.array([x.shape[0]], dtype=np.int32))\n","        x_len = x_len.detach()\n","        y = torch.Tensor([self.target_list[index]])\n","        return x, x_len, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AK8jRp6isDN2"},"outputs":[],"source":["# collate function\n","def pad_collate(batch):\n","\n","    # batch looks like [(x0, xlen0, y0), (x4, xlen4, y4), (x2, xlen2, y2)... ]\n","    feats = [sample[0] for sample in batch]\n","    feat_lens = [sample[1] for sample in batch]\n","    target_list = torch.Tensor([sample[2] for sample in batch])\n","\n","    feats = pad_sequence(feats, batch_first=True, padding_value=0) # batch, features, len\n","    feat_lens = pad_sequence(feat_lens, batch_first=True, padding_value=0).squeeze()\n","    idx = torch.argsort(feat_lens, descending=True) # sorting the input in descending order as required by the lstms in AM.\n","\n","    targets = target_list[idx]\n","    tensor_batch_feat, tensor_batch_feat_len = move_to_tensor([feats[idx], feat_lens[idx]], device_id=-1) # converting to the required tensors\n","\n","    # Features\n","    output_tensor, input_lengths = recognizer.am(tensor_batch_feat, tensor_batch_feat_len, return_lstm=True)# output_shape: [len,batch,features]\n","    output_tensor = output_tensor.permute(1,2,0)\n","    output_tensor = output_tensor.detach()\n","    input_lengths = input_lengths.detach()\n","    \n","    return output_tensor, input_lengths, targets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1638375629842,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"abbkoaDuscWe","outputId":"524835dd-0d15-45a8-80fd-010b18d54077"},"outputs":[{"name":"stdout","output_type":"stream","text":["number training instances: 483\n","number validation instances: 60\n","number test instances: 61\n"]}],"source":["num_train = round(0.8 * total_instances)\n","num_test_all = total_instances - num_train\n","num_val = round(0.5 * num_test_all)\n","num_test = num_test_all - num_val\n","\n","print(\"number training instances:\", str(num_train))\n","print(\"number validation instances:\", str(num_val))\n","print(\"number test instances:\", str(num_test))\n","\n","assert(num_train + num_val + num_test == total_instances)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw3Mh8bpsYc9"},"outputs":[],"source":["# Slightly modified unison shuffle data usin sklearn methods\n","from sklearn.utils import shuffle\n","\n","shuffled_data_paths, shuffled_labels = shuffle(file_paths,labels,random_state=0)\n","\n","train_list_paths = shuffled_data_paths[:num_train]\n","testall_list_paths = shuffled_data_paths[num_train:]\n","val_list_paths = testall_list_paths[:num_val]\n","test_list_paths = testall_list_paths[num_test:]\n","\n","assert(len(train_list_paths) + len(val_list_paths) + len(test_list_paths)+1  == total_instances)\n","\n","train_labels = shuffled_labels[:num_train]\n","testall_labels = shuffled_labels[num_train:]\n","val_labels = testall_labels[:num_val]\n","test_labels = testall_labels[num_test:]\n","\n","\n","assert(len(train_labels) + len(val_labels) + len(test_labels) +1 == total_instances)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6L5WOufrx7i"},"outputs":[],"source":["##Implemented it slightly differently \n","\n","# get corresponding labels for data\n","# train_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in train_list_paths]\n","# val_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in val_list_paths]\n","# test_list_labels = [file_to_label[filepath.split('/')[-1]] for filepath in test_list_paths]\n","\n","# assert(len(train_list_labels) == len(train_list_paths))\n","# assert(len(val_list_labels) == len(val_list_paths))\n","# assert(len(test_list_labels) == len(test_list_paths))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_V9_bpjrxg8"},"outputs":[],"source":["# train dataloader\n","train_dset = MyDataset(train_list_paths, train_labels)\n","train_args = dict(shuffle=True, batch_size=32, num_workers=4, collate_fn=pad_collate, drop_last=True)  # change to num_workers=4 on diff platform\n","train_loader = DataLoader(train_dset, **train_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ktxCl_ZftaMl"},"outputs":[],"source":["# val dataloader\n","val_dset = MyDataset(val_list_paths, val_labels)\n","val_args = dict(shuffle=False, batch_size=32, num_workers=4, collate_fn=pad_collate, drop_last=True)\n","val_loader = DataLoader(val_dset, **val_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xh_xwODor_O9"},"outputs":[],"source":["#  def get_k_folder(k, i):\n","#   n = num_train+num_val\n","#   train_val_list_paths = shuffled_data_paths[:n]\n","#   fold_size = n // k\n","\n","#   train_list_paths.append(train_val_list_paths[i*fold_size+fold_size:n])\n","#   val_list_paths.append(train_val_list_paths[i*fold_size:min(i*fold_size+fold_size, n)])\n","\n","#   return train_list_paths, val_list_paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ts2DKMHRymHL"},"outputs":[],"source":["#shuffled paths\n","\n","complete_paths=train_list_paths+val_list_paths\n","complete_labels= train_labels + val_labels\n","complete_dataset=MyDataset(complete_paths,complete_labels)\n","\n","\n","complete_paths_lst=([i for i in complete_paths])\n","complete_labels_lst=([i for i in complete_labels])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qnmbsoWYLKY"},"outputs":[],"source":["def kfoldSKLearn(kValue, currentFold,dataset):\n","  # testing k-fold function\n","  k_folds = kValue\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=k_folds, shuffle=False)\n","  train_paths=[]\n","  val_paths=[]\n","  train_labels=[]\n","  val_labels=[]\n","  print(\"K FOLD FUNCTION ACCESSED\")\n","  for fold, (train_ids, val_ids) in enumerate(kfold.split(complete_dataset)):\n","      \n","      train_paths.append([complete_paths_lst[i] for i in train_ids ])\n","      val_paths.append([complete_paths_lst[i] for i in val_ids ])\n","      \n","      train_labels.append([complete_labels_lst[i] for i in train_ids ])\n","      val_labels.append([complete_labels_lst[i] for i in val_ids ])\n","  # print(val_paths[currentFold])\n","  # print(train_paths[currentFold])\n","  train_dset = MyDataset(train_paths[currentFold], train_labels[currentFold])\n","  train_args = dict(shuffle=True, batch_size=32, num_workers=2, collate_fn=pad_collate, drop_last=True)  # change to num_workers=4 on diff platform\n","  train_loader = DataLoader(train_dset, **train_args)\n","\n","  val_dset = MyDataset(val_paths[currentFold], val_labels[currentFold])\n","  val_args = dict(shuffle=False, batch_size=32, num_workers=2, collate_fn=pad_collate, drop_last=True)\n","  val_loader = DataLoader(val_dset, **val_args)\n","\n","  return train_loader,val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8ZIiO_l6-i4"},"outputs":[],"source":["class CNNModel(nn.Module):\n","    def __init__(self, in_channels =640, out_channels = 256, layers=4, label_size=5):\n","        super().__init__()\n","\n","        self.layers = layers\n","        kernel = [3,5,7,9]\n","        dil = [1,2,3,4]\n","        pad = []\n","        for i in range(4):\n","          out = int(kernel[i]/2) * (dil[i])\n","          pad.append(out)\n","        \n","        if layers >=1:\n","          self.layer1 = nn.Sequential(\n","                            nn.Conv1d(in_channels, out_channels, kernel_size=int(kernel[0]), stride=1, padding=int(pad[0]), dilation=int(dil[0]), bias=False),\n","                            nn.BatchNorm1d(out_channels),\n","                            nn.ReLU(),\n","                            nn.Dropout(p=0.2))\n","    \n","\n","        if layers >=2:\n","          self.layer2 = nn.Sequential(\n","                            nn.Conv1d(out_channels, out_channels, kernel_size=kernel[1], stride=1, padding=pad[1], dilation=dil[1], bias=False),\n","                            nn.BatchNorm1d(out_channels),\n","                            nn.ReLU(),\n","                            nn.Dropout(p=0.4))\n","\n","        if layers >=3:\n","          self.layer3 = nn.Sequential(\n","                            nn.Conv1d(out_channels, out_channels, kernel_size=kernel[2], stride=1, padding=pad[2], dilation=dil[2], bias=False),\n","                            nn.BatchNorm1d(out_channels),\n","                            nn.ReLU(),\n","                            nn.Dropout(p=0.4))\n","\n","        if layers >=4:\n","          self.layer4 = nn.Sequential(\n","                            nn.Conv1d(out_channels, out_channels // 4, kernel_size=kernel[3], stride=1, padding=pad[3], dilation=dil[3], bias=False),\n","                            nn.BatchNorm1d(out_channels // 4),\n","                            nn.ReLU(),\n","                            nn.Dropout(p=0.4))\n","            \n","        self.avg_pool  = nn.Sequential(nn.AdaptiveAvgPool1d(4))\n","\n","        self.last = nn.Sequential(nn.Dropout(p=0.5),nn.Flatten())\n","\n","        if layers<=3: \n","          self.linear = nn.Linear(in_features = out_channels * 4, out_features = label_size)\n","        else: \n","          self.linear = nn.Linear(in_features = out_channels//4 * 4, out_features = label_size)\n","\n","\n","    def forward(self, input, lengths):\n","      \n","      out = self.layer1(input)\n","      if self.layers >=2:\n","        out = self.layer2(out)\n","      if self.layers >=3:\n","        out = self.layer3(out)\n","      if self.layers >=4:\n","        out = self.layer4(out)\n","\n","      out = self.avg_pool(out)\n","\n","      out = self.last(out)\n","\n","      logits = self.linear(out)\n","      return logits"]},{"cell_type":"markdown","metadata":{"id":"KZAxmuMs8jAa"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMCs_r1t8g5O"},"outputs":[],"source":["def train_model(train_loader, model, opt, criterion, device):\n","\n","    loss_accum = 0.0\n","    batch_cnt = 0\n","\n","    acc_cnt = 0     #count correct predictions\n","    err_cnt = 0     #count incorrect predictions\n","\n","    model.train()\n","    start_time = time.time()\n","    for batch, (x, lengths, y) in enumerate(train_loader):\n","        x = x.to(device)\n","        #lengths = lengths.to(device)\n","        y = y.long().to(device)\n","        opt.zero_grad()\n","\n","        # print(x.shape)\n","        # print(y.shape)\n","\n","        logits = model(x, lengths)\n","\n","        loss = criterion(logits, y)\n","        loss_score = loss.cpu().item()\n","\n","        loss_accum += loss_score\n","        batch_cnt += 1\n","        loss.backward()\n","        opt.step()\n","\n","        #model outputs\n","        out_val, out_indices = torch.max(logits, dim=1)\n","        tar_indices = y\n","\n","        for i in range(len(out_indices)):\n","            if out_indices[i] == tar_indices[i]:\n","                acc_cnt += 1\n","            else:\n","                err_cnt += 1\n","                     \n","    training_accuracy =  acc_cnt/(err_cnt+acc_cnt) \n","    training_loss = loss_accum / batch_cnt\n","        \n","    return model, training_accuracy, training_loss\n","\n","\n","def test_model(loader, model, opt, criterion, device):\n","    model.eval()\n","    acc_cnt = 0\n","    err_cnt = 0\n","\n","    for x, lengths, y in loader:\n","        \n","        x = x.to(device)\n","        y = y.long().to(device)\n","        \n","        logits = model(x, lengths)\n","\n","        out_val, out_indices = torch.max(logits, dim=1)\n","        tar_indices = y\n","\n","        for i in range(len(out_indices)):\n","            if out_indices[i] == tar_indices[i]:\n","                acc_cnt += 1\n","            else:\n","                err_cnt += 1\n","\n","    current_acc = acc_cnt/(err_cnt+acc_cnt)\n","    \n","    return current_acc"]},{"cell_type":"markdown","metadata":{"id":"aAOlPe9g80N_"},"source":["## Main runner"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXwYXAdJ2DLN"},"outputs":[],"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","criterion = nn.CrossEntropyLoss()\n","# print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdP3rmfGl9Ll"},"outputs":[],"source":["def reset_weights(m):\n","    if isinstance(m, (nn.Conv1d, nn.Linear, nn.BatchNorm1d)):\n","        m.reset_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1638376874894,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"dsl6-R0b2GZw","outputId":"12f6962f-556e-4827-ab16-eff202d23ad3"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJCPGtZywCmc"},"outputs":[],"source":["file1 = open(\"/content/gdrive/MyDrive/intro_to_deeplearning/Project/Pure_CNN/log/log.txt\",\"a+\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5984393,"status":"ok","timestamp":1638383097769,"user":{"displayName":"Samarth Thopaiah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNnhPYuCBHJ92MYpqjSfXB-tjc6vlAGLhbvyytLQ=s64","userId":"05083263964626222577"},"user_tz":300},"id":"FyMP1HFp8y6C","outputId":"b8f3c627-12fc-44de-f8e6-14be95e50d80"},"outputs":[{"name":"stdout","output_type":"stream","text":["CNNModel(\n","  (layer1): Sequential(\n","    (0): Conv1d(640, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.2, inplace=False)\n","  )\n","  (layer2): Sequential(\n","    (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,), bias=False)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.4, inplace=False)\n","  )\n","  (layer3): Sequential(\n","    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,), bias=False)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.4, inplace=False)\n","  )\n","  (avg_pool): Sequential(\n","    (0): AdaptiveAvgPool1d(output_size=4)\n","  )\n","  (last): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Flatten(start_dim=1, end_dim=-1)\n","  )\n","  (linear): Linear(in_features=1024, out_features=5, bias=True)\n",")\n",".........Running 0th cross validation.......\n","K FOLD FUNCTION ACCESSED\n","Epoch: 0, Fold: 0, Training Accuracy: 0.26988636363636365, Training loss:1.6233478025956587, Validation accuracy:0.21875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 1, Fold: 0, Training Accuracy: 0.4119318181818182, Training loss:1.4311881065368652, Validation accuracy:0.36875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 2, Fold: 0, Training Accuracy: 0.4630681818181818, Training loss:1.2730732831087979, Validation accuracy:0.4125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 3, Fold: 0, Training Accuracy: 0.5142045454545454, Training loss:1.1354658657854253, Validation accuracy:0.45625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 4, Fold: 0, Training Accuracy: 0.5965909090909091, Training loss:0.9877106276425448, Validation accuracy:0.51875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 5, Fold: 0, Training Accuracy: 0.6420454545454546, Training loss:0.9732995412566445, Validation accuracy:0.46875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 6, Fold: 0, Training Accuracy: 0.6534090909090909, Training loss:0.9265050400387157, Validation accuracy:0.5125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 7, Fold: 0, Training Accuracy: 0.6619318181818182, Training loss:0.9027446833523837, Validation accuracy:0.5625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 8, Fold: 0, Training Accuracy: 0.6846590909090909, Training loss:0.9022322730584578, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 9, Fold: 0, Training Accuracy: 0.6818181818181818, Training loss:0.8992345333099365, Validation accuracy:0.54375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 10, Fold: 0, Training Accuracy: 0.6590909090909091, Training loss:0.9061299833384427, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 11, Fold: 0, Training Accuracy: 0.6590909090909091, Training loss:0.8972099044106223, Validation accuracy:0.5375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 12, Fold: 0, Training Accuracy: 0.6789772727272727, Training loss:0.8940545645627108, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 13, Fold: 0, Training Accuracy: 0.6875, Training loss:0.9105517918413336, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 14, Fold: 0, Training Accuracy: 0.6818181818181818, Training loss:0.9209215370091525, Validation accuracy:0.55625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 15, Fold: 0, Training Accuracy: 0.6789772727272727, Training loss:0.8943212845108726, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 16, Fold: 0, Training Accuracy: 0.6420454545454546, Training loss:0.9043947837569497, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 17, Fold: 0, Training Accuracy: 0.6590909090909091, Training loss:0.895683694969524, Validation accuracy:0.55\n","K FOLD FUNCTION ACCESSED\n","Epoch: 18, Fold: 0, Training Accuracy: 0.6363636363636364, Training loss:0.9060147783973, Validation accuracy:0.55625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 19, Fold: 0, Training Accuracy: 0.6846590909090909, Training loss:0.8868170380592346, Validation accuracy:0.5375\n",".........Running 1th cross validation.......\n","K FOLD FUNCTION ACCESSED\n","Epoch: 0, Fold: 1, Training Accuracy: 0.29545454545454547, Training loss:1.6435611573132602, Validation accuracy:0.30625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 1, Fold: 1, Training Accuracy: 0.3778409090909091, Training loss:1.4591906504197554, Validation accuracy:0.4375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 2, Fold: 1, Training Accuracy: 0.4602272727272727, Training loss:1.2627795934677124, Validation accuracy:0.4125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 3, Fold: 1, Training Accuracy: 0.5625, Training loss:1.0531193830750205, Validation accuracy:0.36875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 4, Fold: 1, Training Accuracy: 0.6704545454545454, Training loss:0.9018770347942006, Validation accuracy:0.5125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 5, Fold: 1, Training Accuracy: 0.6931818181818182, Training loss:0.8549700379371643, Validation accuracy:0.48125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 6, Fold: 1, Training Accuracy: 0.7215909090909091, Training loss:0.807489275932312, Validation accuracy:0.50625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 7, Fold: 1, Training Accuracy: 0.6931818181818182, Training loss:0.8225859457796271, Validation accuracy:0.53125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 8, Fold: 1, Training Accuracy: 0.7130681818181818, Training loss:0.7893020727417686, Validation accuracy:0.525\n","K FOLD FUNCTION ACCESSED\n","Epoch: 9, Fold: 1, Training Accuracy: 0.6960227272727273, Training loss:0.822555276480588, Validation accuracy:0.53125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 10, Fold: 1, Training Accuracy: 0.6931818181818182, Training loss:0.8115502595901489, Validation accuracy:0.5375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 11, Fold: 1, Training Accuracy: 0.6988636363636364, Training loss:0.809507283297452, Validation accuracy:0.51875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 12, Fold: 1, Training Accuracy: 0.6931818181818182, Training loss:0.807381581176411, Validation accuracy:0.53125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 13, Fold: 1, Training Accuracy: 0.7159090909090909, Training loss:0.7844903469085693, Validation accuracy:0.525\n","K FOLD FUNCTION ACCESSED\n","Epoch: 14, Fold: 1, Training Accuracy: 0.7386363636363636, Training loss:0.7710252458398993, Validation accuracy:0.53125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 15, Fold: 1, Training Accuracy: 0.6988636363636364, Training loss:0.7957663481885736, Validation accuracy:0.5375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 16, Fold: 1, Training Accuracy: 0.6988636363636364, Training loss:0.7938194329088385, Validation accuracy:0.53125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 17, Fold: 1, Training Accuracy: 0.6931818181818182, Training loss:0.8007889064875516, Validation accuracy:0.525\n","K FOLD FUNCTION ACCESSED\n","Epoch: 18, Fold: 1, Training Accuracy: 0.7017045454545454, Training loss:0.8013694286346436, Validation accuracy:0.51875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 19, Fold: 1, Training Accuracy: 0.6903409090909091, Training loss:0.8016597682779486, Validation accuracy:0.525\n",".........Running 2th cross validation.......\n","K FOLD FUNCTION ACCESSED\n","Epoch: 0, Fold: 2, Training Accuracy: 0.2784090909090909, Training loss:1.6624835079366511, Validation accuracy:0.31875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 1, Fold: 2, Training Accuracy: 0.4431818181818182, Training loss:1.3958098129792647, Validation accuracy:0.39375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 2, Fold: 2, Training Accuracy: 0.45454545454545453, Training loss:1.252830147743225, Validation accuracy:0.46875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 3, Fold: 2, Training Accuracy: 0.5738636363636364, Training loss:1.0583271980285645, Validation accuracy:0.29375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 4, Fold: 2, Training Accuracy: 0.6051136363636364, Training loss:1.0229437784715132, Validation accuracy:0.51875\n","K FOLD FUNCTION ACCESSED\n","Epoch: 5, Fold: 2, Training Accuracy: 0.6761363636363636, Training loss:0.8238082744858481, Validation accuracy:0.60625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 6, Fold: 2, Training Accuracy: 0.71875, Training loss:0.7292859716848894, Validation accuracy:0.49375\n","K FOLD FUNCTION ACCESSED\n","Epoch: 7, Fold: 2, Training Accuracy: 0.7642045454545454, Training loss:0.6294165226546201, Validation accuracy:0.60625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 8, Fold: 2, Training Accuracy: 0.8323863636363636, Training loss:0.5328790437091481, Validation accuracy:0.60625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 9, Fold: 2, Training Accuracy: 0.8295454545454546, Training loss:0.5225846686146476, Validation accuracy:0.65\n","K FOLD FUNCTION ACCESSED\n","Epoch: 10, Fold: 2, Training Accuracy: 0.8409090909090909, Training loss:0.5133768997409127, Validation accuracy:0.6625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 11, Fold: 2, Training Accuracy: 0.8551136363636364, Training loss:0.506841469894756, Validation accuracy:0.65625\n","K FOLD FUNCTION ACCESSED\n","Epoch: 12, Fold: 2, Training Accuracy: 0.8465909090909091, Training loss:0.5038633671673861, Validation accuracy:0.68125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 13, Fold: 2, Training Accuracy: 0.8494318181818182, Training loss:0.49575409293174744, Validation accuracy:0.68125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 14, Fold: 2, Training Accuracy: 0.8494318181818182, Training loss:0.4938286949287761, Validation accuracy:0.68125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 15, Fold: 2, Training Accuracy: 0.8607954545454546, Training loss:0.4745075377550992, Validation accuracy:0.675\n","K FOLD FUNCTION ACCESSED\n","Epoch: 16, Fold: 2, Training Accuracy: 0.8522727272727273, Training loss:0.4953450154174458, Validation accuracy:0.675\n","K FOLD FUNCTION ACCESSED\n","Epoch: 17, Fold: 2, Training Accuracy: 0.8664772727272727, Training loss:0.47752889719876374, Validation accuracy:0.675\n","K FOLD FUNCTION ACCESSED\n","Epoch: 18, Fold: 2, Training Accuracy: 0.875, Training loss:0.4705280607396906, Validation accuracy:0.68125\n","K FOLD FUNCTION ACCESSED\n","Epoch: 19, Fold: 2, Training Accuracy: 0.8579545454545454, Training loss:0.4821428412740881, Validation accuracy:0.675\n","Average Val Accuracy: 0.5791666666666667\n"]}],"source":["os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","#os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n","\n","n_epochs = 20\n","cuda = torch.cuda.is_available()\n","\n","#Define Training Grid Search\n","in_channels = [640]\n","#out_channels = [64, 128, 256]\n","#layers = [2, 3, 4]\n","out_channels = [256]\n","layers = [3]\n","\n","\n","for layer in layers:\n","    for in_channel in in_channels:\n","        for out_channel in out_channels:\n","\n","            model = CNNModel(in_channel, out_channel, layer, label_size=5)        \n","\n","            device = torch.device(\"cuda\" if cuda else \"cpu\")\n","            model.to(device)\n","            \n","            print(model)\n","\n","            k = 3\n","            \n","            avg_val_acc = 0\n","  \n","            for i in range(k):\n","\n","              print(f'.........Running {i}th cross validation.......')\n","\n","              ## Reset weights for each fold\n","\n","              model.apply(reset_weights)\n","\n","              opt = optim.Adam(model.parameters(), lr = 0.001, weight_decay=1e-6)\n","              criterion = nn.CrossEntropyLoss()\n","              scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, patience=2)\n","\n","              ## To reload saved model\n","\n","              # key = str(i) + '-' + str(layer) + '-' + str(in_channel) + '-' + str(out_channel)\n","              # path = '/content/gdrive/MyDrive/model/{i}.pt'.format(i=key)\n","              # checkpoint = torch.load(path)\n","              # model.load_state_dict(checkpoint['model_state_dict'])\n","              # opt.load_state_dict(checkpoint['optimizer_state_dict'])\n","              # saved_epoch = 15\n","\n","              for n in range(0, n_epochs):      \n","                  \n","                  train_loader, val_loader =  kfoldSKLearn(k, i,complete_dataset)\n","\n","                  model, train_acc, train_loss = train_model(train_loader, model, opt, criterion, device)\n","\n","                  valid_acc = test_model(val_loader, model, opt, criterion, device)\n","    \n","                  scheduler.step(valid_acc)\n","            \n","                  print(\"Epoch: \"+str(n)+ \", Fold: \" + str(i) + \", Training Accuracy: \" +str(train_acc)+ \", Training loss:\"+str(train_loss)+ \", Validation accuracy:\" +str(valid_acc))\n","\n","                  #Logging the results of the 10th epoch \n","\n","                  key = str(n) + '-' + str(i) + '-' + str(layer) + '-' + str(in_channel) + '-' + str(out_channel) + '-' + str(valid_acc) + '\\n'\n","                  \n","                  #file1.write(key)\n","              \n","              # Considering the validation acc of the last epoch for each of the k folds\n","\n","              avg_val_acc+=valid_acc\n","\n","              p = str(i) + '-' + str(layer) + '-' + str(in_channel) + '-' + str(out_channel)\n","\n","              path = '/content/gdrive/MyDrive/intro_to_deeplearning/Project/Pure_CNN/run2_15_epochs/{i}.pt'.format(i=p)\n","\n","              torch.save({\n","                      'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': opt.state_dict(),\n","                      'scheduler_state_dict' : scheduler.state_dict(),\n","                      }, path) \n","\n","            avg_val_acc/=k\n","            print(\"Average Val Accuracy: \" + str(avg_val_acc))  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYGceDU53yqu"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"CNNEmbed_OOD.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
